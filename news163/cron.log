2020-08-03 15:15:02 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: news163)
2020-08-03 15:15:02 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.6.0 |Continuum Analytics, Inc.| (default, Dec 23 2016, 12:22:00) - [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-74-generic-x86_64-with-debian-buster-sid
2020-08-03 15:15:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'news163', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'news163.spiders', 'SPIDER_MODULES': ['news163.spiders']}
2020-08-03 15:15:02 [scrapy.extensions.telnet] INFO: Telnet Password: 2372b67c0e87f0b2
2020-08-03 15:15:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-03 15:15:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-03 15:15:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-03 15:15:02 [scrapy.middleware] INFO: Enabled item pipelines:
['news163.pipelines.News163Pipeline']
2020-08-03 15:15:02 [scrapy.core.engine] INFO: Spider opened
2020-08-03 15:15:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-03 15:15:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-03 15:15:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://3g.163.com/touch/tech/ via http://localhost:8050/execute> (referer: None)
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3DU18J000999D8.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '两面派！TikTok在美被"封杀"小扎乐开花?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3DU18J000999D8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3EGL5H00097U81.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'SpaceX载人龙飞船成功返回地球 完成终极测试再创历史'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3EGL5H00097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3GAM1I00097U7R.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '外媒：特朗普同意给字节45天协商向微软出售TikTok事宜'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3GAM1I00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3MGUQR00097U7S.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '北斗系统28nm工艺芯片量产 大部分智能手机支持北斗功能'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3MGUQR00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ42O09K00097U7R.html',
 'pubtime': '1小时前',
 'real_pubtime': '2020-08-03 14:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '微软称正商谈购买TikTok在美国和加拿大等四国的业务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ42O09K00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ45KSDM00097U7H.html',
 'pubtime': '27分钟前',
 'real_pubtime': '2020-08-03 14:48:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '许家印的造车梦又进一步 恒大一口气发布6款车型'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ45KSDM00097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3LVBES00097U7R.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '官宣！雷军小米十周年主题演讲8月11日见！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3LVBES00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1595227652798n56Vq.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '在北京种牙不花冤枉钱！收费透明，在线获取报价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1595227652798n56Vq.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ46F05M00097U7H.html',
 'pubtime': '13分钟前',
 'real_pubtime': '2020-08-03 15:02:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '特斯拉或因广告违规被北京市场监管部门罚款5万元 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ46F05M00097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3LN3QJ00097U7S.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '华为推迟Mate40发布时间至10月底 共分四个版本'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3LN3QJ00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3CK9JU00097U7H.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '微软：将继续讨论收购TikTok美国业务 最早9月15日完成'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3CK9JU00097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3S3BPI00097U81.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '钟南山院士被推为“共和国勋章”建议人选 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3S3BPI00097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3E98S700097U7S.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果要求英国零售店房东减免一半租金 承诺会延长租期'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3E98S700097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3CNIUK00097U7H.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'Facebook抄袭抹黑！字节跳动深夜发声:仍坚守全球化愿景'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3CNIUK00097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3Q5OAH000999LD.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '马斯克称金字塔系外星人所建 埃及：欢迎来参观'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3Q5OAH000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3LL333000999LD.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'ofo仿佛"人间蒸发"了，你的99块押金还要得回吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3LL333000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3BOIRN000999LD.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美媒：微软和TikTok正同白宫协商 避免全面封禁 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3BOIRN000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3LDIAN000999LD.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '最畅销电动汽车！特斯拉Model 3上半年交付14.23万辆'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3LDIAN000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3E0QSJ000999LD.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '神州优车公告：被罚款50万元 证监会对陆正耀给予警告'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3E0QSJ000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2MPCGS00119821.html',
 'pubtime': '14小时前',
 'real_pubtime': '2020-08-03 01:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '华为Mate 40 Pro正面已无悬念：上手盈盈一握'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2MPCGS00119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3L6DSG000999LD.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果1亿美元收购加拿大公司:可将iPhone转为支付终端'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3L6DSG000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3QGQ5M00097U7S.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '北斗办：北斗与5G融合将推动无人驾驶等技术发展 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3QGQ5M00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3NC5OV0511844G.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'Zoom宣布将于8月23日正式停止向中国用户直销模式'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3NC5OV0511844G.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3G0C81000999LD.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '小鹏汽车再获超3亿美元融资，阿里领投'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3G0C81000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3MQ4880511844G.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '华为宣布成立数通自动驾驶网络联合实验室'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3MQ4880511844G.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3HN5RE0511844G.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '没有5G手机的我用上了5G网络，怎么做到的？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3HN5RE0511844G.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2R19I200119821.html',
 'pubtime': '13小时前',
 'real_pubtime': '2020-08-03 02:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '一代神机小米6钉子户 雷军惊讶：建议大家对自己好一点'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2R19I200119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3G8GD300097U7S.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '起底电信诈骗"杀猪盘":瞄准30+女性 有人被怂恿卖房卖车'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3G8GD300097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3FS9FI0511WT04.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '在线教育厮杀“暑期档”：烧钱、亏钱、欠钱'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3FS9FI0511WT04.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2IUGQL00119821.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美国公然炫耀封杀华为成果：5G干净了！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2IUGQL00119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/video/VGI61DPHC.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '【大佬言论】马云谈如何做好慈善'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/video/VGI61DPHC.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3PSC3S00097U7R.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '喜马拉雅8周年推"攀登者"致敬短片 平台主播人数超千万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3PSC3S00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2IUJ6F00119821.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '充电宝电芯里竟是沙子：10000mAh实际输出才这么点'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2IUJ6F00119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2IUEC8001697V8.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'Win10升级不香了：这组数据 让微软内心拔凉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2IUEC8001697V8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3Q0P8600097U7R.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '天图投资募得首期美元VC基金 雀巢集团为基石投资者'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3Q0P8600097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3LP9PI000999LD.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'AMD明年2季度投片量将超越苹果 跃居台积电第一大客户'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3LP9PI000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2KH9OC001697V8.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '三星诀别中国！最后一家电脑工厂关门'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2KH9OC001697V8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ3PDOEV000999LD.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '太费电！洛阳联通定时休眠5G基站'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ3PDOEV000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ17S8HT00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '小扎抨击中国公司 但FB在国内生意并不小'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ17S8HT00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0T9SKE00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '白宫出现意见分歧 微软暂缓TikTok收购案'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0T9SKE00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ1SPA4I00097U7R.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '特朗普要彻底封禁TikTok，美媒推测这俩原因'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ1SPA4I00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ1TB7DR00097U7R.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '腾讯孙忠怀：疫情只是小关口 视频行业不能只做短期打算'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ1TB7DR00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ1LDOQT000999LD.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '印度时报：苹果供应商研究向印度转移6条生产线'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ1LDOQT000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ1781JS00097U81.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '"龙飞船"返程！两名美国宇航员结束国际空间站任务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ1781JS00097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0VFKUJ00097U7S.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '三星电子关闭在华最后一家电脑厂 约850名员工受影响'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0VFKUJ00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ155S0Q00097U7S.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'iPhone虚假宣传？广告称"水下30分钟" 出问题辩称"实验数据"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ155S0Q00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0UMEAP00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'TikTok官号发布"稳定军心"视频：我们不会离开  '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0UMEAP00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ14OB0P000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '“熬死”所有对手 百度网盘又成香饽饽？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ14OB0P000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ10OCU600097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '印度推出66亿美元制造业奖励计划 富士康、三星等纷纷响应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ10OCU600097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0UIEU200097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '1999元无限次飞全国 "同程任我飞"刚要发售突然叫停'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0UIEU200097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0MC1LC000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '努力追赶台积电！中芯国际宣布全力发展28nm工艺'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0MC1LC000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0LJBFS000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '小米在印度被起诉！因涉嫌侵犯智能手机技术专利'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0LJBFS000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ19VIO005199LET.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'B站UP主有多赚钱：有人用爱发电，有人年入千万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ19VIO005199LET.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ142K80001697V8.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '花呗接入央行征信，注意：额度没用也可能算负债'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ142K80001697V8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ13GHHI00097U7S.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '软银计划继续持有芯片设计公司ARM的股份'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ13GHHI00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ10HBHG00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '特朗普拟禁止TikTok 专家：全球企业将对美国失去信心'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ10HBHG00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ18J8380511A0EF.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '小鹏汽车被曝再融3亿美元：中东资本加持 或很快美国上市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ18J8380511A0EF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ14LROK00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'TikTok是否拆分尚无定论，但已被集体“默哀”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ14LROK00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ13MJGS00097U7S.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '胡锡进：华为和TikTok让华盛顿心神不宁的是这种能力'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ13MJGS00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ11S9D400119821.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '华为Mate40稳了！曝5nm麒麟1020比A14成本更高'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ11S9D400119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0UENQO00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果动手！中国区商店半天下架近3万款 这个行业迎大洗牌'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0UENQO00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0RU8IT05118DFD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '传「英伟达」 有意「ARM」，已进行深入谈判阶段'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0RU8IT05118DFD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0M9ICI000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '华为首超三星成全球手机之王！最关键原因在此'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0M9ICI000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ1Q7QPF00097U7R.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '阅文连三月：加大新文创内的协同力度 提速IP动漫改编'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ1Q7QPF00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ1Q5DUQ00097U7R.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '游戏内容月活突破3亿 快手：未来将引入1万家游戏公会'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ1Q5DUQ00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ167TC005118HJE.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '代拍、卖票、营销号...职业追星可以赚钱你知道吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ167TC005118HJE.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ14C6VF000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '距离地球约300万公里，天问一号完成首次轨道修正'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ14C6VF000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ12CCM900119821.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '印度米粉翻出一代旗舰小米3：印度狂销50万台'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ12CCM900119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ128HMU00119821.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '80后的集体回忆 2020年可拆卸电池手机还能回来吗'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ128HMU00119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ118Q7D0511844G.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '它们掳去的，只是TikTok的躯体'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ118Q7D0511844G.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0VVQS200097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '推特最大漏洞黑客曝光！17岁少年盗号盖茨等骗比特币'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0VVQS200097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0SUSF5053192O2.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'Tik Tok美国卖给Google怎样？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0SUSF5053192O2.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ15967400119821.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '华为Mate 40 Pro正面细节：3D人脸识别+双孔曲面屏'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ15967400119821.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ14VKLI00097U81.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '前所未有画面！火星表面照片被制成4K视频 令人身临其境'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ14VKLI00097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ12G2JK0511WT04.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '互联网人，“三十而已”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ12G2JK0511WT04.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ108HN200097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '马斯克称中国人聪明勤奋 美国人越来越自满又自以为是'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ108HN200097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ0U9GD500097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '花呗分批接入央行征信系统 会影响个人征信记录吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ0U9GD500097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ13RVMJ001697V8.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'Intel被控侵犯中科院微电子所专利 预计赔偿2亿元'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ13RVMJ001697V8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ05NAA7051288MF.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '5G基站耗电量是4G的十倍？5G也有不为人知的一面'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ05NAA7051288MF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ05KO2A05169FIR.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '重磅！2020欧洲科学院院士名单公布，这些中国学者入选！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ05KO2A05169FIR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ07752M051180F7.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '北斗三号组网完成！四大黑科技吊打GPS，七个行业受益'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ07752M051180F7.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ13UMBL001697V8.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '电脑越用越卡原因盘点：需对症下药根治卡顿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ13UMBL001697V8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2BPT3D00097U7H.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'A 站发布 “二八计划”：80% 直播打赏将直接分给 UP 主'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x76f4) at index 88
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FJ2BBT3C00097U7H.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '腾讯视频副总裁王娟：打造综合视频平台 将推腾讯视频号'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FJ2BBT3C00097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIVPGL8300097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '外媒：字节跳动同意剥离TikTok美国业务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIVPGL8300097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUPFGIS000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '加拿大称将孟晚舟引渡到美国的要求已经满足'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUPFGIS000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIU92PFM00097U7T.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果股价周五飙升10％！市值超越沙特阿美'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIU92PFM00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUEMK4A000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '北斗三号系统全面建成给北斗产业带来什么？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUEMK4A000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIU8JJ2300097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '特朗普或强迫tiktok卖身，传微软正谈判收购'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIU8JJ2300097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUIL5A800097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '微软收购TikTok美国？字节：这是猜测'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUIL5A800097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUEGVNU00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '针对有色人种 美一零售商秘密部署人脸识别系统达8年'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUEGVNU00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUDPGVF000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'iPhone 12 Pro 尚未发布，但已开始接受第三方高级定制'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUDPGVF000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUEAKPF000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '即将返航！NASA为载人龙飞船从国际空间站返回“开绿灯”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUEAKPF000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUE693T000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '微软美国办公室最早要到明年1月才会全面重新开放'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUE693T000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUE3MCL000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '比卫星看到的深三倍 科学家利用LiDAR技术探测海洋深处'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUE3MCL000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUE0ADK000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '谷歌母公司Alphabet的营收22年来首次出现下滑'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUE0ADK000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUDUGLC000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '1090万人订了票的“毅力号”核动力火星车有多强？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUDUGLC000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUD8OJV000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '库克称苹果不会通过收购其他公司来阻止竞争'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUD8OJV000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUMH0CT00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '外媒：TikTok拟开放算法赢得美国监管支持'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUMH0CT00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIULD7EF00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '特斯拉报告：自动驾驶每453万英里1起事故 明显改善'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIULD7EF00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUL7FOP00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '库克：苹果的收购行动是为了把技术用在iPhone上'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUL7FOP00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUL2OM400097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '中芯国际欲成立合资企业 投资76亿美元开发集成电路项目'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUL2OM400097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUGC5OA00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '马斯克：疫情期间的特斯拉汽车消费需求依然强劲'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUGC5OA00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIV51J0C00097U7R.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '快手游戏直播月活超2.2亿 游戏短视频月活破3亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIV51J0C00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIV2HM19000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '天文学家研究发现“潜伏”在我们星系边缘的古老恒星'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIV2HM19000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIV2F1BK000999LD.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '研究表明类太阳系星系或可容纳多达7颗类地行星'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIV2F1BK000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIV2C59I000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'NASA将密切监测热带风暴 以调整载人龙飞船返回计划'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIV2C59I000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIV291F4000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'LG希望扩大竞争力：计划推出更廉价的5G手机'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIV291F4000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIV26Q61000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '马云的湖畔大学有多严？一年内缺2节课发“禁课令” '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIV26Q61000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUJ34L5000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '疫情刺激家庭成为流量中心：Verizon将LTE用于FWA家宽接入'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUJ34L5000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUIFIOP000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '做好5G要解决好五个问题，“先发”者占据竞争优势'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUIFIOP000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUI01UB000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '自主研发？印度“三无”5G背后的“阴谋”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUI01UB000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUHS2IU000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '无视美国警告！菲律宾最大运营商与华为合作5G服务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUHS2IU000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUHMLAB000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美国制裁香港在即，中国芯片进口商加紧囤货'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUHMLAB000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUHBTJB000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美国施压下，智利放弃中国海缆建设方案'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUHBTJB000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUH1064000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '传英伟达正与软银就收购ARM深入谈判 交易价值超320亿美元'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUH1064000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUGOTR1000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '诺基亚二季度营收50.92亿欧元 已获得83份5G商用合同'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUGOTR1000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUGBMJD000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '法国电信大亨Patrick Drahi发声 称华为5G设备是最好的'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUGBMJD000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIUG8AI8000999LD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '亚马逊100亿美元卫星互联网项目获批，将与SpaceX星链竞争'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIUG8AI8000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT61ILA00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '瑞幸咖啡回应被立案调查：不会影响门店运营'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIT61ILA00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISMBF0G00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '财政部：瑞幸虚增收入21.19亿元 将给予行政处罚'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISMBF0G00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS7OSTI000999D8.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '不少中国人在疫情期买iPad和Mac，库克自豪'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS7OSTI000999D8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT0Q8FT00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '21记者多方求证：微信 支付宝被反垄断调查纯属传言'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIT0Q8FT00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS3DSA500097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '从北京晨跑到抹黑中国，扎克伯格为何变得这么快'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS3DSA500097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRKJKPT00097U7S.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果证实了！今年新款iPhone上市将比往年晚几周'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRKJKPT00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT1DQ9E00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '证监会：对瑞幸咖啡境内运营主体等予以行政处罚'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIT1DQ9E00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISQUVRU00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'ofo戴威新动态！公布生娃喜讯：升级了 努力做个好奶爸'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISQUVRU00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRKBCFU00097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '大涨！苹果Q3营收597亿美元 净利113亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRKBCFU00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISTT2O000097U7H.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '外媒：小鹏汽车正洽谈超3亿美元融资计划'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISTT2O000097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQR1QSG000999D8.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '中国第二家!理想汽车美股上市 特斯拉蔚来们怎么看?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQR1QSG000999D8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://3g.163.com/touch/live.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '直播：北斗三号全球卫星导航系统建成开通仪式'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://3g.163.com/touch/live.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT5KQ1500097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '7月31日美股全线高开，苹果涨7% 诺基亚大涨近10％'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x8bfa) at index 89
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT1DCLV0511A6N9.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '搜狗宣布成立独立特别委员会 审查腾讯初步非约束性收购提议'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIT1DCLV0511A6N9.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISSSKRN00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '马云因抗疫被约旦国王授予一级卓越勋章 系中国第一人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISSSKRN00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT9URBB00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '阿里将认购8.2亿港元易居股份 双方签署战略合作协议'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIT9URBB00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIT05D2B00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '瑞幸咖啡回应财政部处罚：暂时还未收到通知'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIT05D2B00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISQ3U0200097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '市场监管总局对瑞幸咖啡等涉嫌不正当竞争立案调查'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISQ3U0200097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISMU6TM00097U7S.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '任正非访问复旦：很高兴在复旦看到愿坐冷板凳的人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISMU6TM00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISFDKKJ00097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '4.8万美元！特斯拉长续航后驱版Model Y价格曝光'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISFDKKJ00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISBJHFU000999LD.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': ' 华为已无退路，传已招聘数百位顶尖光刻机工艺师'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISBJHFU000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/special/S1596003667710.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '库克：以旧换新是趋势，买新iPhone会非常便宜'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/special/S1596003667710.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS3KRAK000999LD.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '三星苏州电脑工厂只保留研发部 员工一度有6500人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS3KRAK000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS1UKLT00097U7S.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '中国手机市场Q2出货量萎缩，华为与苹果逆势增长'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS1UKLT00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS0GO5J000999LD.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '理想汽车的理想是千亿美元市值公司？王兴:万亿级别'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS0GO5J000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS0D45V00098IEO.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '旷视被列入美国实体清单 80后创始人吐露心声'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS0D45V00098IEO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISL8IUQ00097U7S.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '腾讯黑鲨游戏手机3S发布 搭载骁龙865处理器 3999元起'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISL8IUQ00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISK2B9D00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '暴风集团：上海市静安区人民检察院以行贿罪对冯鑫提起公诉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISK2B9D00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISBNDCF00097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '61岁肖亚庆任工信部党组书记，65岁苗圩不再担任'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISBNDCF00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRSASJ700097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '多了2500亿美元！美四大科技巨头盘后市值飙升'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRSASJ700097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISOKDLE0519QIKK.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '消息称英伟达就收购软银芯片公司ARM展开深入谈判'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISOKDLE0519QIKK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISCE6MM0511A99L.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'ofo总部“人间蒸发”，20亿外债该谁还？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISCE6MM0511A99L.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISBURE700097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '松下计划3年内推无钴电池 5年内电池能量密度提两成'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISBURE700097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/special/S1594973245447.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '大气密度不足地球1% NASA的火星直升机能成功吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character 'N' (0x4e) at index 82
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRUUQI500097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'Facebook CFO：苹果iOS 14更新或影响我们广告收入'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRUUQI500097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRRAR0Q0511WT04.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '头部新造车扎推IPO：理想距离特斯拉还差18个蔚来'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRRAR0Q0511WT04.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRR6BP10511844G.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '永远不要相信扎克伯格：表演太浮夸让人没法信'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRR6BP10511844G.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRMPONR00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '亚马逊Q2净销售额899亿美元同比增40% 净利翻番'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x51c0) at index 93
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRMFVF100097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '谷歌母公司第二季度营收383亿美元 16年来首次下滑'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRMFVF100097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRL2R2000097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '理想在美上市首日大涨43%，总市值近140亿美元'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0xff0c) at index 84
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISIJ16R00098IEO.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '陆奇：原熊猫资本合伙人毛圣博加入 担任奇绩创坛合伙人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISIJ16R00098IEO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISCJJRI00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '微博增"宣扬仇恨"投诉分类：含性别歧视和地域歧视'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISCJJRI00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISC672H00097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '历时30年建设，北斗"全球时代"到来'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISC672H00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRNM8FI00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美国会议员要求司法部调查Zoom和TikTok与中国关系'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRNM8FI00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRLSSU100097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'FB二季度营收187亿美元，净利52亿美元同比增98%'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character ''' (0x27) at index 98
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIST2I4S00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '腾讯云首次披露云原生产品数据：API日调用量超100亿次'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIST2I4S00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISGBESK00097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '京东战略投资利丰集团，在自有品牌等业务深度合作'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISGBESK00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISE0J3200097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '法院宣判抖音案：隐私权不同于个人信息权益保护'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISE0J3200097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISDIQR300097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '消息称字节跳动考虑中国业务在香港或上海上市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISDIQR300097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRSU0SP00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '软银计划动用96亿美元 最高回购公司12.3%的股份'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x7684) at index 94
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRSQEKO05319YKA.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '“美团大炮”王兴，中国互联网界最“会”说话的人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRSQEKO05319YKA.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIROSNRO00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美团阿里之战并不仅在支付，从外卖到生鲜都在打'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIROSNRO00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRO606500097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美股周四走势分化 道指跌超200点 苹果盘后上涨6%'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character ''' (0x27) at index 97
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRNE9E300097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '库克：苹果员工要到2021年初才会回到美国办公室'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRNE9E300097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISSNQI300097U7R.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '微信可以叫e代驾！目前向北京深圳广州重庆用户开放'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISSNQI300097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQQV40I05319LDA.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '抖音商家与淘宝千牛脱钩，“友谊的小船”翻了？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQQV40I05319LDA.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS8BGAQ00097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '理想之后又一家，路透：小鹏汽车计划8月赴美国上市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS8BGAQ00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRLF4OM00097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果宣布1：4比例进行拆股：让更多投资者能买得起'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIRLF4OM00097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQQM2E20511GOL5.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '无数年轻人的第一笔巨额开支，成就了这家公司的上市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQQM2E20511GOL5.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FISFAMEE051184MS.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '60年间，人类火星探测都经历了哪些历程？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FISFAMEE051184MS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS1VCJ90511A8O9.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'NASA坚毅号启程奔赴火星，本届火星赛季圆满落幕'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS1VCJ90511A8O9.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIS0CMPI0511A8O9.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '人类首次在火星上起飞直升机，为何只能飞5米高？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIS0CMPI0511A8O9.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIRN7VFV00097U7S.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '苹果Q3大中华区营收同比仅增1.9% 库克：汇率影响大'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x5e93) at index 90
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIPFOENV00097U7S.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '二季度华为手机首超三星成全球出货冠军'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIPFOENV00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIP3I4UM00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '面对议员尖锐提问，贝索斯库克等四大佬"否认三连"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIP3I4UM00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQJG39A00097U81.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美国"毅力号"火星车发射，探秘35亿年前的生命'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQJG39A00097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIPO8JU8000999D8.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '王兴想拒绝支付宝，但用户可能不答应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIPO8JU8000999D8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIOD3P0P00097U7H.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '王兴：淘宝为什么不支持微信支付'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIOD3P0P00097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIP5DK0900097U7T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '三星Q2营收457亿美元净利47亿，芯片与家电需求强劲'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIP5DK0900097U7T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQDUVUH00097U81.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': 'NASA"毅力"号核动力火星车发射升空'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQDUVUH00097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQ869BP00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '理想汽车赴美敲钟，王兴和美团的出行野心还在路上'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQ869BP00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQFEPA800097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '盖茨批评马斯克新冠言论离谱 马斯克回怼：你又不是我恋人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQFEPA800097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQBN1N500097U7H.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '特斯拉Q2车辆安全报告：自动辅助驾驶下安全性高出9倍'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQBN1N500097U7H.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQ82P64000999LD.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '台积电3nm工艺计划明年风险试产 有望提前大规模量产'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQ82P64000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQ3MJ2T00097U7S.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '美威胁巴西弃用华为 外交部：坚决抵制国别歧视'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQ3MJ2T00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQLET170511A0EF.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '理想汽车上市：市值百亿美元 80后李想40岁前再敲钟'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQLET170511A0EF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQD8GDR00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '互联网法院一审认定抖音侵害用户个人信息 抖音：会上诉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQD8GDR00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQBUHSN00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '斗鱼回应主播跳槽：主播与公会和解 违约金系签约时约定'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQBUHSN00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQBQBL000097U81.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '揭秘首个火星直升机：将是首架在外星大气飞行的人类飞机'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQBQBL000097U81.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIQ43B1S00097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '腾讯回应微信读书侵害用户信息：尊重判决 功能已优化'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIQ43B1S00097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:24 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/tech/article/FIPPR21700097U7R.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:24',
 'source': 'https://3g.163.com/touch/tech/',
 'title': '雷军发布在B站首个视频：听说我在B站很有名'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/tech/article/FIPPR21700097U7R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://3g.163.com/touch/money via http://localhost:8050/execute> (referer: None)
2020-08-03 15:15:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://3g.163.com/touch/news via http://localhost:8050/execute> (referer: None)
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3RIQQN00259DLP.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '起底汇丰银行:陷害华为只是个"小目标"?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3RIQQN00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3C6H6000259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '印度又有大动作!小米、Vivo要遭殃?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3C6H6000259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ46FUT300258105.html',
 'pubtime': '12分钟前',
 'real_pubtime': '2020-08-03 15:03:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股8月开门红！沪指涨1.75% 超250股涨停'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x8d85) at index 88
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ46BJBF00258J1R.html',
 'pubtime': '15分钟前',
 'real_pubtime': '2020-08-03 15:00:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '田轩：美国将陷入严重衰退 可能永久改变全球经济'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ46BJBF00258J1R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ44KEKP00258105.html',
 'pubtime': '45分钟前',
 'real_pubtime': '2020-08-03 14:30:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '小i机器人对苹果提起侵权诉讼 索赔100亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ44KEKP00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3G5EUV00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '蓬佩奥又威胁！特朗普将对中国科技公司采取行动'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3G5EUV00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3DFCK800258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '神州优车：被罚款50万元 证监会对陆正耀给予警告'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3DFCK800258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1595227652798n56Vq.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '在北京种牙不花冤枉钱！收费透明，在线获取报价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1595227652798n56Vq.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ410A8100259DLP.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '葫芦岛银行行长被查引挤兑 央行、银保监联合辟谣'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ410A8100259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ40QCCB00259DLP.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '中科院院刊刊文：支持深圳、青岛等升格为直辖市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ40QCCB00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3PUE9I00259DLP.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '商汤科技考虑在最近一轮融资后上市 估值100亿美元'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3PUE9I00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CNEJV00258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '大案！银行行长借钱炒股血亏4000万 6年欠债2.8亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CNEJV00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CKVT700259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '提醒！中一签或狂赚20万 就在今天 千万别错过！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CKVT700259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3C89SD00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '300万元菜籽油被盗 保管员失踪 牵出国家粮库大问题'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3C89SD00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3F1J9U00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '国家医保局发出1号令！八类“神药”出局 市场重塑'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3F1J9U00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3RALRO000189FH.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '这个郑重承诺，习近平反复提及 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3RALRO000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3RBQ18000189FH.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '调动广大农民积极性、主动性、创造性'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3RBQ18000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3R8UBN000189FH.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '习近平提出三点希望\xa0同心答好“加试题”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3R8UBN000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ40J7F20515TDAO.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '失踪女大学生死亡:南京某大学"6朵金花"其中1朵凋零'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ40J7F20515TDAO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2BGUNS051996QS.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '太暴利！中国“可口可乐”要上市了！茅台小心了！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2BGUNS051996QS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ43TMSG00259DLP.html',
 'pubtime': '57分钟前',
 'real_pubtime': '2020-08-03 14:18:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '商务部：对原产于美国的进口聚苯醚进行反倾销调查'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ43TMSG00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3NCTDQ002580S6.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '微软重启收购TikTok \xa0字节跳动回应坚守全球化愿景'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3NCTDQ002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3MU01G002580S6.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '深交所强调：创业板注册制对欺诈、造假零容忍'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3MU01G002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3KDD3T00259DLP.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '7月财新中国制造业PMI升至52.8 为九年半来最高'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3KDD3T00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3JLVF300259DLP.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '中国外汇交易中心：暂免部分直接交易货币对交易手续费'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3JLVF300259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CHJ0A00258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '媒体：围猎TikTok是最丑陋的美剧之一'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CHJ0A00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3C1BG800258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '中储粮回应“禁带手机入库区”:严厉批评'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3C1BG800258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ42UOER00259DLP.html',
 'pubtime': '1小时前',
 'real_pubtime': '2020-08-03 14:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '特斯拉被北京市场监管局罚款5万元 或因广告内容不准确'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ42UOER00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3IS95H00258105.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '特朗普封禁TikTok？美国用户心碎：用选票表达不满'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3IS95H00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3I7R2700259DLP.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '农夫山泉获准上市 “大自然的搬运工”有多赚？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3I7R2700259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3I11AM00258105.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '特朗普给字节跳动45天时间协商向微软出售TikTok'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3I11AM00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EI0SV00259DLP.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '易纲:进一步提高货币信贷政策执行的针对性和有效性'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EI0SV00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3E6RH700259DLP.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '微软：推进TikTok谈判 以求在9月15日前完成商谈'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3E6RH700259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3IN0JK00259DLP.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '100万亿资管大消息：影响有多大？整改进度如何？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3IN0JK00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3TN8VS00018AOR.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '浙江高考满分作文"生活在树上" 马伯庸：辞不配位'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3TN8VS00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3DC19E0514BE2Q.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '涉案14亿！公安局长竟是黑老大 进公安系统原因成迷'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3DC19E0514BE2Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3CFUP70001899O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '台湾真想打一场战争？绿媒：中美必有一战 大陆会败'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3CFUP70001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1595227652798n56Vq.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '在北京种牙不花冤枉钱！收费透明，在线获取报价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1595227652798n56Vq.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2FAJKM0537A693.html',
 'pubtime': '16小时前',
 'real_pubtime': '2020-08-02 23:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '港大给白湘菱百万奖学金！母亲狂喜：好到不能再好'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2FAJKM0537A693.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2BJKDJ051482MP.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '厅官怀疑情人与企业老板搞暧昧 向该老板索要200万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2BJKDJ051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1P0UTC0001899O.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '无缘清华北大的江苏文科第一名 最终申请香港大学'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1P0UTC0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3QN44D0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '失联女大学生遗骸被找到 救援队：非野兽袭击身亡'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3QN44D0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3C8I9M00019QIF.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '用两吨水碎尸?杭州杀妻男不知道中国刑侦技术多牛逼'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3C8I9M00019QIF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3C89SD00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '国有粮库空仓近一年无人发现?揭硕鼠四大贪腐手段'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3C89SD00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITP2PQ905370H3B.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子将醉酒女友带宾馆发生关系后 叫2朋友将其强奸'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITP2PQ905370H3B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1FEDKT0537A693.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '可可西里身亡女孩死因成谜：一举动表明不像去自杀'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1FEDKT0537A693.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ421P6H00018AOR.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '高校毕业生组织卖淫手机存200名嫖客电话?校方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ421P6H00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3MSOT80001875P.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '主持人沈力追悼会朱军白岩松现身 倪萍痛哭被搀扶'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3MSOT80001875P.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3JS4450001899O.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '浙江高考满分作文曝光 阅卷时因晦涩难懂被打39分'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3JS4450001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3J0S91002580S6.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A站争夺创作者：八月起80%直播打赏分给UP主'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x76f4) at index 85
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3ICAV20025817I.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '前7月主动权益基金收益超30% 4只业绩翻倍'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x53ea) at index 88
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3H7L2C00259DLP.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'ofo“消失”了 1600多万人等退钱 还要得回吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3H7L2C00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3H7B9B053900WX.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '农夫山泉将于本月中旬寻求通过港交所聆讯 预计9月正式上市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3H7B9B053900WX.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3HQUKE002580S6.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '游资大佬集结做多 头条概念龙头省广集团再来一波?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3HQUKE002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ40NOCE002580S6.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '华尔街顶级分析师看好这些股：高通 Paypal Spotify'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ40NOCE002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ40A86O00258105.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '张一鸣谈Tik Tok：还没有完全决定最后的解决方案'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ40A86O00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3TKAT400259DLP.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '什么是妖股？交易所重点监控 用“一字涨停”回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3TKAT400259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3SJND300259DLP.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '沾上概念就能火！33天17个涨停板 股价大涨368%'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character ''' (0x27) at index 97
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3F60K400258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '中国版集体诉讼启航 “康美们”迎投资者索赔大时代'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3F60K400258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3F4GHI00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '机构预期降准降息幅度将变小 股债性价比趋于平衡'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3F4GHI00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3F2T9200259DLP.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '这类医用耗材带量采购渐成规模 这些股或持续受益'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3F2T9200259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EVKCU00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '疫情反复令美经济雪上加霜 科技股能否扛起美股大旗'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EVKCU00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3ES4R300258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '后疫情时代英放大招吸引留学生 智库为本土学生叫屈'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3ES4R300258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EG06G002580S6.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '7月股民人均赚5万 8月走势如何？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EG06G002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3AEGAA0001899O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '25岁漂亮女教师离奇失踪 警方在一水沟发现女性内衣'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3AEGAA0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2NT2MG05379L57.html',
 'pubtime': '14小时前',
 'real_pubtime': '2020-08-03 01:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '无人区陆续找到女学生“散骨头”可可西里有多危险？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2NT2MG05379L57.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ45DVB30001899O.html',
 'pubtime': '31分钟前',
 'real_pubtime': '2020-08-03 14:44:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '“秘书”吐槽陪副司长孩子考试？当事人：没秘书'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ45DVB30001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ44FEKE0001899O.html',
 'pubtime': '47分钟前',
 'real_pubtime': '2020-08-03 14:28:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '瑞士跟风插手香港事务 污蔑中国"偏离了开放的道路"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ44FEKE0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ438Q5H0514R9P4.html',
 'pubtime': '1小时前',
 'real_pubtime': '2020-08-03 14:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '秘书微博"出卖"了领导?当事人:发牢骚吹牛不能当真'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ438Q5H0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ42KP6Q0001899O.html',
 'pubtime': '1小时前',
 'real_pubtime': '2020-08-03 14:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '港警问为何冒险逆行 内地医生:我是中国人 为国做事'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ42KP6Q0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ41PM3V0541A1UA.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '奥巴马同父异母哥哥怒斥弟弟势利 发文支持特朗普'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ41PM3V0541A1UA.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3R6R2M0001899O.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '环球：中国从未禁止美科技公司来华 谷歌是自己退出'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3R6R2M0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3QUSEI0514R9P4.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '国防部首次公开布一种新型轰炸机存在 被称航母杀手'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3QUSEI0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3QLBF00001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '国家信息中心原副主任马忠玉被双开 涉一罕见问题'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3QLBF00001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3QJML20514DTKM.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '法专家鼓励青年互相传染 医生随意开不能戴口罩证明'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3QJML20514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3Q37RQ051481US.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普不会离开白宫？议员：他想通过紧急方式留任'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3Q37RQ051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1595227652798n56Vq.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '在北京种牙不花冤枉钱！收费透明，在线获取报价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1595227652798n56Vq.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3P2UQD0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美俄军控谈判长达13小时 俄方：美国不再逼中国加入'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3P2UQD0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3O8I5R0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '媒体：美国新冠失控 不过是30年前艾滋泛滥的重演'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3O8I5R0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3C3MMU00258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '字节跳动深夜发声：面临国际政治环境紧张等困难'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3C3MMU00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3BALTP00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '微软和TikTok正同白宫协商 避免全面封禁'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3BALTP00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3M53RB00259DLP.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '7月财新中国制造业PMI升至52.8 为九年半来最高 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3M53RB00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3KN6AH002580S6.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '微软重启收购TikTok业务讨论 最晚9月中旬公布进展'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3KN6AH002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EU18P00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '百年高校因财务危机关闭!欧美教育产业化弊端渐现'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EU18P00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CVISV00259GN4.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股上月成交超30万亿 141份中报或掀"业绩浪"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CVISV00259GN4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CU9LR00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '最新！上半年GDP十强排位出炉 这两座城市亮了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CU9LR00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CSN6F00258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '年内22家上市公司退市 有进有出市场生态日益完善 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CSN6F00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CQDV000258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '美国经济遭遇"休克式打击" 下半年走势仍难乐观 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CQDV000258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CEDG100259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '美国千万粉丝博主不舍告别：TikTok让我买上了房'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CEDG100259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3C919F00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '字节跳动： 面临FB抄袭等困难 仍坚守全球化愿景'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3C919F00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3BVVO200259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '澳议员拿中国变压器说事 炒作“中国威胁澳电网”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3BVVO200259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3BRD3M00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '重磅信号！增量资金持续入市 A股8月风口在哪儿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3BRD3M00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2TGB59002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '今日视点:从一到亿 证券集体诉讼制度凝心聚力'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2TGB59002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2QH3S8002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股上月成交超30万亿元 141份中报或掀“业绩浪”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2QH3S8002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3O7OQV0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '乱港分子不服被港警通缉：我是美国人 在美生活25年'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3O7OQV0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUM2KO9N000189FH.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '“没有不能揭的黑，没有不敢碰的恶” '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUM2KO9N000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUM24BRS000189FH.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '新华时评：5G不能被政治化 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUM24BRS000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUJ790P7000189FH.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '“让世界享受中国创新、开放所带来的红利” '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUJ790P7000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUJ76SJ2000189FH.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '推动数字技术制造业深度融合是推动高质量发展关键'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUJ76SJ2000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUJ75M7V000189FH.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '穆巴达拉公司CEO：中国是值得外国人来投资的国家'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUJ75M7V000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUJ72ESB000189FH.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '贸易摩擦严重冲击中国经济？美智库：高估了 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUJ72ESB000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/EUJ70D5R000189FH.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '“开放带来共赢” ——记2019年创新经济论坛'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/EUJ70D5R000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/E6KATJC70514HDK6.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '【网络祝年】“公益慢火车”让回家的脚步更从容'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/E6KATJC70514HDK6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/E6KA44UI0514HDK6.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '昔有桃园三结义，今赞携手京津冀'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/E6KA44UI0514HDK6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/E6K77H210514HDK6.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '【网络祝年】别样年货，文化年味'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/E6K77H210514HDK6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3NM7F60550AXYG.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '拒戴口罩狂殴公交司机头部16拳 男子获刑3年3个月'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3NM7F60550AXYG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3MLFVU0534J2WK.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '台湾政坛大地震 蔡英文发现事态严重了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3MLFVU0534J2WK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3L0UKT0550HKNY.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普没等到中国屈服 先等来王毅6天4次密集表态'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3L0UKT0550HKNY.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3K6V9E0543B28N.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '不是他杀 不像自杀 是谁把失联女大学生推向死亡？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3K6V9E0543B28N.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2LSFVV002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '海运航线需求回升价格急涨 乐歌股份呼吁平抑运价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2LSFVV002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ41R33D002580S6.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '业绩连续高增长股名单曝光！8月机构看好这个概念'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ41R33D002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ41R2TH002580S6.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '涨价声起！龙头封住涨停 纸业概念绩优股名单出炉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ41R2TH002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3UR7P0002580S6.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '特斯拉一旦纳入标普500指数 意味着什么？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3UR7P0002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3RRA1E002580S6.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '核心部件全国产！北斗三号在途 产业链将全面铺开'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3RRA1E002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3R8VFN002580S6.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '一纸公告引概念股秒板 中芯国际坐实"带头大哥"地位'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3R8VFN002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3QCOOI002580S6.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '仔猪占比较高 天邦股份7月商品猪收入下滑11.75%'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character ''' (0x27) at index 97
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3M81MH002580S6.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '民泰银行违规罚款超200万 支行员工违法放贷7.38亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3M81MH002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3MICOE002580S6.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '原董事长涉严重违纪 东海证券去年被调查处罚9次'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3MICOE002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CH0GU0025817I.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '投研能力决定管理规模 百位基金经理掌舵万亿资金'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CH0GU0025817I.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3BUUI900259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '3800点目标实现中！短期震荡接近尾声'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3BUUI900259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3BM5KP0025817I.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '赚钱效应凸显 新基金发行市场火热'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3BM5KP0025817I.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2RPA1Q002580S6.html',
 'pubtime': '13小时前',
 'real_pubtime': '2020-08-03 02:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股8月走势如何？分析：股指有望突破前期的高点'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2RPA1Q002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ33IHIP002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '重组返利网关键期 ST昌九大股东持股遭冻结'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ33IHIP002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2VLUB8002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '新创业板本周打新 赚钱效应几何？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2VLUB8002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3HRA1J0001899O.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '微信要遭殃?美政府未来几天将对更多中国软件"下手"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3HRA1J0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3GBDK50514R9L4.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '出售TikTok！特朗普给了字节跳动最后时限：45天'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3GBDK50514R9L4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3DLBLA00018AOR.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '中国和三个邻国开会应对疫情 印度为何突然急眼了？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3DLBLA00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3CVHMA0519E14O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美强制出售中国公司！中国对策核心"内循环"咋搞?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3CVHMA0519E14O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3CGP5B0514R9OJ.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '福奇突然表态：中俄疫苗不可靠 美国不会依赖他们'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3CGP5B0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2KF19A0519814N.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '联合国警告!前所未有的粮食危机逼近 中国咋应对?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2KF19A0519814N.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3B5CDO051481US.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '张一鸣心中早有倾向？字节跳动深夜发声：面临困难'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3B5CDO051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ3AS2JQ052182V3.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '牛弹琴：大选前 ，特朗普给普京送了最后一份大礼'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ3AS2JQ052182V3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2RBQ410519APGA.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '监管障碍会更少？TikTok为何选择微软？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2RBQ410519APGA.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ38G7LC0514R9OJ.html',
 'pubtime': '9小时前',
 'real_pubtime': '2020-08-03 06:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '三姐妹残忍杀害熟睡的父亲 却有30万人请求释放他们'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ38G7LC0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2GTTCV00018AOR.html',
 'pubtime': '16小时前',
 'real_pubtime': '2020-08-02 23:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '白宫官员：美将于11月3日大选 此前特朗普提议推迟'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2GTTCV00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2EE50B05128ELF.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '巴西总统肺里长霉菌、妻子也确诊 还被起诉反人类罪'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2EE50B05128ELF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2BGUNS051996QS.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '太暴利！中国“可口可乐”准备上市 茅台要小心了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2BGUNS051996QS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ2BKRKU00018AOR.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子舞厅内救女孩被刺4刀未获感谢 将女孩告上法庭'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ2BKRKU00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1Q5Q4600258105.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '游说各国弃用华为后 美国给出一份“干净5G”名单'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1Q5Q4600258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2LSG8K002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '半年报业绩亮眼 海大集团获超百家机构调研'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2LSG8K002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2LSFFU002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '《八佰》历经400天再度定档 电影业复苏仍需时日'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2LSFFU002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2LSF2R002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '股市波动货币ETF规模激增 近三周增长380亿份'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2LSF2R002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2HCCMQ002580S6.html',
 'pubtime': '16小时前',
 'real_pubtime': '2020-08-02 23:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '今年A股净减持超3000亿！11人套现逾10亿元'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2HCCMQ002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2HCB9N002580S6.html',
 'pubtime': '16小时前',
 'real_pubtime': '2020-08-02 23:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '“孤品”TikTok：中国互联网出海头牌如何炼成的？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2HCB9N002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EHMVE0025817I.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '7月A股ETF资金净流出112.16亿元 军工类ETF大涨'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EHMVE0025817I.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EHGF300258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '资管新规过渡期延长符合预期 利好长期稳定资金入市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EHGF300258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EG3S900258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '郎酒IPO背后：扩产能缓销售 快慢间高端野心不减'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EG3S900258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3DAPG000258152.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '券商7月百强营业部王者归来 中信上海溧阳路重登榜首 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3DAPG000258152.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3D90E600258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '券商7月份揽入佣金211亿元 环比大增108% '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character ''' (0x27) at index 95
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3D7CGH00258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '银行二级资本债券发行热度不减 7月规模达415亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3D7CGH00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3D2BLA00258152.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '农产品“上网”半年考：零售小微企业订单上升 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3D2BLA00258152.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3D113900258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '精选层开市首周平稳运行 成交额占新三板76.48% '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character ''' (0x27) at index 97
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3BIMOQ0025817I.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '指数基金开发迎“新规” 引导行业高质量良性竞争'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3BIMOQ0025817I.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3GUL7T00259DLP.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '无惧实体清单 高盛狂买海康威视！看QFII持仓变化'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3GUL7T00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ29BAP8051482MP.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '考察归来后市委书记"狠批自己":已被人拉开、甩开'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ29BAP8051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ28QGFH051492T3.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子与女友分手上门讨钱遭拒 杀害女友奶奶和表妹'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ28QGFH051492T3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ25SHE90001899O.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': ' 杭州杀妻案楼栋住户忙搬家：总有点阴森森的感觉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ25SHE90001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ24N01N0001899O.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '江苏文科430分考生妈妈:港大主动邀请 给百万奖学金'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ24N01N0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1UFL4U0514D3UH.html',
 'pubtime': '21小时前',
 'real_pubtime': '2020-08-02 18:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '青海失联女大学生身亡 爷爷:她曾说明年春节再回来'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1UFL4U0514D3UH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1U0AIS0514R9OJ.html',
 'pubtime': '21小时前',
 'real_pubtime': '2020-08-02 18:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美TikTok用户放话:如特朗普真禁 大选时投票反对他'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1U0AIS0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1S1BKA055040N3.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美媒：如果拜登当选总统，美国外交政策或将剧变'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1S1BKA055040N3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1NM91B051481US.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普要封禁TikTok 美国年轻人“揭竿而起”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1NM91B051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1LPUND051481US.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美媒推测：封禁tiktok是因特朗普"感情受到了伤害"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1LPUND051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1JP27K00018AP1.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '日本导演：看到TikTok被美封杀 想起80年代的日本'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1JP27K00018AP1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUI9LSP052583KJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '辽宁的哥送客途中发现对方是密接者 操作引网友狂赞'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUI9LSP052583KJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1G0T3E05504DOH.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '英媒:印度在边境疯狂搞基建 但它不是中国的对手'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1G0T3E05504DOH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1FSEPK0514BQ68.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '近2/3美国人表示不满 民调显示特朗普陷四面楚歌'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1FSEPK0514BQ68.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1EQ1EU0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子将29颗磁力珠塞入尿道多日 医生:见过更可怕的'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1EQ1EU0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1EBH0N0534J2WK.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '车主违停20次称车贵以为城管不敢拖 网友:这算豪车?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1EBH0N0534J2WK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3GEP170025811R.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '8月3日股市内参早报：今有两只新股申购'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3GEP170025811R.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3FEHN300258152.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '最新中报业绩翻倍股出炉！这些股业绩与股价齐升 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3FEHN300258152.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3F7MLT00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股7月跑赢全球主要股指 后市将如何演绎？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3F7MLT00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3FJ46Q002580S6.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '银行股遇尴尬：股东高管买买买 公募基金卖卖卖'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3FJ46Q002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3KDRMQ0530I1ON.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '频繁投资 A股"扫货" 巨额发债！腾讯为何投资忙？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3KDRMQ0530I1ON.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3JRN0T0530I1ON.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '被罚后股价涨近130% 獐子岛"跑路的扇贝"回来了？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x7350) at index 83
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3J65BK0519D3BI.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '北斗三号升空背后：有公司400万蹭热点打水漂'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3J65BK0519D3BI.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3H5KG5002580S6.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '日本一季度GDP终值下降2.2% 民间资本开支遭下调'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x6c11) at index 88
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3FS9FI0511WT04.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '在线教育厮杀“暑期档”：烧钱、亏钱、欠钱'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3FS9FI0511WT04.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3DC19E0514BE2Q.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '涉案14亿 非法放贷暴力催债 公安局长竟是黑社会老大'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3DC19E0514BE2Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3CVHMA0519E14O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '美国强制出售中国公司！“内循环”该怎么理解？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3CVHMA0519E14O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2KF19A0519814N.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '联合国警告：前所未有的粮食危机在逼近！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2KF19A0519814N.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3EA0ES00259DLP.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '外汇局：将探索私募股权投资基金跨境投资管理改革'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3EA0ES00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3E2UNE00258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '420亿私有化方案出炉 海尔智家将"A+H+D"三股同行'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3E2UNE00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3DUHB300258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '经济复苏致钢铁需求回升快 新兴产业需求带来新机遇'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3DUHB300258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ3DSFG700258105.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '央行披露上半年贷款流向 未来将向这几个领域倾斜'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ3DSFG700258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1D7OP30001875P.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '失联女生遗骸找到 救援人员哽咽:缺氧或加速了死亡'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1D7OP30001875P.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ197KK30514R9L4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '中美关系已经"没有回头路"可走？刘晓明大使回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ197KK30514R9L4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ19162V055080L4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '台湾学者：美国其实希望中国大陆先“擦枪走火”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ19162V055080L4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ17VUK70001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '足疗店内一男一女遇害身亡 警方:女子已有三月身孕'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ17VUK70001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ137U7B051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美航母徘徊南海 少将承认:解放军曾逼近至可视距离'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ137U7B051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ1250KJ051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '香港面临一年“真空期” 媒体：中央或“另有打算”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ1250KJ051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ11N0LO00018AP1.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '中美无回头路?对英反制雷声大雨点小?驻英大使回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ11N0LO00018AP1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ106J310514R9P4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '女子11年前与丈夫独处时失踪 妹妹悬赏10万重新报案'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ106J310514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0VGBHT0001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '干部被曝出轨并家暴 妻子满身伤痕猝死后丈夫失联'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0VGBHT0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0V4ITI0514BE2Q.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '中科院90多人集体离职:科研人员与体制如何共享红利'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0V4ITI0514BE2Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0SI99M0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子3次跳河 痛哭：无论老婆和谁在一起，我都爱她 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0SI99M0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0SEH9F0519DDQ2.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': 'TikTok切割尚无定论 国内舆论集体为张一鸣"默哀"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0SEH9F0519DDQ2.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ08AP6005199A0B.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美国会对中国使用金融终极武器SWIFT吗？分析来了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ08AP6005199A0B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0RI4J8052182V3.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '牛弹琴:美国豪夺TikTok 目的是整垮中国企业的优势'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0RI4J8052182V3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2P1LRD0519DFFO.html',
 'pubtime': '13小时前',
 'real_pubtime': '2020-08-03 02:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '首度回应五道口闭店风波，昔日网红原麦山丘转型商超'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2P1LRD0519DFFO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2LL5N00539GTK1.html',
 'pubtime': '14小时前',
 'real_pubtime': '2020-08-03 01:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '“火箭蛋”归来，中国的物价能否控制得住？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2LL5N00539GTK1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1JMSOR0519D3BI.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '为什么TikTok不干脆退出美国？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1JMSOR0519D3BI.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1CTNQ000259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '海底捞张勇捞金离场?企业损失却靠银行挽救'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1CTNQ000259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1RSON500259DLP.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '马云给企业家20个建议：永远要准备三年的钱'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1RSON500259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ109HHD00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '迎来曙光!近30省份明确原油宝事件受理法院'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ109HHD00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0VCTMU00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '不符合这5要求打不了新股!创业板注册制来了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0VCTMU00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ29NLHB00258105.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '股民心慌！TikTok在美国深陷困境 这些概念股小心'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ29NLHB00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ237GFQ002580S6.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '十大券商策略：8月是布局A股下一轮上涨重要窗口'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ237GFQ002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1Q5Q4600258105.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '游说各国弃用华为后 美国给出一份“干净5G”名单'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1Q5Q4600258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ11SP2F00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '1999元无限次飞全国 "同程任我飞"刚要发售突然叫停'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ11SP2F00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0TKSQT00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '"币圈余额宝"400亿"惊天大案"!200万人陷币圈传销'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0TKSQT00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0TH2KF00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '退市前涨停了!13万股民沸腾:明明是火坑 谁在设局?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0TH2KF00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0QGAJ90001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': 'Tik-Tok为什么要被强制卖给微软？背后有更深层原因'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0QGAJ90001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0QEGSD0001875O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '胡锡进:TikTok遭围猎 中方能采取的反制措施很有限'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0QEGSD0001875O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FJ0EOMOJ0519W8KP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '离婚男刷爆信用卡欠160万债务 留言前妻:你想办法还'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FJ0EOMOJ0519W8KP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVQ0FTI00018AP1.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '她去可可西里就是为了死？警方：发现时只剩骨骸'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVQ0FTI00018AP1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVLCB0D0001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '专家:对中国数千亿级美元的"掠夺盛宴" 正在美发生'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVLCB0D0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVJJOL7051484BP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '中国14亿人被监视、压迫和恐吓?侠客岛驳斥蓬佩奥'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVJJOL7051484BP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVJ69RR0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '后悔晚了!被通缉后乱港分子称早就不主张"港独"了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVJ69RR0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVHFEEF051482MP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '释放啥信号？军科院战争研究院院长走进中南海'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVHFEEF051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVDIIN60514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '不爱戴口罩的美国议员疯狂追问，把福奇都整笑了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVDIIN60514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVDB62E05504DP0.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '美媒怒揭:我国本有改变命运大计划 被特朗普家废了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVDB62E05504DP0.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVCD5130514DTKM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '"中国纸箱上有病毒！"澳男子一把火烧了自家超市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVCD5130514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVCCU0I0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '又来骗钱！黄之锋卖惨众筹：我被人跟踪，要请保镖'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVCCU0I0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVCCU3V0514DTKM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '德专家:中企并不照搬德企技术 更注重现有科技创新'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVCCU3V0514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIVBERU50512DU6N.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '福奇再现身国会：为中国仗义执言 被不实流言傍身'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIVBERU50512DU6N.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIV9FCP40001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/news',
 'title': '舆论称中国奶业走上不可挽回的歧路?官方:居心叵测'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIV9FCP40001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:26 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0T6QCP00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '1块钱起拍的豪宅来了!想捡漏先看自己有没有500万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0T6QCP00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0RTD4A00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:26',
 'source': 'https://3g.163.com/touch/money',
 'title': '数据揭示真相!从"超级小散"到"超级大散"都在亏钱'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0RTD4A00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1PVCGR00259DLP.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '日产巨亏拖累雷诺：去“戈恩化”的联盟路在何方？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1PVCGR00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1QTBTO002580S6.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': 'AppStore下架2.6万款游戏 苹果和开发者何去何从'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1QTBTO002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1QCR2600258105.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '日本导演：Tiktok被美国封杀 我想起80年代的日本'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1QCR2600258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1QDT8D002580S6.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '城中村租房的大学毕业生:750元广州能合租两房一厅'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1QDT8D002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FIUG5AAA0519D4UH.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '蒙古9月分批向中国运送30000头活羊！该国有3230万头'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FIUG5AAA0519D4UH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2EAG20002580S6.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '央行披露上半年贷款流向 未来投资向这几个领域倾斜'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2EAG20002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2E4U8I002580S6.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '科创实力加速城市洗牌：南京超天津 跻身全国十强'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2E4U8I002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ295HBQ00259DLP.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '央行周末大利好 下周A股怎么走？十大券商最新研判'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ295HBQ00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ265L2H00259DLP.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '以耻为荣！美国亮出全球追杀华为战果'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ265L2H00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ24QJ7V002580S6.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '机构预期降准降息幅度将会变小 股债性价比趋于平衡'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ24QJ7V002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ24QIC6002580S6.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '钱都去哪了？上半年新增贷款超12万亿'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ24QIC6002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ23KM0P00259DLP.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '美TikTok用户放话:如特朗普真禁 大选时投票反对他'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ23KM0P00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ23ATER00258105.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '特朗普刚开口 澳大利亚立马调查TikTok'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ23ATER00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIV4IQ49051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '港媒：中央出钱出人，为全港市民免费检测！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIV4IQ49051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIU0EO9I0514D849.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '周小平:传美领馆欠薪欠补 蓬佩奥谎言令美颜面扫地'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIU0EO9I0514D849.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRAUN0705345ARG.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '西瓜摊主去救人，瓜全被城管搬走！结局让人想不到'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRAUN0705345ARG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUV4DKJ05504DPG.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普打算直接下死手!称将动用总统权力封杀TikTok'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUV4DKJ05504DPG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUTALSP0519D4UH.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普明抢？抖音海外版不卖就封杀？字节跳动回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUTALSP0519D4UH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUSQJFD055040N3.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '中美又现摩擦上海举行战备演练要打仗了?官方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUSQJFD055040N3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUSBJMP0514EGPO.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美国首位换脸人去世 曾被丈夫散弹枪轰脸留狰狞面容'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUSBJMP0514EGPO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUQDKFF0524AOBI.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '脸书总裁公然反华 曾经大秀中文过年还包饺子'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUQDKFF0524AOBI.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUQI0BI05219MM0.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '富二代听妻子出轨传言 砍妻子20几刀致其当场死亡'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUQI0BI05219MM0.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUNVH6M0514BE2Q.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '取消收了20年的服务费 全聚德：到了非改不可的地步'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUNVH6M0514BE2Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIULMHAC00018AOR.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普：我可以动用行政命令禁止TikTok在美国运营'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIULMHAC00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUJTMNK05504DOH.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '印度阵风战机对中国歼-20有机会赢？美媒泼冷水'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUJTMNK05504DOH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUJIPBJ05504DOH.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美司令：中国很快会部署激光武器 用激光打美国卫星'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUJIPBJ05504DOH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUJEFLU0514R9OJ.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '超暖后续！司机冒死开起火货车驶离闹市，获赠新车'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUJEFLU0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUH1GMM0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '逃往伦敦后 乱港分子罗冠聪宣布与香港亲人断绝关系'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUH1GMM0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ23MOTO002580S6.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '7月新基金发行最火爆！5389.4亿元规模创历史纪录'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ23MOTO002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ223H4L002580S6.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '41股获机构调研！7家百亿私募现身 1股已五连板'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ223H4L002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ20RPR2002580S6.html',
 'pubtime': '21小时前',
 'real_pubtime': '2020-08-02 18:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '浙江发生一起企业安全生产事故 致2人死亡6人受伤'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ20RPR2002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1TIT64002580S6.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '深圳发细则补充“715新政”： 房价“涨价即下架”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1TIT64002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1PS8A1002580S6.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '二季度GDP重挫三成 为什么美股没有“二次探底”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1PS8A1002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1N9ETD002580S6.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股周一见 新基将驰援A股 谁会是8月主战场？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1N9ETD002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1MTJJ800258105.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '最后一个月！这次重要的二选一将决定你以后房贷'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1MTJJ800258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1QDQ0K002580S6.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '美只是TikTok全球第二大市场 下载量让特朗普怕了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1QDQ0K002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ16DRTN00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '全国门店超5000家 这家知名药房却因卖劣药被罚'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ16DRTN00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ10EU4K00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '引国资重组？财务造假300亿的康美药业或将重生'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ10EU4K00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0TVE5P00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '6连板英特集团遭重点监控 小股民煎熬:还没解套呢'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0TVE5P00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0TOPSM00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '微软暂停收购TikTok 美国区总经理：我们不会离开'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0TOPSM00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ107G5R00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '暑期赢回"宅"的你！机票1折、门票免费、夜市开启'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ107G5R00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1040D000259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '断供、逾期之后车被拖走  消费者冤不冤？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1040D000259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUGTNO80001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '李登辉的最后三天：临死前，身边只有一名军队人士'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUGTNO80001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUG39KB0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '林郑月娥:对于美国要制裁本人 我一笑置之嗤之以鼻'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUG39KB0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUFUJO7051481US.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '福奇在听证会上力挺中国！现场画面曝光：有理有据'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUFUJO7051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUFFV0Q00019B3E.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '政治谎言被戳穿！蓬佩奥公开承认：建反华联盟太难'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUFFV0Q00019B3E.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIUDRDFL0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '宋楚瑜为什么要哭祭李登辉？两人曾有深仇大恨'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIUDRDFL0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITCCOB605346RC6.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '一场持久战！中央政治局会议透出深意 信息量巨大'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITCCOB605346RC6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIU95GC00001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '乱港分子要对驰援医护下手？工会急呼：不来抢饭碗'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIU95GC00001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIU87IB40001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '蓬佩奥宣战演讲 标题：共产主义中国和自由世界未来'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIU87IB40001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIU7QEBI00019K82.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '铁笼沉尸监控画面曝光：有人看到他本人搬运铁笼子'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIU7QEBI00019K82.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/special/S1592302260716.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '继续挑衅?印媒称印度准备向中印边境增兵3.5万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/special/S1592302260716.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITIM9TG0514AD1K.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '武汉护士坠楼 其母：事发前女儿在备孕 不可能自杀'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITIM9TG0514AD1K.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIU5R9Q30514R9OJ.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '林郑月娥作出7个月来最艰难决定！反对派人士跳骂'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIU5R9Q30514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIU0IT5P05259Q0E.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '蒙古国的三万只羊即将到货 除了涮肉还能干什么？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIU0IT5P05259Q0E.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITU17PU0519QIKK.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '突发！美媒：微软正在谈判收购TikTok美国业务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITU17PU0519QIKK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0UEEAV00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '胡锡进:华为和TikTok让华盛顿心神不宁的是这种能力'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0UEEAV00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0T9H7600258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '城市经济排位赛:郑州GDP增速为什么没有"转正"？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0T9H7600258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0S20M700258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '铁矿石再遇狂飙之夏:价格升至近5年新高意味着什么'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0S20M700258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0RMKCD00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '没有大妈的"黄金列车":80后90后进场 上车还是等等?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0RMKCD00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0QFOP900259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '字节跳动剥离TikTok美国业务 微软或接管'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0QFOP900259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0USSRJ00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '"00后"加入"抗老"大军？国产护肤品牌高端化危与机'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0USSRJ00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0UPF8300258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '被抖音取消合作后股价跌停 宝通科技又遭深交所问询'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0UPF8300258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0UABL2002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '受疫情影响 南美航空公司将裁减至少2700名机组人员'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0UABL2002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1NCDOR002580S6.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '银价7月涨超30％仍被低估？后市将跑赢黄金？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1NCDOR002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1MR16E00258105.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '韩国人"花式消毒"钞票：放微波炉加热 丢洗衣机洗'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1MR16E00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1MP1LS00258105.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '8月“中报季”哪些行业已被提前布局？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1MP1LS00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1MND6700258105.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '7月大宗交易热火朝天：两只保险股惊现大幅溢价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1MND6700258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1I1NOL00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '银行股又迎尴尬时刻!公募疯狂减持 高管却在买买买'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1I1NOL00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HR4L600259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '钱太多！7月超2400只私募产品备案 基金经理犯难了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HR4L600259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITMCECU0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '林郑月娥：除非使用“核手段” 否则都可以应付！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITMCECU0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITLO6IE0519DGP6.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '中央会议定调！内循环带来大震动 这些地方要起飞了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITLO6IE0519DGP6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITETQBA0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '浙大深夜通报：犯强奸罪学生努某某被开除学籍'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITETQBA0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITEKH0R0516FC9F.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '"中国好女婿"扎克伯格 祭出了对中国的终极杀器'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITEKH0R0516FC9F.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT9BCN405504DPG.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '香港立法会选举推迟一年 乱港分子为何如遭雷击？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT9BCN405504DPG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT5F3RA0530U7LS.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '女子想向父亲讨回拆迁款 父亲甩出"无精症"化验单'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT5F3RA0530U7LS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT4N8770549LATK.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '来女士所在小区：住户纷纷搬家，夜晚楼内漆黑一片'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT4N8770549LATK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISQ8BID05504DP0.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '民调:美反华情绪泛滥 7成人认为美应插手中国事务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISQ8BID05504DP0.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISND9660001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '写《平安经》的吉林省公安厅副厅长被免'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISND9660001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISNCQM80001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '两干部灌醉女同事后乱性？男方：啥都没干 只喝了酒'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISNCQM80001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FITA2HH9051481US.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '印度：3千多确诊病例离奇失踪 方舱医院发生强奸案'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FITA2HH9051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT63UDV0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '港媒：港警正式通缉罗冠聪等6名逃往海外乱港分子'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT63UDV0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT55V0J0514R9KD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '坠楼护士亲属：医院说监控坏了 没人知道发生什么'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT55V0J0514R9KD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT5675N0001899O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '中国政府利用香港国安法进行"政治清洗"？中方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT5675N0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HN44100259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '一个月350多家机构涌入这家公司 股价能不涨吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HN44100259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HHIDM00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '北上资金出逃股名单来了！4000亿免税巨头遭大减持'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HHIDM00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1H8DED00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '壕!7月融资客北向资金加仓超2400亿 这些股票被抢筹'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1H8DED00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1H2GL100258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '金银价格突破重要整数关口 飙涨后还有多少空间？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1H2GL100258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HD5IQ002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '苹果股价暴涨！美股高价股“拆股潮”即将到来？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HD5IQ002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HD8JC002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '马斯克赌赢了！特斯拉成为疫情下汽车业最大赢家'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HD8JC002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1ENFMR002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '理财顾问违规炒股近1年半 亏损近9万罚3万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1ENFMR002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HDBPC002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '北上资金出逃股名单来了!4000亿免税巨头遭大减持'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HDBPC002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1ET6TR002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '深圳叫停商务公寓后 城市更新住宅比例有望增加'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1ET6TR002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1CRFCS002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': 'TikTok美国业务命运未卜 A股小伙伴们影响几何？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1CRFCS002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ178H3S002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '城市居民如何合法获得农村宅基地？暂时只有这两条途径'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ178H3S002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ17OGUG002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '恒瑞医药营收、净利增速下滑 股权激励计划能否奏效？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ17OGUG002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0VG2SM00259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '首批私募巨头持仓曝光！高毅正心谷礼仁买了这些股'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0VG2SM00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0V0BNB00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '华联股权纠纷遭深交所关注 杭州锦江被指隐瞒实控人 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0V0BNB00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0V4U6L002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '筋膜枪被托上"神坛":"打"退颈椎病 还能减脂塑形'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0V4U6L002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIT10EUN0514R9OJ.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '蓬佩奥:我们在引领世界意识到中共威胁 形势在逆转'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIT10EUN0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISUP2KL0530L4D3.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '令基层护士"颤抖"的护理部 究竟是怎样的存在'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISUP2KL0530L4D3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISTOVB8051484BP.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '背叛者李登辉：曾两次加入中国共产党'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISTOVB8051484BP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISRSLC80519D9A7.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '中国企业赌在越南：用一条微信就能谈起上亿的生意'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISRSLC80519D9A7.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISPQAV000018AOR.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '江苏文科第一名无缘清北 港中大:未达最低提档要求'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISPQAV000018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISORVO205148UNS.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '杭州杀妻者16年前曾受访 记者回忆：模样像个官员'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISORVO205148UNS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISMTNI40514R9P4.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '"五人出游一人还"生者解释:为何将死者遗体放冰柜'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISMTNI40514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISLN8A20534LTRH.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '推迟大选能赢？GDP创1947年最大跌幅 特朗普慌了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISLN8A20534LTRH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISL2KOU051481US.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '大转弯！日方：没有派人出席李登辉葬礼的计划'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISL2KOU051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/special/S1596110883100.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '蓬佩奥对李登辉病亡表示哀悼 中方:不要发错误信号'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/special/S1596110883100.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISIC9SU00018AOR.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '蓬佩奥称"美国做好了带头对抗中共准备" 中方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISIC9SU00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISG59C9055040N3.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '受贿超7亿妻子涉案 陕西原书记赵正永受一审获死缓'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISG59C9055040N3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FISED9D200019B3E.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子沉尸铁笼被排除他杀 知情人:自己定制200斤铁笼'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FISED9D200019B3E.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQNT2UP05199A0B.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '中国被迫启动经济内循环会怎样？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQNT2UP05199A0B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIPEDQDQ053770WR.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '白宫智囊余茂春被网民骂"汉奸" 重庆母校对其除名'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIPEDQDQ053770WR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0SEHIL002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '被动抗争!TikTok切割尚无定论 但已被集体"默哀"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0SEHIL002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0RQR6O00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '巴基斯坦蝗灾防治新进展 中国无人机飞向治蝗一线'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0RQR6O00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0ROKT400259DLP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '苹果下架中国区3万款应用 这一行要变天'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0ROKT400259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ01Q38T002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '字节跳动同意剥离TikTok 中国互联网出海标杆折戟'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ01Q38T002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1LBP2B00258105.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '不管就卖 曝光就删！二手电商成违禁品隐秘的角落'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1LBP2B00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1L7U1H00258105.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '北京租房补贴标准8月起提高！谁能领 领多少？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1L7U1H00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1HD7EN002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '美元疯狂贬值后 数字货币起飞了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1HD7EN002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ178BV5002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '经济复苏致钢铁需求回升较快 新兴产业需求带来新机遇'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ178BV5002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ1CRFNV002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '下周二创业板注册制来了 一图看懂规则变化'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ1CRFNV002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ17P70E002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '法拉利、迪士尼等将公布业绩 财务数据或出现较大变动'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ17P70E002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ17KNGS002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '针对特朗普停止运营威胁 TikTok美国总经理:不会离开'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ17KNGS002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0V3QCI00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '无力支付房租!美国超1730万户家庭恐被"扫地出门"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0V3QCI00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0SHV5K00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '股东不相信牛市?7月减持家数与金额创今年新高'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0SHV5K00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ07S949002580S6.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '医保目录调整 8类药品直接出局'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ07S949002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2AME06002580S6.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': 'A股7月跑赢全球主要股指 后市将如何演绎'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2AME06002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQ6CS2D0514EV7Q.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '正厅级官员拥36套房谎称无房 "隐形房叔"如何炼成？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQ6CS2D0514EV7Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRVVHAP00019B3E.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '洪秀柱评李登辉病亡：希望台湾价值混乱时代结束'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRVVHAP00019B3E.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRUVOF0051482MP.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '官方证实：解放军新型轰炸机入役 训练打击海面目标'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRUVOF0051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRU5D8Q0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '李登辉最后时刻：无人敢提拔管 妻子做最后决定'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRU5D8Q0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRMNE5C0515DN7K.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普要轰炸中国黄岩岛？日媒曝光美军绝密计划'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRMNE5C0515DN7K.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRSQJ1N0519AQ5J.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '"新冷战"要来？澳大利亚怯了，日本却开始起变化'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRSQJ1N0519AQ5J.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRTFMQD0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '90后小伙带狗黄河漂流41天 直播40天涨近15万粉丝'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRTFMQD0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRSO6D70514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '一份直接威胁中国的“重磅密件” 美澳为何不公开？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRSO6D70514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRS17F800018AP1.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '揭秘李登辉上位史：美国暗中操控，逼迫蒋经国用他'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRS17F800018AP1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRPTFMN0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美媒：蓬佩奥试图挑动中美对抗，但中国没有上当'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRPTFMN0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRPH32G0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '印度大肆购买战斗机针对中国？外交部只回了一句话'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRPH32G0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRP0JH70001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '刘晓明:英国不要被美胁迫 中国不承认香港BNO护照  '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRP0JH70001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRONBCM0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '河中发现男性尸体被装在不锈钢笼中 警方:排除他杀'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRONBCM0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRO6UCD0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '抢劫运钞车嫌犯官至副局长 家属：死者太阳穴有枪伤'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRO6UCD0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRNNSLR0514R9P4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '女大学生16年前神秘失踪 一处花坛里发现其私人物品'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRNNSLR0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2AH7VM002580S6.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '禁止TikTok将加剧美国科技企业垄断格局'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2AH7VM002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2A8VB5002580S6.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '中国版集体诉讼启航“康美们”迎投资者索赔大时代'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2A8VB5002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ2B603M002580S6.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '深莞调控后惠州成交量猛增 库存高企土地供需两旺'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ2B603M002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ28ONRR002580S6.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '如果不得不卖 微软是TikTok最合适的美国下家'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ28ONRR002580S6.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0T86HU00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '公募初战精选层小胜 部分机构发力抢赛道 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0T86HU00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0T6G8F00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '募资项目一再变更 部分募资转用还债 海南海药受关注'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0T6G8F00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/money/article/FJ0SUFPD00258105.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/money',
 'title': '保额缩水 条款被改 太平财险被点名揭开哪些潜规则?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/money/article/FJ0SUFPD00258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRND2F700019B3E.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '31省区市新增确诊127例 其中新疆112例辽宁11例'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRND2F700019B3E.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIP0TEDS05198O06.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '全美27州收不明种子，标签写"中国邮政"，中方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIP0TEDS05198O06.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIRC7BFI0512DKHT.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '"天问一号"后美国"毅力号"升空 谁会率先抵达火星'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIRC7BFI0512DKHT.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQSKUVF0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '当心！美国联邦调查局的触角公然伸过来了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQSKUVF0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQJERQK0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普突然"提议"推迟大选 美媒:他无权单方面决定'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQJERQK0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQH0BA50001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '李登辉病亡 胡锡进：他一定在中国历史上遗臭万年'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQH0BA50001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQG5IVJ0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '台湾当局前领导人李登辉病亡 医院披露死因'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQG5IVJ0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQ9VDUH0512GTK3.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '女生过敏 校长张口就骂：回家嫁个男的，种地生娃'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQ9VDUH0512GTK3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQ7JJ2R053469M5.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '男子劝架后获刑2年：涉事者拿刀追砍他 19天后身亡'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQ7JJ2R053469M5.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQ74JPF0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '河北抢劫运钞车案嫌犯官至副局长 知情人透露细节'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQ74JPF0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIO3AAAI0514CQIE.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '支付宝被美团"捅了一刀"！两家企业9年恩怨被重提'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIO3AAAI0514CQIE.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIQ0GNFH0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '群众出版社：出版《平安经》造成不良影响 将严查'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIQ0GNFH0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIN9FVJP0512DKHT.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '拜登副手将露面 重要性或超美史上所有副总统候选人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIN9FVJP0512DKHT.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIN8PV9J0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': 'CNN：中国战机真够拼 日本都没有喘息机会'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIN8PV9J0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIMSQ62K055080L4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '台军事专家：只要大陆决定开打，台湾几乎就已输了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIMSQ62K055080L4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/video/VZHN7FT0M.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '杭州遇害女子大女儿删除10天前发的帖子'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/video/VZHN7FT0M.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILNSU5005129QAF.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '江苏文科状元无缘清北:比起后悔 更重要是接受缺憾 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILNSU5005129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIN046AM05129QAF.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '女子4年前失踪 丈夫用两理由拖了1个月才告知家属'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIN046AM05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIKVVCJE05345AQP.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '杀妻案牵出另一悬案，16岁女孩为何死亡？警方回应 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIKVVCJE05345AQP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILISNHO05504DP0.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '计划迫使中央宣布香港进入紧急状态的黑手被铲除'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILISNHO05504DP0.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIMLSO7C0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美国号召“讨伐中国” 韩国：抱歉这次我不跟了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIMLSO7C0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIMHFNCO052182V3.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '最荒唐一幕发生了，美国军火商正在偷着乐！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIMHFNCO052182V3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIMG4VK90001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美称中国驻休斯敦总领馆外交官为特工 中方揭事实'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIMG4VK90001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILKIR0B051481US.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '英国外相：英方不赞同全面“重置”英中关系'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILKIR0B051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILBAJ5Q0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美国严防部分中国种子在本土生长 易造成侵入危害'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILBAJ5Q0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIKOI0U30515TDAO.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '许某某反侦察能力强：警犬在现场嗅不到来女士气味'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIKOI0U30515TDAO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIKK6U8I00018AOR.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '江苏高考文科第一名选修B+ 清华北大南大：无法录取'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIKK6U8I00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIJRAFME0517N3J7.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '美国多地居民收到未知种子 袋上印有"中国邮政"标志'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIJRAFME0517N3J7.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILGEB9H0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '律师谈杭州杀妻案嫌犯：判死刑立即执行概率大'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILGEB9H0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILFLKKU0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '菲律宾总统请求中国先给新冠疫苗 外交部回应了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILFLKKU0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILE4A93051482MP.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '“乱港军师”被解雇 梁振英：监狱在等着他'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILE4A93051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FILAEUR00514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '非法“占中”发起人之一戴耀廷被港大解雇'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FILAEUR00514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/news/article/FIL92R1705504DP0.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/news',
 'title': '特朗普:美国很快击败新冠病毒，并将进入"黄金时代"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/news/article/FIL92R1705504DP0.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://3g.163.com/touch/#/recommend via http://localhost:8050/execute> (referer: None)
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3RALRO000189FH.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '这个郑重承诺，习近平反复提及 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3RALRO000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3RBQ18000189FH.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '调动广大农民积极性、主动性、创造性'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3RBQ18000189FH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://3g.163.com/touch/#/recommend>
{'link': 'https://3g.163.com/all/article/FJ1JAKFR0514CQIE.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '明确了！医保这些都不可报销'}
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://g.163.com/c',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '限时享3年7.5折保值回购'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://g.163.com/c' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3CFUP70001899O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '台湾真想打一场战争？绿媒：中美必有一战 大陆会败'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3CFUP70001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISGPPEB0548LQEQ.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '下半年运势逆转，好事成双的3星座，事业和爱情一帆风顺'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISGPPEB0548LQEQ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://3g.163.com/touch/#/recommend>
{'link': 'https://3g.163.com/all/article/FJ242A8M0546A151.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '梦幻十大鬼区，最鬼的区只有几十个人在玩，世界频道可以聊天'}
2020-08-03 15:15:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://3g.163.com/touch/#/recommend>
{'link': 'https://3g.163.com/all/article/FJ2TV50Q0534HFB2.html',
 'pubtime': '12小时前',
 'real_pubtime': '2020-08-03 03:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '苏联巅峰的模样正被世界遗忘'}
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1595227652798n56Vq.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '在北京种牙不花冤枉钱！收费透明，在线获取报价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1595227652798n56Vq.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ003RES0543B9SS.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中国唯一的混血族群：欧洲人后代，却说着纯正的粤语'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ003RES0543B9SS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISS4PK305444GZJ.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '你看到《向往的生活》周迅的聪明吗？不会是黑色的'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISS4PK305444GZJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0G3I6Q05490OL8.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '在国超收藏之后，任嘉伦已经出国做超级文案了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0G3I6Q05490OL8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1P1SN10514R9P4.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '派出所所长跳桥身亡 曾嘱托妻子别让孩子当公务员'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1P1SN10514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0VFKUJ00097U7S.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '三星电子关闭在华最后一家电脑厂 约850名员工受影响'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0VFKUJ00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0NFPQL05118H7J.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '三星苏州电脑产线将迁至越南，或掏空苏州及周边产业链，员工补偿方案不如惠州工厂'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0NFPQL05118H7J.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0Q0QD105373U0A.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '此生无悔入华夏，来世不做河南人——2020高考一河南考生的心声'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0Q0QD105373U0A.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2PRJS00536GLHX.html',
 'pubtime': '13小时前',
 'real_pubtime': '2020-08-03 02:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '反转！江苏文科女状元获港大1000000奖学金，这个B+价值连城'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2PRJS00536GLHX.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://ob.laishijialaojiu.com/laishi.htm',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '20元抢1箱53°茅台镇酱香酒，每人限购一箱！手快有。'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://ob.laishijialaojiu.com/laishi.htm' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ234IKV0514WIJ2.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '【最新通报】武汉协和护士坠楼事件，疑似同事爆料出更多幕后信息！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ234IKV0514WIJ2.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ265J5I0514FQ27.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '乌鲁木齐市政府紧急向市民发放连花清瘟胶囊！关于连花清瘟胶囊，这些你一定要知道！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ265J5I0514FQ27.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1DB5MQ0514Q0KM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '男子杀人后逃跑 藏深山与世隔绝18年：养狗放哨'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1DB5MQ0514Q0KM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2BJKDJ051482MP.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '厅官怀疑情人与企业老板搞暧昧 向该老板索要200万'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2BJKDJ051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t北京植发3000单位需要多少钱？费用怎么算？查看价格表\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIV3UDEH0535J856.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中山2020年GDP下降6.5%，再次全省倒数，该拿什么来挽救你？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0xff0c) at index 87
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ25FRV005369A52.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '负气出走还是自我挑战？江苏文科女状元选择香港大学，刺痛了谁？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ25FRV005369A52.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ20J31C05503FCU.html',
 'pubtime': '21小时前',
 'real_pubtime': '2020-08-02 18:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '多次猥亵儿童仅行拘15日获改判，"最牛改判"十年有期徒刑改无期'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ20J31C05503FCU.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2EOJCP05444M88.html',
 'pubtime': '16小时前',
 'real_pubtime': '2020-08-02 23:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '白湘菱去哪儿？孤注一掷申请港大，430分女状元突然就不香了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2EOJCP05444M88.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1U0AIS0514R9OJ.html',
 'pubtime': '21小时前',
 'real_pubtime': '2020-08-02 18:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美TikTok用户放话:如特朗普真禁 大选时投票反对他'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1U0AIS0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ25BTIO0514R9OJ.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '青岛崂山现大量北极狐、银黑狐 有的断腿有的缺耳朵'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ25BTIO0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3U1UBR000887BT.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '每日易乐:这车咋开的 不知道保护弱势群体吗?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3U1UBR000887BT.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1EQ1EU0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '男子将29颗磁力珠塞入尿道多日 医生:见过更可怕的'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1EQ1EU0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1595227652798n56Vq.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '在北京种牙不花冤枉钱！收费透明，在线获取报价'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1595227652798n56Vq.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ137U7B051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美航母徘徊南海 少将承认:解放军曾逼近至可视距离'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ137U7B051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1AK3QP05500MQX.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '11人中毒1人死亡！广东一肠粉店疑发生食物中毒事件'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1AK3QP05500MQX.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ26GP6P0534J2XC.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '高速公路限速忽高忽低？广东将开展大排查'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ26GP6P0534J2XC.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3H2SQ50536KRKY.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '浙江大学山东大学表态：拒绝招收白湘菱！结果被网友喷了！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3H2SQ50536KRKY.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2INA3H05361PTA.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '江苏文科状元白湘菱花落港大，获百万奖金，也许这是最好的结果'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2INA3H05361PTA.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1FSEPK0514BQ68.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '近2/3美国人表示不满 民调显示特朗普陷四面楚歌'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1FSEPK0514BQ68.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1IRCCO0514R9P4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '“福建男子被跨省拘捕后获国家赔偿”续：警方决定终止侦查'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1IRCCO0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1NJR9K0512B07B.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '刚刚，SpaceX载人龙飞船启程返回地球！“送100万人上火星”，马斯克的SpaceX比特斯拉还值钱？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'title' at row 1")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISUITRD0512B07B.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '日本从辉瑞处订购1.2亿剂新冠病毒疫苗，未透露具体金额'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISUITRD0512B07B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3C1BG800258105.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中储粮回应“禁带手机入库区”:严厉批评'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3C1BG800258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ176UQA0514R9P4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '急！印度朋友在微信上问我借钱，现在微信被封失联了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ176UQA0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIS3H75A0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '大连市疾控中心：大连全民核酸检查发现更多无症状感染者'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIS3H75A0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3C89SD00259DLP.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '国有粮库空仓近一年无人发现?揭硕鼠四大贪腐手段'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3C89SD00259DLP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3MGUQR00097U7S.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '北斗系统28nm工艺芯片量产 大部分智能手机支持北斗功能'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3MGUQR00097U7S.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIP9VIQL0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '伊朗革命卫队围攻夺取“美航母”，美国海军选择用“嘲笑”来报复！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIP9VIQL0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISTVSRF0514EGPO.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '伊朗抓了17名美以间谍！美国中情局对伊朗渗透究竟有多深'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISTVSRF0514EGPO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVFKG1F0512B07B.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '达成协议！美军将永久性驻扎波兰，波兰方面曾提议以特朗普命名军事基地'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVFKG1F0512B07B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIOSUHH20514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '港媒：黄河正处于500年来最清澈状态？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIOSUHH20514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIQCDB7U0545971M.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '钱钟书数学15分敲开清华的门，白湘菱B+推不开，这才是“历史”？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIQCDB7U0545971M.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ172FV70519DDQ2.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '“龙飞船”返程！两名美国宇航员结束国际空间站任务'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ172FV70519DDQ2.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ29BAP8051482MP.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '考察归来后市委书记"狠批自己":已被人拉开、甩开'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ29BAP8051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:27 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUPD6BM000887BT.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:27',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '每日易乐:这车贴我仔细观察了11秒才看明白'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUPD6BM000887BT.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1N51V70514R9P4.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '空军原司令员王海上将逝世，曾在抗美援朝时击落击伤9架敌机'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1N51V70514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVHR1N2051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '澳大利亚驻印大使向印度外交部表态，澳媒：在中印边境冲突中支持印度'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVHR1N2051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ265RPR05129QAF.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '搜捕数月逮到一只“亚洲巨型杀人蜂”，但华盛顿州时间已经不多了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ265RPR05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISIB9RA0514R9P4.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '伊朗首次公开地下发射导弹 专家：美国可能早就知道'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISIB9RA0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUI9LSP052583KJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '辽宁的哥送客途中发现对方是密接者 操作引网友狂赞'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUI9LSP052583KJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3EOUAL00018AOR.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '微软宣布继续收购TikTok计划 谈判最迟9月15日完成'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3EOUAL00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FITAD1KC05199NPP.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '减租50%仍留不住租户！“亚洲最赚钱商场”收入锐减30%，空置率创新高！业主：“不能单方面拯救地球”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0x4ecd) at index 76
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2DJTIB0514FGV8.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '污名化中央支援香港抗疫，又蠢又坏！｜香港一日'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2DJTIB0514FGV8.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0TNDND0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '紧急提醒：近期食用河粉注意！已有11人中毒，1人抢救无效去世！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0TNDND0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0SPPHV0001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '豪华别墅每天大量“女模”进出 警方调查发现大秘密'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0SPPHV0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIP2PGP30517O41O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '对于方方这样的作家，对于《方方日记》，怎么看？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIP2PGP30517O41O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ20FU9L051481US.html',
 'pubtime': '21小时前',
 'real_pubtime': '2020-08-02 18:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '特朗普刚开口，澳大利亚立马调查TikTok'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ20FU9L051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1K6KNP051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '拍摄武汉抗疫纪录片的日本导演：看到Tiktok被美国封杀，我想起80年代的日本'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1K6KNP051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1PF5DO0514R9OJ.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '国家队来了！核酸检测“先遣队”抵港，市民挥国旗欢迎'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1PF5DO0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3CGP5B0514R9OJ.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '福奇突然表态：中俄疫苗不可靠 美国不会依赖他们'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3CGP5B0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIOG8FCO0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中美两军一项关键规则告急！专家：已不够管控风险'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIOG8FCO0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVSSSHK0001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '女大学生青海失联近20天遗骸被找到 搜救画面曝光'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVSSSHK0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ40J7F20515TDAO.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '失踪女大学生死亡:南京某大学"6朵金花"其中1朵凋零'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ40J7F20515TDAO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1DNE9Q0534KDG3.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '江苏高考新方案定了！总分750分，科目“3+1+2”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1DNE9Q0534KDG3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FINSHKPS0524W65T.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '桂林“最霸道”景点：将山遮住不给看，当地人：曾经的骄傲变耻辱'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FINSHKPS0524W65T.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIPQE5RJ0514R9OJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美军机现身东海南海，鼓噪战争威胁金一南：谁敢攻击必令其加倍付出代价！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIPQE5RJ0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ27K9890514R9OJ.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '澳大利亚维多利亚州进入“灾难状态”，特朗普却直接甩锅中国，网友不留情面反驳！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ27K9890514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISBOQCP0514R9P4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '蓬佩奥：对伊朗实施新制裁，限制“金属和其他核武材料”进口'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISBOQCP0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ23BPUD05129QAF.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '7岁女童商场偷玩具，亲妈报警教育孩子，引网友热议，话题上热搜'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ23BPUD05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIPAKTRU0517R8EB.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '出江苏数学题的葛军到底是怎样的一个人？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIPAKTRU0517R8EB.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUSON1I0534A4S1.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '房、车成硬指标？姑娘公布自己22次相亲史，求网友轻喷'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUSON1I0534A4S1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0SVGKV0512B07B.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '400亿“惊天大案”！200万人陷币圈传销，层级关系达3000多层，都是什么套路？公安部破获首宗数字货币传销案'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'title' at row 1")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1LDOQT000999LD.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '印度时报：苹果供应商研究向印度转移6条生产线'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1LDOQT000999LD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRT54GF00297VGM.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '兰州大学：欢迎白湘菱报考我校 目前没有电话邀请的打算'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIRT54GF00297VGM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1NK4VD0514EGPO.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '鸽子坚持站在正起飞的客机发动机上 乘客都以为它要搭"顺风飞机" '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1NK4VD0514EGPO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0V4ITI0514BE2Q.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中科院90多人集体离职:科研人员与体制如何共享红利'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0V4ITI0514BE2Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1LPUND051481US.html',
 'pubtime': '24小时前',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美媒推测：封禁tiktok是因特朗普"感情受到了伤害"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1LPUND051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VLI18JBF2.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '福奇被问到近乎崩溃……一度不敢相信自己的耳朵'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VLI18JBF2.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVJJOL7051484BP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中国14亿人被监视、压迫和恐吓?侠客岛驳斥蓬佩奥'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVJJOL7051484BP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIQNHK45051481US.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '深圳卫健委发了一篇《人体健康经》'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIQNHK45051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIT48B89055004XG.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '留守女生报考北大考古专业上热搜，行业大V纷纷送去入学大礼'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIT48B89055004XG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FINVMTTE051482MP.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '3月火神山医院“火线”颁奖的他，升上将、履新职！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FINVMTTE051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ14LJ2F0514R9P4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '房贷重点提醒：利率转换还剩最后一个月！你该怎么选？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ14LJ2F0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRRO05F0514R9P4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '乌航客机被击落事件初步达成赔偿意见：伊朗同意支付赔偿金'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIRRO05F0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISTOVB8051484BP.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '背叛者李登辉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISTOVB8051484BP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ338F5105346936.html',
 'pubtime': '10小时前',
 'real_pubtime': '2020-08-03 05:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '制造业全面恢复回升'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ338F5105346936.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ17S14E0514DTKM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '日本华人朋友注意了！中国外交部：不明种子快递并非来自中国'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ17S14E0514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VAI0JCQ79.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美议员质疑中国盗窃美国疫苗 福奇无奈解释 听证会主席拒绝回答'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VAI0JCQ79.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ22728K0512GTK3.html',
 'pubtime': '20小时前',
 'real_pubtime': '2020-08-02 19:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '时速都是148公里，交警拦下两辆超速车！两司机受罚有说有笑，他们竟然是夫妻'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ22728K0512GTK3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ108VFI0534A4SC.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '扎克伯格抨击中国互联网公司，但Facebook在国内的生意并不小'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ108VFI0534A4SC.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRVET0E05444G1U.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '曾门庭若市的郭亮村，如今却成“屠宰场”，游客：不要钱都不去'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIRVET0E05444G1U.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ07S6970530SFP3.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '新出土陶猪撞脸愤怒的小鸟，三星堆官微：“这关系怕是说不清了”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ07S6970530SFP3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0GCGC40545I7RS.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '江苏女大学生失联的可可西里，究竟有多可怕？被困只能听天由命！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0GCGC40545I7RS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVSE25305129QAF.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '开除努某某，浙大亡羊补牢为时不晚'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVSE25305129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VOI3COS0G.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '可可西里无人区真的可以徒步旅行?最真实的格尔木到可可西里全程航拍路拍!'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VOI3COS0G.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIP47Q5R05346982.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '自制"祖传秘方咳嗽药" 研读多种说明书用西药勾兑假药'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIP47Q5R05346982.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIO3R5N200018AOR.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美国将从德国撤军1.2万 美媒：两国关系急剧恶化'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIO3R5N200018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VAHVCT1MD.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '劝阻插队过了头 两男子在地铁车厢大打出手'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VAHVCT1MD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2O0N5C0514D3UH.html',
 'pubtime': '14小时前',
 'real_pubtime': '2020-08-03 01:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美国千万粉丝博主不舍告别：TikTok让我买上了房'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2O0N5C0514D3UH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRL5HM40514R9P4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '大气密度不足地球1%，NASA的火星直升机能成功吗？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 168, in execute
    query = self.mogrify(query, args)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 147, in mogrify
    query = query % self._escape_args(args, conn)
ValueError: unsupported format character '?' (0xff0c) at index 81
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIQD9A8D0514R9P4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '上海一小区发生“人貉冲突”，已诱捕10只貉逐步放归野外'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIQD9A8D0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VUHRHI3RJ.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '听够了石班瑜的配音，听一下周星驰原版配音，别有一番韵味'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VUHRHI3RJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUHRBT900018AOR.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '孟晚舟或将被引渡 久未露面的任正非突然连访4名校'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUHRBT900018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0LF7ST05129QAF.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '张发奎战时日记中所见重庆饮宴应酬之风'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0LF7ST05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIQ52PD30514R9P4.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '“毅力”号火星车7月30日将发射，准备首次在火星上制氧'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIQ52PD30514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VWHN2CNAT.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '新疆住沙漠边咋解手？南疆娜娜全村露天解决，上个厕所咋这么难？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VWHN2CNAT.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUFER710514R9P4.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '马上评｜努某某被开除学籍，维护学风校风绝不能手软'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUFER710514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VJHV0064K.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '意外之喜！男子接到挪车电话 到达现场后发现竟是自己8年前丢的车'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VJHV0064K.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1G0T3E05504DOH.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '英媒:印度在边境疯狂搞基建 但它不是中国的对手'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1G0T3E05504DOH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIV7LNJP051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '英美之后，日本向美制药公司预定1.2亿剂新冠疫苗'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIV7LNJP051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0RU5M90534A4SC.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '通过“北溪2号”管道出口，俄罗斯要将氢气变成下一时代的天然气'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0RU5M90534A4SC.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRC7BFI0512DKHT.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '"天问一号"后美国"毅力号"升空 谁会率先抵达火星'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIRC7BFI0512DKHT.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1871O90519AKBM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '不管就卖，曝光就删！二手电商成违禁品隐秘的角落'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1871O90519AKBM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3DC19E0514BE2Q.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '涉案14亿！公安局长竟是黑老大 进公安系统原因成迷'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3DC19E0514BE2Q.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VWHTUQB7B.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '实拍南京鸡鸣寺，第一次在寺庙吃斋饭，被这价格吓到了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VWHTUQB7B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ282FGB0534A4RQ.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '小小村支书，为啥被中纪委点了名？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ282FGB0534A4RQ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3T0SLA0519C6T9.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '恒驰全球发布六款车！亮相便惊艳世界'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3T0SLA0519C6T9.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VUHULDTDF.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '塞班岛海战，落水日军反应，让美军决定不再营救而是直接枪杀'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VUHULDTDF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUKEF5B0514R9P4.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '著名马克思主义哲学家、南京大学哲学系奠基人之一李华钰逝世'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUKEF5B0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUT86N40514BQ68.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '境外媒体关注：中国北斗全球开通令人振奋'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUT86N40514BQ68.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIQ1VU6M05129QAF.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '以为治疗无望吞下84颗化疗药“疗身、疗心”给了她二次生命'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIQ1VU6M05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VWHQDFLKD.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '徒步西藏，109国道无人区有家饭店，进去吃碗面花了一张多！好贵'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VWHQDFLKD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0LF7BO05129QAF.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '鼓励个体经营 支持发展各类特色小店'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0LF7BO05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUU3V8V05129QAF.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '8月1日大限已至，国内26000款无版号游戏被苹果商店下架'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUU3V8V05129QAF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISOPGUR0512D03F.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中医“抗疫”功不可没 20余名专家齐聚探讨中医外治新思路'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISOPGUR0512D03F.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/video/VUHUQCU7O.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2003年，美国抓获并绞死了萨达姆，镜头记录下他死前画面！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/video/VUHUQCU7O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3TN8VS00018AOR.html',
 'pubtime': '3小时前',
 'real_pubtime': '2020-08-03 12:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '浙江高考满分作文"生活在树上" 马伯庸：辞不配位'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3TN8VS00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1P0UTC0001899O.html',
 'pubtime': '23小时前',
 'real_pubtime': '2020-08-02 16:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '无缘清华北大的江苏文科第一名 最终申请香港大学'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1P0UTC0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3C8I9M00019QIF.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '用两吨水碎尸?杭州杀妻男不知道中国刑侦技术多牛逼'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3C8I9M00019QIF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FITP2PQ905370H3B.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '男子将醉酒女友带宾馆发生关系后 叫2朋友将其强奸'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FITP2PQ905370H3B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1FEDKT0537A693.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '可可西里身亡女孩死因成谜：一举动表明不像去自杀'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1FEDKT0537A693.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ421P6H00018AOR.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '高校毕业生组织卖淫手机存200名嫖客电话?校方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ421P6H00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3MSOT80001875P.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '主持人沈力追悼会朱军白岩松现身 倪萍痛哭被搀扶'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3MSOT80001875P.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3AEGAA0001899O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '25岁漂亮女教师离奇失踪 警方在一水沟发现女性内衣'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3AEGAA0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5O8M2QL0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '香港现第二例新冠肺炎死亡病例 患者为70岁男性'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5O8M2QL0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2NT2MG05379L57.html',
 'pubtime': '14小时前',
 'real_pubtime': '2020-08-03 01:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '无人区陆续找到女学生“散骨头”可可西里有多危险？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2NT2MG05379L57.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ45DVB30001899O.html',
 'pubtime': '31分钟前',
 'real_pubtime': '2020-08-03 14:44:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '“秘书”吐槽陪副司长孩子考试？当事人：没秘书'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ45DVB30001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ44FEKE0001899O.html',
 'pubtime': '48分钟前',
 'real_pubtime': '2020-08-03 14:27:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '瑞士跟风插手香港事务 污蔑中国"偏离了开放的道路"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ44FEKE0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ42KP6Q0001899O.html',
 'pubtime': '1小时前',
 'real_pubtime': '2020-08-03 14:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '港警问为何冒险逆行 内地医生:我是中国人 为国做事'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ42KP6Q0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ41PM3V0541A1UA.html',
 'pubtime': '2小时前',
 'real_pubtime': '2020-08-03 13:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '奥巴马同父异母哥哥怒斥弟弟势利 发文支持特朗普'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ41PM3V0541A1UA.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3R6R2M0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '环球：中国从未禁止美科技公司来华 谷歌是自己退出'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3R6R2M0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3QUSEI0514R9P4.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '国防部首次公开布一种新型轰炸机存在 被称航母杀手'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3QUSEI0514R9P4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://ob.laishijialaojiu.com/laishi.htm',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '20元抢1箱53°茅台镇酱香酒，每人限购一箱！手快有。'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://ob.laishijialaojiu.com/laishi.htm' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3QJML20514DTKM.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '法专家鼓励青年互相传染 医生随意开不能戴口罩证明'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3QJML20514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3QLBF00001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '国家信息中心原副主任马忠玉被双开 涉一罕见问题'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3QLBF00001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5NB8ANB0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '防疫期间散布"纪委不怕死"言论 陕西一副局长被查处'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5NB8ANB0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3Q37RQ051481US.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '特朗普不会离开白宫？议员：他想通过紧急方式留任'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3Q37RQ051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3P2UQD0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美俄军控谈判长达13小时 俄方：美国不再逼中国加入'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3P2UQD0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3O8I5R0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '媒体：美国新冠失控 不过是30年前艾滋泛滥的重演'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3O8I5R0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3O7OQV0001899O.html',
 'pubtime': '4小时前',
 'real_pubtime': '2020-08-03 11:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '乱港分子不服被港警通缉：我是美国人 在美生活25年'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3O7OQV0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3NM7F60550AXYG.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '拒戴口罩狂殴公交司机头部16拳 男子获刑3年3个月'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3NM7F60550AXYG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3MLFVU0534J2WK.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '台湾政坛大地震 蔡英文发现事态严重了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3MLFVU0534J2WK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3L0UKT0550HKNY.html',
 'pubtime': '5小时前',
 'real_pubtime': '2020-08-03 10:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '特朗普没等到中国屈服 先等来王毅6天4次密集表态'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3L0UKT0550HKNY.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3HRA1J0001899O.html',
 'pubtime': '6小时前',
 'real_pubtime': '2020-08-03 09:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '微信要遭殃?美政府未来几天将对更多中国软件"下手"'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3HRA1J0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3DLBLA00018AOR.html',
 'pubtime': '7小时前',
 'real_pubtime': '2020-08-03 08:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中国和三个邻国开会应对疫情 印度为何突然急眼了？'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3DLBLA00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3CVHMA0519E14O.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美强制出售中国公司！中国对策核心"内循环"咋搞?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3CVHMA0519E14O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2KF19A0519814N.html',
 'pubtime': '15小时前',
 'real_pubtime': '2020-08-03 00:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '联合国警告!前所未有的粮食危机逼近 中国咋应对?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2KF19A0519814N.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ3AS2JQ052182V3.html',
 'pubtime': '8小时前',
 'real_pubtime': '2020-08-03 07:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '牛弹琴：大选前 ，特朗普给普京送了最后一份大礼'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ3AS2JQ052182V3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ38G7LC0514R9OJ.html',
 'pubtime': '9小时前',
 'real_pubtime': '2020-08-03 06:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '三姐妹残忍杀害熟睡的父亲 却有30万人请求释放他们'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ38G7LC0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2EE50B05128ELF.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '巴西总统肺里长霉菌、妻子也确诊 还被起诉反人类罪'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2EE50B05128ELF.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2BGUNS051996QS.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '太暴利！中国“可口可乐”准备上市 茅台要小心了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2BGUNS051996QS.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ2BKRKU00018AOR.html',
 'pubtime': '17小时前',
 'real_pubtime': '2020-08-02 22:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '男子舞厅内救女孩被刺4刀未获感谢 将女孩告上法庭'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ2BKRKU00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1Q5Q4600258105.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '游说各国弃用华为后 美国给出一份“干净5G”名单'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1Q5Q4600258105.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ28QGFH051492T3.html',
 'pubtime': '18小时前',
 'real_pubtime': '2020-08-02 21:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '男子与女友分手上门讨钱遭拒 杀害女友奶奶和表妹'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ28QGFH051492T3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ25SHE90001899O.html',
 'pubtime': '19小时前',
 'real_pubtime': '2020-08-02 20:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': ' 杭州杀妻案楼栋住户忙搬家：总有点阴森森的感觉'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ25SHE90001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1S1BKA055040N3.html',
 'pubtime': '22小时前',
 'real_pubtime': '2020-08-02 17:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美媒：如果拜登当选总统，美国外交政策或将剧变'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1S1BKA055040N3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1EBH0N0534J2WK.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '车主违停20次称车贵以为城管不敢拖 网友:这算豪车?'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1EBH0N0534J2WK.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ197KK30514R9L4.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中美关系已经"没有回头路"可走？刘晓明大使回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ197KK30514R9L4.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ17VUK70001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '足疗店内一男一女遇害身亡 警方:女子已有三月身孕'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ17VUK70001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ1250KJ051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '香港面临一年“真空期” 媒体：中央或“另有打算”'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ1250KJ051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0VGBHT0001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '干部被曝出轨并家暴 妻子满身伤痕猝死后丈夫失联'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0VGBHT0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ08AP6005199A0B.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美国会对中国使用金融终极武器SWIFT吗？分析来了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ08AP6005199A0B.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0QGAJ90001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': 'Tik-Tok为什么要被强制卖给微软？背后有更深层原因'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0QGAJ90001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FJ0QEGSD0001875O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '胡锡进:TikTok遭围猎 中方能采取的反制措施很有限'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FJ0QEGSD0001875O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVLCB0D0001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '专家:对中国数千亿级美元的"掠夺盛宴" 正在美发生'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVLCB0D0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5OKHD040001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '印度空军将出动该国最大运输机向武汉运送医疗物资 '}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5OKHD040001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVHFEEF051482MP.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '释放啥信号？军科院战争研究院院长走进中南海'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVHFEEF051482MP.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVDIIN60514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '不爱戴口罩的美国议员疯狂追问，把福奇都整笑了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVDIIN60514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVDB62E05504DP0.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美媒怒揭:我国本有改变命运大计划 被特朗普家废了'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVDB62E05504DP0.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVCD5130514DTKM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '"中国纸箱上有病毒！"澳男子一把火烧了自家超市'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVCD5130514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVCCU0I0514R9OJ.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '又来骗钱！黄之锋卖惨众筹：我被人跟踪，要请保镖'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVCCU0I0514R9OJ.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVCCU3V0514DTKM.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '德专家:中企并不照搬德企技术 更注重现有科技创新'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVCCU3V0514DTKM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIVBERU50512DU6N.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '福奇再现身国会：为中国仗义执言 被不实流言傍身'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIVBERU50512DU6N.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIV9FCP40001899O.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '舆论称中国奶业走上不可挽回的歧路?官方:居心叵测'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIV9FCP40001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIV4IQ49051481US.html',
 'pubtime': '昨天',
 'real_pubtime': '2020-08-02 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '港媒：中央出钱出人，为全港市民免费检测！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIV4IQ49051481US.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIU0EO9I0514D849.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '周小平:传美领馆欠薪欠补 蓬佩奥谎言令美颜面扫地'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIU0EO9I0514D849.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRAUN0705345ARG.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '西瓜摊主去救人，瓜全被城管搬走！结局让人想不到'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIRAUN0705345ARG.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUSQJFD055040N3.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中美又现摩擦上海举行战备演练要打仗了?官方回应'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUSQJFD055040N3.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIUSBJMP0514EGPO.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '美国首位换脸人去世 曾被丈夫散弹枪轰脸留狰狞面容'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIUSBJMP0514EGPO.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5N6OFOO0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '感染离世院长妻子:疫情发生后 近1个月没见过面'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5N6OFOO0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5N5S7N20001875P.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '广东唯一零感染城市：大数据核实每个进出人员踪迹'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5N5S7N20001875P.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5OF35CU00018AOR.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '日本教授探访"钻石公主号"：很悲惨 防疫工作混乱'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5OF35CU00018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5OF1LO100018AOR.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '中疾控论文的新数据:去年12月31日前有感染者104人'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5OF1LO100018AOR.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5N5AF34054557O1.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '关闭着最危险病毒的武汉病毒所P4实验室'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5N5AF34054557O1.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/F5N59A7K0001899O.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '湖北接收社会捐赠资金115.43亿 仍急需口罩防护服'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/F5N59A7K0001899O.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISSGI280525X3AH.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '你可以拒绝旅行车，但是你很难不喜欢这台沃尔沃v60！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISSGI280525X3AH.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FISTUELL0522D3NM.html',
 'pubtime': '前天',
 'real_pubtime': '2020-08-01 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '晒我家三伏天早餐，不精致但营养味道棒，花钱不多，比早餐店丰盛'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FISTUELL0522D3NM.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://3g.163.com/all/article/FIRE0C8705421ROD.html',
 'pubtime': '3天前',
 'real_pubtime': '2020-07-31 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': 'iOS锁屏超实用功能化！设置教程'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://3g.163.com/all/article/FIRE0C8705421ROD.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'https://www.caozhigh.com/1594280707807N0FRj.html',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '2020年种植牙报价系统已更新，一键测算种植牙费用！'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'https://www.caozhigh.com/1594280707807N0FRj.html' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.scraper] ERROR: Error processing {'link': 'http://wy.zhifa999.cn/zt/wy2/022/',
 'pubtime': None,
 'real_pubtime': '2020-08-03 15:15:28',
 'source': 'https://3g.163.com/touch/#/recommend',
 'title': '\n\t\t\t男人秃头，出门没面子？植发3000单位需要多少钱？\n\t\t\t'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/news163/news163/pipelines.py", line 17, in process_item
    self.db.insertData('news_163',item['title'],item['link'],item['source'],item['pubtime'],item['real_pubtime'])
  File "/home/glacier/scrapy/news163/news163/dbutil.py", line 26, in insertData
    self.cur.execute(sql,real_pubtime)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry 'http://wy.zhifa999.cn/zt/wy2/022/' for key 'link_UNIQUE'")
2020-08-03 15:15:28 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-03 15:15:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 4665,
 'downloader/request_count': 4,
 'downloader/request_method_count/POST': 4,
 'downloader/response_bytes': 1351596,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'elapsed_time_seconds': 25.799888,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 3, 7, 15, 28, 127483),
 'item_scraped_count': 3,
 'log_count/DEBUG': 7,
 'log_count/ERROR': 854,
 'log_count/INFO': 10,
 'memusage/max': 53374976,
 'memusage/startup': 53374976,
 'response_received_count': 4,
 'scheduler/dequeued': 8,
 'scheduler/dequeued/memory': 8,
 'scheduler/enqueued': 8,
 'scheduler/enqueued/memory': 8,
 'splash/execute/request_count': 4,
 'splash/execute/response_count/200': 4,
 'start_time': datetime.datetime(2020, 8, 3, 7, 15, 2, 327595)}
2020-08-03 15:15:28 [scrapy.core.engine] INFO: Spider closed (finished)
**** 200 https://3g.163.com/touch/tech/
**** 199 https://3g.163.com/touch/money
**** 214 https://3g.163.com/touch/news
**** 244 https://3g.163.com/touch/#/recommend
