2020-08-02 22:59:01 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: index163)
2020-08-02 22:59:01 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.6.0 |Continuum Analytics, Inc.| (default, Dec 23 2016, 12:22:00) - [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-74-generic-x86_64-with-debian-buster-sid
2020-08-02 22:59:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'index163', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'index163.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['index163.spiders']}
2020-08-02 22:59:01 [scrapy.extensions.telnet] INFO: Telnet Password: 6cd05b6d874e8513
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled item pipelines:
['index163.pipelines.Index163Pipeline']
2020-08-02 22:59:01 [scrapy.core.engine] INFO: Spider opened
2020-08-02 22:59:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-02 22:59:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6024
2020-08-02 22:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/robots.txt> (referer: None)
2020-08-02 22:59:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://localhost:8050/robots.txt> (referer: None)
2020-08-02 22:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:04 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=2&season=1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-02 22:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=2&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=0&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=0&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=0&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=2&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=0&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '12.04',
 'change_rate': '0.33',
 'close': '3686.16',
 'date': '2020-03-31',
 'max': '3716.07',
 'min': '3676.20',
 'name': '沪深300',
 'open': '3708.14',
 'volumn': '161595510008.20',
 'volumn_hand': '111453025.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-31' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-35.95',
 'change_rate': '-0.97',
 'close': '3674.11',
 'date': '2020-03-30',
 'max': '3690.64',
 'min': '3637.59',
 'name': '沪深300',
 'open': '3657.46',
 'volumn': '180640799409.30',
 'volumn_hand': '126876673.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '12.01',
 'change_rate': '0.32',
 'close': '3710.06',
 'date': '2020-03-27',
 'max': '3758.78',
 'min': '3709.92',
 'name': '沪深300',
 'open': '3746.39',
 'volumn': '186103426334.70',
 'volumn_hand': '124060995.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-24.47',
 'change_rate': '-0.66',
 'close': '3698.05',
 'date': '2020-03-26',
 'max': '3736.25',
 'min': '3681.27',
 'name': '沪深300',
 'open': '3692.61',
 'volumn': '169336311861.40',
 'volumn_hand': '112310665.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-26' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '97.40',
 'change_rate': '2.69',
 'close': '3722.52',
 'date': '2020-03-25',
 'max': '3732.65',
 'min': '3685.99',
 'name': '沪深300',
 'open': '3711.48',
 'volumn': '231561518761.20',
 'volumn_hand': '153495958.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-25' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '94.81',
 'change_rate': '2.69',
 'close': '3625.11',
 'date': '2020-03-24',
 'max': '3627.76',
 'min': '3545.45',
 'name': '沪深300',
 'open': '3598.65',
 'volumn': '208553840688.50',
 'volumn_hand': '143103021.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-122.92',
 'change_rate': '-3.36',
 'close': '3530.31',
 'date': '2020-03-23',
 'max': '3585.80',
 'min': '3523.79',
 'name': '沪深300',
 'open': '3542.68',
 'volumn': '197669624970.10',
 'volumn_hand': '137108790.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '64.13',
 'change_rate': '1.79',
 'close': '3653.22',
 'date': '2020-03-20',
 'max': '3663.95',
 'min': '3588.78',
 'name': '沪深300',
 'open': '3629.51',
 'volumn': '211223073323.10',
 'volumn_hand': '139603000.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-47.16',
 'change_rate': '-1.30',
 'close': '3589.09',
 'date': '2020-03-19',
 'max': '3647.99',
 'min': '3503.19',
 'name': '沪深300',
 'open': '3623.79',
 'volumn': '271827467961.60',
 'volumn_hand': '180807407.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-73.43',
 'change_rate': '-1.98',
 'close': '3636.26',
 'date': '2020-03-18',
 'max': '3775.85',
 'min': '3636.26',
 'name': '沪深300',
 'open': '3729.69',
 'volumn': '244127161535.30',
 'volumn_hand': '155037547.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-18.16',
 'change_rate': '-0.49',
 'close': '3709.68',
 'date': '2020-03-17',
 'max': '3786.89',
 'min': '3618.31',
 'name': '沪深300',
 'open': '3739.78',
 'volumn': '250824025696.90',
 'volumn_hand': '166246129.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-167.47',
 'change_rate': '-4.30',
 'close': '3727.84',
 'date': '2020-03-16',
 'max': '3899.86',
 'min': '3720.51',
 'name': '沪深300',
 'open': '3899.86',
 'volumn': '282836238271.20',
 'volumn_hand': '185968260.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-55.60',
 'change_rate': '-1.41',
 'close': '3895.31',
 'date': '2020-03-13',
 'max': '3937.18',
 'min': '3765.15',
 'name': '沪深300',
 'open': '3771.01',
 'volumn': '280213453213.70',
 'volumn_hand': '188296722.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-77.52',
 'change_rate': '-1.92',
 'close': '3950.91',
 'date': '2020-03-12',
 'max': '3987.43',
 'min': '3926.27',
 'name': '沪深300',
 'open': '3976.11',
 'volumn': '233152848759.10',
 'volumn_hand': '157060458.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-54.30',
 'change_rate': '-1.33',
 'close': '4028.43',
 'date': '2020-03-11',
 'max': '4091.27',
 'min': '4028.40',
 'name': '沪深300',
 'open': '4090.93',
 'volumn': '244990872685.90',
 'volumn_hand': '161656111.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '85.60',
 'change_rate': '2.14',
 'close': '4082.73',
 'date': '2020-03-10',
 'max': '4093.00',
 'min': '3954.75',
 'name': '沪深300',
 'open': '3975.23',
 'volumn': '296184435851.30',
 'volumn_hand': '197416402.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-141.37',
 'change_rate': '-3.42',
 'close': '3997.13',
 'date': '2020-03-09',
 'max': '4063.08',
 'min': '3995.13',
 'name': '沪深300',
 'open': '4063.08',
 'volumn': '305428730303.80',
 'volumn_hand': '208102035.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-68.22',
 'change_rate': '-1.62',
 'close': '4138.51',
 'date': '2020-03-06',
 'max': '4181.31',
 'min': '4135.39',
 'name': '沪深300',
 'open': '4158.20',
 'volumn': '253168631958.90',
 'volumn_hand': '172475717.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '91.67',
 'change_rate': '2.23',
 'close': '4206.73',
 'date': '2020-03-05',
 'max': '4215.85',
 'min': '4127.04',
 'name': '沪深300',
 'open': '4150.21',
 'volumn': '362838831775.50',
 'volumn_hand': '231823115.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-05' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '54.25',
 'change_rate': '1.32',
 'close': '4163.96',
 'date': '2020-06-30',
 'max': '4174.42',
 'min': '4129.78',
 'name': '沪深300',
 'open': '4130.00',
 'volumn': '227935704488.90',
 'volumn_hand': '125933521.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-29.27',
 'change_rate': '-0.71',
 'close': '4109.72',
 'date': '2020-06-29',
 'max': '4137.37',
 'min': '4092.54',
 'name': '沪深300',
 'open': '4127.93',
 'volumn': '226522059762.90',
 'volumn_hand': '130865854.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '17.20',
 'change_rate': '0.42',
 'close': '4138.99',
 'date': '2020-06-24',
 'max': '4144.68',
 'min': '4123.36',
 'name': '沪深300',
 'open': '4128.10',
 'volumn': '224551430008.00',
 'volumn_hand': '121712465.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '19.75',
 'change_rate': '0.48',
 'close': '4121.79',
 'date': '2020-06-23',
 'max': '4124.73',
 'min': '4080.75',
 'name': '沪深300',
 'open': '4098.04',
 'volumn': '234806510834.50',
 'volumn_hand': '129229510.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '3.34',
 'change_rate': '0.08',
 'close': '4102.05',
 'date': '2020-06-22',
 'max': '4126.94',
 'min': '4088.78',
 'name': '沪深300',
 'open': '4097.51',
 'volumn': '259200520725.70',
 'volumn_hand': '155829465.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '54.33',
 'change_rate': '1.34',
 'close': '4098.71',
 'date': '2020-06-19',
 'max': '4109.36',
 'min': '4043.49',
 'name': '沪深300',
 'open': '4047.05',
 'volumn': '255549797299.60',
 'volumn_hand': '152946990.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '26.79',
 'change_rate': '0.67',
 'close': '4044.38',
 'date': '2020-06-18',
 'max': '4047.56',
 'min': '4000.90',
 'name': '沪深300',
 'open': '4009.78',
 'volumn': '210192918146.20',
 'volumn_hand': '138148761.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '3.02',
 'change_rate': '0.08',
 'close': '4017.59',
 'date': '2020-06-17',
 'max': '4018.61',
 'min': '3992.13',
 'name': '沪深300',
 'open': '4018.61',
 'volumn': '176977503611.20',
 'volumn_hand': '105605799.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '23.69',
 'change_rate': '0.58',
 'close': '4115.05',
 'date': '2020-03-04',
 'max': '4115.26',
 'min': '4060.73',
 'name': '沪深300',
 'open': '4078.50',
 'volumn': '281784863844.90',
 'volumn_hand': '182424730.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-04' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '21.70',
 'change_rate': '0.53',
 'close': '4091.36',
 'date': '2020-03-03',
 'max': '4147.65',
 'min': '4067.91',
 'name': '沪深300',
 'open': '4125.14',
 'volumn': '330802584618.90',
 'volumn_hand': '219369777.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '129.62',
 'change_rate': '3.29',
 'close': '4069.67',
 'date': '2020-03-02',
 'max': '4092.54',
 'min': '3968.84',
 'name': '沪深300',
 'open': '3968.84',
 'volumn': '317426205457.10',
 'volumn_hand': '219313559.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-03-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-144.83',
 'change_rate': '-3.55',
 'close': '3940.05',
 'date': '2020-02-28',
 'max': '4031.15',
 'min': '3928.07',
 'name': '沪深300',
 'open': '3988.73',
 'volumn': '330358907265.50',
 'volumn_hand': '230275093.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '11.86',
 'change_rate': '0.29',
 'close': '4084.88',
 'date': '2020-02-27',
 'max': '4110.53',
 'min': '4067.44',
 'name': '沪深300',
 'open': '4084.08',
 'volumn': '282050206371.00',
 'volumn_hand': '181290981.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-50.84',
 'change_rate': '-1.23',
 'close': '4073.02',
 'date': '2020-02-26',
 'max': '4132.78',
 'min': '4061.13',
 'name': '沪深300',
 'open': '4070.10',
 'volumn': '366022417907.40',
 'volumn_hand': '261094061.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-26' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-8.98',
 'change_rate': '-0.22',
 'close': '4123.85',
 'date': '2020-02-25',
 'max': '4126.71',
 'min': '4020.91',
 'name': '沪深300',
 'open': '4066.30',
 'volumn': '372213717029.50',
 'volumn_hand': '244167831.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-25' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-16.65',
 'change_rate': '-0.40',
 'close': '4132.84',
 'date': '2020-02-24',
 'max': '4149.01',
 'min': '4097.18',
 'name': '沪深300',
 'open': '4131.84',
 'volumn': '326387800605.70',
 'volumn_hand': '212869303.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '4.83',
 'change_rate': '0.12',
 'close': '4149.49',
 'date': '2020-02-21',
 'max': '4184.44',
 'min': '4130.17',
 'name': '沪深300',
 'open': '4134.87',
 'volumn': '326564003558.50',
 'volumn_hand': '217213604.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '93.35',
 'change_rate': '2.30',
 'close': '4144.66',
 'date': '2020-02-20',
 'max': '4148.53',
 'min': '4055.81',
 'name': '沪深300',
 'open': '4062.90',
 'volumn': '310835589162.30',
 'volumn_hand': '212232624.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '59.58',
 'change_rate': '1.51',
 'close': '4014.57',
 'date': '2020-06-16',
 'max': '4014.57',
 'min': '3987.86',
 'name': '沪深300',
 'open': '3995.58',
 'volumn': '185104029158.90',
 'volumn_hand': '111051539.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-48.09',
 'change_rate': '-1.20',
 'close': '3954.99',
 'date': '2020-06-15',
 'max': '4007.14',
 'min': '3954.99',
 'name': '沪深300',
 'open': '3982.97',
 'volumn': '211125336143.80',
 'volumn_hand': '131297860.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '7.20',
 'change_rate': '0.18',
 'close': '4003.08',
 'date': '2020-06-12',
 'max': '4011.06',
 'min': '3927.25',
 'name': '沪深300',
 'open': '3931.62',
 'volumn': '193504046742.30',
 'volumn_hand': '134166649.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-43.82',
 'change_rate': '-1.08',
 'close': '3995.88',
 'date': '2020-06-11',
 'max': '4043.01',
 'min': '3979.75',
 'name': '沪深300',
 'open': '4031.74',
 'volumn': '197079441861.10',
 'volumn_hand': '127308941.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-7.32',
 'change_rate': '-0.18',
 'close': '4039.71',
 'date': '2020-06-10',
 'max': '4046.23',
 'min': '4024.42',
 'name': '沪深300',
 'open': '4046.23',
 'volumn': '166778642366.20',
 'volumn_hand': '112265728.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '25.07',
 'change_rate': '0.62',
 'close': '4047.03',
 'date': '2020-06-09',
 'max': '4052.16',
 'min': '4016.34',
 'name': '沪深300',
 'open': '4027.56',
 'volumn': '166533966010.00',
 'volumn_hand': '115304479.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '20.70',
 'change_rate': '0.52',
 'close': '4021.95',
 'date': '2020-06-08',
 'max': '4050.22',
 'min': '4016.10',
 'name': '沪深300',
 'open': '4023.61',
 'volumn': '193047518687.60',
 'volumn_hand': '137925813.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '19.07',
 'change_rate': '0.48',
 'close': '4001.25',
 'date': '2020-06-05',
 'max': '4001.25',
 'min': '3967.93',
 'name': '沪深300',
 'open': '3988.22',
 'volumn': '154311342981.80',
 'volumn_hand': '102443942.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-05' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-1.46',
 'change_rate': '-0.04',
 'close': '3982.19',
 'date': '2020-06-04',
 'max': '3999.81',
 'min': '3968.57',
 'name': '沪深300',
 'open': '3998.16',
 'volumn': '149057855837.50',
 'volumn_hand': '104277737.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-04' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '0.08',
 'change_rate': '0.00',
 'close': '3983.65',
 'date': '2020-06-03',
 'max': '4018.68',
 'min': '3982.93',
 'name': '沪深300',
 'open': '4001.17',
 'volumn': '200882767676.90',
 'volumn_hand': '136597483.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-6.20',
 'change_rate': '-0.15',
 'close': '4051.31',
 'date': '2020-02-19',
 'max': '4085.17',
 'min': '4042.85',
 'name': '沪深300',
 'open': '4049.59',
 'volumn': '257554535729.80',
 'volumn_hand': '169046441.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-19.91',
 'change_rate': '-0.49',
 'close': '4057.51',
 'date': '2020-02-18',
 'max': '4076.39',
 'min': '4027.79',
 'name': '沪深300',
 'open': '4069.83',
 'volumn': '242552517334.40',
 'volumn_hand': '163236220.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '89.69',
 'change_rate': '2.25',
 'close': '4077.42',
 'date': '2020-02-17',
 'max': '4077.45',
 'min': '3999.65',
 'name': '沪深300',
 'open': '3999.65',
 'volumn': '273067817277.80',
 'volumn_hand': '182778969.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '27.82',
 'change_rate': '0.70',
 'close': '3987.73',
 'date': '2020-02-14',
 'max': '4001.56',
 'min': '3954.02',
 'name': '沪深300',
 'open': '3954.23',
 'volumn': '222895073624.80',
 'volumn_hand': '143239803.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-24.51',
 'change_rate': '-0.62',
 'close': '3959.92',
 'date': '2020-02-13',
 'max': '3999.55',
 'min': '3950.14',
 'name': '沪深300',
 'open': '3985.88',
 'volumn': '228605964793.40',
 'volumn_hand': '145001843.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '31.97',
 'change_rate': '0.81',
 'close': '3984.43',
 'date': '2020-02-12',
 'max': '3984.43',
 'min': '3940.67',
 'name': '沪深300',
 'open': '3945.67',
 'volumn': '200776706549.80',
 'volumn_hand': '126710321.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '36.46',
 'change_rate': '0.93',
 'close': '3952.46',
 'date': '2020-02-11',
 'max': '3970.52',
 'min': '3915.71',
 'name': '沪深300',
 'open': '3926.42',
 'volumn': '219307119361.30',
 'volumn_hand': '143441674.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '16.14',
 'change_rate': '0.41',
 'close': '3916.01',
 'date': '2020-02-10',
 'max': '3920.17',
 'min': '3861.01',
 'name': '沪深300',
 'open': '3872.37',
 'volumn': '229625441895.60',
 'volumn_hand': '148406969.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '0.09',
 'change_rate': '0.00',
 'close': '3899.87',
 'date': '2020-02-07',
 'max': '3899.88',
 'min': '3849.71',
 'name': '沪深300',
 'open': '3879.55',
 'volumn': '237508816255.60',
 'volumn_hand': '151731759.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '71.25',
 'change_rate': '1.86',
 'close': '3899.78',
 'date': '2020-02-06',
 'max': '3914.92',
 'min': '3806.96',
 'name': '沪深300',
 'open': '3841.75',
 'volumn': '262820088451.90',
 'volumn_hand': '176462235.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '38.90',
 'change_rate': '0.84',
 'close': '4695.05',
 'date': '2020-07-31',
 'max': '4741.81',
 'min': '4621.96',
 'name': '沪深300',
 'open': '4652.18',
 'volumn': '351119312415.00',
 'volumn_hand': '184839026.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-31' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-22.86',
 'change_rate': '-0.49',
 'close': '4656.15',
 'date': '2020-07-30',
 'max': '4704.63',
 'min': '4649.77',
 'name': '沪深300',
 'open': '4689.76',
 'volumn': '324009242692.40',
 'volumn_hand': '166967566.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '110.75',
 'change_rate': '2.42',
 'close': '4679.01',
 'date': '2020-07-29',
 'max': '4680.56',
 'min': '4548.85',
 'name': '沪深300',
 'open': '4559.16',
 'volumn': '350432649160.50',
 'volumn_hand': '186695305.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '39.81',
 'change_rate': '0.88',
 'close': '4568.26',
 'date': '2020-07-28',
 'max': '4590.25',
 'min': '4537.68',
 'name': '沪深300',
 'open': '4567.67',
 'volumn': '292835785345.20',
 'volumn_hand': '162768498.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '22.86',
 'change_rate': '0.51',
 'close': '4528.45',
 'date': '2020-07-27',
 'max': '4558.12',
 'min': '4482.44',
 'name': '沪深300',
 'open': '4535.01',
 'volumn': '301893370163.20',
 'volumn_hand': '171420551.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-206.85',
 'change_rate': '-4.39',
 'close': '4505.59',
 'date': '2020-07-24',
 'max': '4691.70',
 'min': '4479.39',
 'name': '沪深300',
 'open': '4679.03',
 'volumn': '437726712279.70',
 'volumn_hand': '243905203.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-2.01',
 'change_rate': '-0.04',
 'close': '4712.44',
 'date': '2020-07-23',
 'max': '4731.40',
 'min': '4607.66',
 'name': '沪深300',
 'open': '4668.74',
 'volumn': '405175268660.90',
 'volumn_hand': '234314569.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '23.40',
 'change_rate': '0.50',
 'close': '4714.45',
 'date': '2020-07-22',
 'max': '4790.45',
 'min': '4675.35',
 'name': '沪深300',
 'open': '4682.66',
 'volumn': '386470859914.30',
 'volumn_hand': '224199211.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '12.23',
 'change_rate': '0.31',
 'close': '3983.57',
 'date': '2020-06-02',
 'max': '3991.78',
 'min': '3958.98',
 'name': '沪深300',
 'open': '3969.95',
 'volumn': '195563304256.30',
 'volumn_hand': '144303060.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '104.32',
 'change_rate': '2.70',
 'close': '3971.34',
 'date': '2020-06-01',
 'max': '3976.32',
 'min': '3901.73',
 'name': '沪深300',
 'open': '3901.73',
 'volumn': '208436512945.10',
 'volumn_hand': '136456652.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-06-01' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '10.39',
 'change_rate': '0.27',
 'close': '3867.02',
 'date': '2020-05-29',
 'max': '3872.30',
 'min': '3830.42',
 'name': '沪深300',
 'open': '3838.38',
 'volumn': '135658136028.20',
 'volumn_hand': '93813832.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '11.02',
 'change_rate': '0.29',
 'close': '3856.63',
 'date': '2020-05-28',
 'max': '3885.42',
 'min': '3818.43',
 'name': '沪深300',
 'open': '3848.49',
 'volumn': '139108407792.30',
 'volumn_hand': '93064054.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-27.16',
 'change_rate': '-0.70',
 'close': '3845.61',
 'date': '2020-05-27',
 'max': '3873.70',
 'min': '3838.42',
 'name': '沪深300',
 'open': '3873.70',
 'volumn': '123737501164.50',
 'volumn_hand': '83711831.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '43.45',
 'change_rate': '1.13',
 'close': '3872.77',
 'date': '2020-05-26',
 'max': '3874.75',
 'min': '3844.48',
 'name': '沪深300',
 'open': '3850.00',
 'volumn': '125445619316.80',
 'volumn_hand': '77448076.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-26' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '5.26',
 'change_rate': '0.14',
 'close': '3829.32',
 'date': '2020-05-25',
 'max': '3835.63',
 'min': '3800.18',
 'name': '沪深300',
 'open': '3828.32',
 'volumn': '127011917716.30',
 'volumn_hand': '79033326.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-25' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-89.73',
 'change_rate': '-2.29',
 'close': '3824.06',
 'date': '2020-05-22',
 'max': '3907.58',
 'min': '3818.15',
 'name': '沪深300',
 'open': '3907.58',
 'volumn': '157286504986.30',
 'volumn_hand': '103378360.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-21.43',
 'change_rate': '-0.54',
 'close': '3913.79',
 'date': '2020-05-21',
 'max': '3951.74',
 'min': '3907.58',
 'name': '沪深300',
 'open': '3950.60',
 'volumn': '149154142257.80',
 'volumn_hand': '94861033.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-21.03',
 'change_rate': '-0.53',
 'close': '3935.22',
 'date': '2020-05-20',
 'max': '3955.71',
 'min': '3923.92',
 'name': '沪深300',
 'open': '3955.71',
 'volumn': '157102533276.10',
 'volumn_hand': '100791150.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '42.89',
 'change_rate': '1.13',
 'close': '3828.53',
 'date': '2020-02-05',
 'max': '3866.01',
 'min': '3781.61',
 'name': '沪深300',
 'open': '3801.10',
 'volumn': '264042920865.70',
 'volumn_hand': '174925524.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-05' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '97.28',
 'change_rate': '2.64',
 'close': '3785.64',
 'date': '2020-02-04',
 'max': '3786.86',
 'min': '3652.00',
 'name': '沪深300',
 'open': '3652.00',
 'volumn': '298165767621.40',
 'volumn_hand': '213933328.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-04' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-315.54',
 'change_rate': '-7.88',
 'close': '3688.36',
 'date': '2020-02-03',
 'max': '3732.16',
 'min': '3639.91',
 'name': '沪深300',
 'open': '3639.91',
 'volumn': '243303105385.90',
 'volumn_hand': '157559647.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-02-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-128.03',
 'change_rate': '-3.10',
 'close': '4003.90',
 'date': '2020-01-23',
 'max': '4103.52',
 'min': '3972.39',
 'name': '沪深300',
 'open': '4093.32',
 'volumn': '250409357700.70',
 'volumn_hand': '160357603.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '17.62',
 'change_rate': '0.43',
 'close': '4131.93',
 'date': '2020-01-22',
 'max': '4141.18',
 'min': '4046.49',
 'name': '沪深300',
 'open': '4093.80',
 'volumn': '208136150791.50',
 'volumn_hand': '126758763.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-71.52',
 'change_rate': '-1.71',
 'close': '4114.31',
 'date': '2020-01-21',
 'max': '4165.02',
 'min': '4113.33',
 'name': '沪深300',
 'open': '4165.02',
 'volumn': '204586880493.90',
 'volumn_hand': '130527507.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '30.98',
 'change_rate': '0.75',
 'close': '4185.83',
 'date': '2020-01-20',
 'max': '4185.96',
 'min': '4149.49',
 'name': '沪深300',
 'open': '4170.74',
 'volumn': '202692287441.80',
 'volumn_hand': '122409147.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '5.81',
 'change_rate': '0.14',
 'close': '4154.85',
 'date': '2020-01-17',
 'max': '4177.03',
 'min': '4141.64',
 'name': '沪深300',
 'open': '4162.19',
 'volumn': '166591591594.30',
 'volumn_hand': '98725682.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-17.69',
 'change_rate': '-0.42',
 'close': '4149.04',
 'date': '2020-01-16',
 'max': '4175.29',
 'min': '4142.18',
 'name': '沪深300',
 'open': '4174.82',
 'volumn': '156242505812.00',
 'volumn_hand': '100267642.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '10.74',
 'change_rate': '0.23',
 'close': '4691.04',
 'date': '2020-07-21',
 'max': '4714.29',
 'min': '4661.44',
 'name': '沪深300',
 'open': '4697.50',
 'volumn': '356069805762.60',
 'volumn_hand': '200415659.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '135.60',
 'change_rate': '2.98',
 'close': '4680.30',
 'date': '2020-07-20',
 'max': '4681.94',
 'min': '4534.23',
 'name': '沪深300',
 'open': '4597.20',
 'volumn': '416714222275.70',
 'volumn_hand': '246068914.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '28.45',
 'change_rate': '0.63',
 'close': '4544.70',
 'date': '2020-07-17',
 'max': '4601.37',
 'min': '4485.82',
 'name': '沪深300',
 'open': '4524.77',
 'volumn': '372973887045.70',
 'volumn_hand': '207375563.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-228.22',
 'change_rate': '-4.81',
 'close': '4516.25',
 'date': '2020-07-16',
 'max': '4772.56',
 'min': '4513.65',
 'name': '沪深300',
 'open': '4741.53',
 'volumn': '511237962884.20',
 'volumn_hand': '284657133.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-62.22',
 'change_rate': '-1.29',
 'close': '4744.47',
 'date': '2020-07-15',
 'max': '4837.48',
 'min': '4723.36',
 'name': '沪深300',
 'open': '4821.52',
 'volumn': '486748347680.40',
 'volumn_hand': '272389006.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-46.27',
 'change_rate': '-0.95',
 'close': '4806.69',
 'date': '2020-07-14',
 'max': '4860.44',
 'min': '4729.93',
 'name': '沪深300',
 'open': '4836.17',
 'volumn': '511211048184.90',
 'volumn_hand': '297241985.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '99.83',
 'change_rate': '2.10',
 'close': '4852.96',
 'date': '2020-07-13',
 'max': '4878.08',
 'min': '4741.87',
 'name': '沪深300',
 'open': '4742.37',
 'volumn': '541105098721.00',
 'volumn_hand': '321645446.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-87.64',
 'change_rate': '-1.81',
 'close': '4753.13',
 'date': '2020-07-10',
 'max': '4821.37',
 'min': '4734.47',
 'name': '沪深300',
 'open': '4796.09',
 'volumn': '510472055095.90',
 'volumn_hand': '316949651.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '66.77',
 'change_rate': '1.40',
 'close': '4840.77',
 'date': '2020-07-09',
 'max': '4854.12',
 'min': '4757.29',
 'name': '沪深300',
 'open': '4770.08',
 'volumn': '556718732098.90',
 'volumn_hand': '351046893.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '75.88',
 'change_rate': '1.62',
 'close': '4774.00',
 'date': '2020-07-08',
 'max': '4803.36',
 'min': '4670.65',
 'name': '沪深300',
 'open': '4692.86',
 'volumn': '532849825964.50',
 'volumn_hand': '348074847.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '28.03',
 'change_rate': '0.60',
 'close': '4698.13',
 'date': '2020-07-07',
 'max': '4796.32',
 'min': '4688.06',
 'name': '沪深300',
 'open': '4739.61',
 'volumn': '635254742706.00',
 'volumn_hand': '406008553.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '33.34',
 'change_rate': '0.85',
 'close': '3956.25',
 'date': '2020-05-19',
 'max': '3966.85',
 'min': '3944.07',
 'name': '沪深300',
 'open': '3963.78',
 'volumn': '159886222402.20',
 'volumn_hand': '94015291.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '10.10',
 'change_rate': '0.26',
 'close': '3922.91',
 'date': '2020-05-18',
 'max': '3946.43',
 'min': '3898.40',
 'name': '沪深300',
 'open': '3914.66',
 'volumn': '188528121367.60',
 'volumn_hand': '112801762.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-12.40',
 'change_rate': '-0.32',
 'close': '3912.82',
 'date': '2020-05-15',
 'max': '3945.20',
 'min': '3907.40',
 'name': '沪深300',
 'open': '3941.13',
 'volumn': '153301505149.40',
 'volumn_hand': '92618382.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-43.04',
 'change_rate': '-1.08',
 'close': '3925.22',
 'date': '2020-05-14',
 'max': '3952.20',
 'min': '3924.05',
 'name': '沪深300',
 'open': '3952.20',
 'volumn': '143499177719.80',
 'volumn_hand': '88530004.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '8.02',
 'change_rate': '0.20',
 'close': '3968.25',
 'date': '2020-05-13',
 'max': '3972.53',
 'min': '3932.57',
 'name': '沪深300',
 'open': '3946.64',
 'volumn': '145563383275.80',
 'volumn_hand': '88190669.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '0.06',
 'change_rate': '0.00',
 'close': '3960.24',
 'date': '2020-05-12',
 'max': '3970.11',
 'min': '3930.21',
 'name': '沪深300',
 'open': '3961.34',
 'volumn': '157465780059.90',
 'volumn_hand': '98250554.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-3.44',
 'change_rate': '-0.09',
 'close': '3960.18',
 'date': '2020-05-11',
 'max': '3998.10',
 'min': '3944.50',
 'name': '沪深300',
 'open': '3974.76',
 'volumn': '193758093899.80',
 'volumn_hand': '122673803.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '38.73',
 'change_rate': '0.99',
 'close': '3963.62',
 'date': '2020-05-08',
 'max': '3979.66',
 'min': '3935.98',
 'name': '沪深300',
 'open': '3943.00',
 'volumn': '190299584716.90',
 'volumn_hand': '116943341.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-11.36',
 'change_rate': '-0.29',
 'close': '3924.89',
 'date': '2020-05-07',
 'max': '3941.48',
 'min': '3915.90',
 'name': '沪深300',
 'open': '3937.59',
 'volumn': '167207801840.20',
 'volumn_hand': '105514646.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '23.68',
 'change_rate': '0.61',
 'close': '3936.25',
 'date': '2020-05-06',
 'max': '3937.69',
 'min': '3865.99',
 'name': '沪深300',
 'open': '3867.26',
 'volumn': '214935962364.40',
 'volumn_hand': '139855675.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-05-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-23.15',
 'change_rate': '-0.55',
 'close': '4166.73',
 'date': '2020-01-15',
 'max': '4193.87',
 'min': '4150.88',
 'name': '沪深300',
 'open': '4186.88',
 'volumn': '163081930622.40',
 'volumn_hand': '104633136.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-14.10',
 'change_rate': '-0.34',
 'close': '4189.89',
 'date': '2020-01-14',
 'max': '4223.51',
 'min': '4188.08',
 'name': '沪深300',
 'open': '4215.16',
 'volumn': '196221263395.60',
 'volumn_hand': '129320783.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '40.80',
 'change_rate': '0.98',
 'close': '4203.99',
 'date': '2020-01-13',
 'max': '4203.99',
 'min': '4148.60',
 'name': '沪深300',
 'open': '4166.93',
 'volumn': '199795489709.10',
 'volumn_hand': '119691982.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-1.18',
 'change_rate': '-0.03',
 'close': '4163.18',
 'date': '2020-01-10',
 'max': '4180.98',
 'min': '4148.48',
 'name': '沪深300',
 'open': '4177.58',
 'volumn': '177827413709.30',
 'volumn_hand': '113031719.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '52.05',
 'change_rate': '1.27',
 'close': '4164.37',
 'date': '2020-01-09',
 'max': '4165.66',
 'min': '4143.59',
 'name': '沪深300',
 'open': '4145.53',
 'volumn': '200150352941.60',
 'volumn_hand': '136886324.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-47.91',
 'change_rate': '-1.15',
 'close': '4112.32',
 'date': '2020-01-08',
 'max': '4149.81',
 'min': '4101.98',
 'name': '沪深300',
 'open': '4139.63',
 'volumn': '212406263857.30',
 'volumn_hand': '167585850.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '30.93',
 'change_rate': '0.75',
 'close': '4160.23',
 'date': '2020-01-07',
 'max': '4161.25',
 'min': '4135.10',
 'name': '沪深300',
 'open': '4137.40',
 'volumn': '196389059714.70',
 'volumn_hand': '139489031.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-15.67',
 'change_rate': '-0.38',
 'close': '4129.30',
 'date': '2020-01-06',
 'max': '4170.64',
 'min': '4102.38',
 'name': '沪深300',
 'open': '4120.52',
 'volumn': '250182071293.90',
 'volumn_hand': '175309953.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-7.28',
 'change_rate': '-0.18',
 'close': '4144.96',
 'date': '2020-01-03',
 'max': '4164.30',
 'min': '4131.86',
 'name': '沪深300',
 'open': '4161.22',
 'volumn': '215216288331.30',
 'volumn_hand': '142826244.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '55.66',
 'change_rate': '1.36',
 'close': '4152.24',
 'date': '2020-01-02',
 'max': '4172.66',
 'min': '4121.35',
 'name': '沪深300',
 'open': '4121.35',
 'volumn': '270105532027.60',
 'volumn_hand': '182116772.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-01-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '250.50',
 'change_rate': '5.67',
 'close': '4670.09',
 'date': '2020-07-06',
 'max': '4678.11',
 'min': '4465.81',
 'name': '沪深300',
 'open': '4465.81',
 'volumn': '597438217715.60',
 'volumn_hand': '405821025.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '83.75',
 'change_rate': '1.93',
 'close': '4419.60',
 'date': '2020-07-03',
 'max': '4419.60',
 'min': '4348.45',
 'name': '沪深300',
 'open': '4353.19',
 'volumn': '442335024266.10',
 'volumn_hand': '290485539.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '88.06',
 'change_rate': '2.07',
 'close': '4335.84',
 'date': '2020-07-02',
 'max': '4340.10',
 'min': '4238.12',
 'name': '沪深300',
 'open': '4239.41',
 'volumn': '399571526695.30',
 'volumn_hand': '252939368.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '83.82',
 'change_rate': '2.01',
 'close': '4247.78',
 'date': '2020-07-01',
 'max': '4247.78',
 'min': '4163.50',
 'name': '沪深300',
 'open': '4172.64',
 'volumn': '305711799761.90',
 'volumn_hand': '169990456.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-07-01' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '45.55',
 'change_rate': '1.18',
 'close': '3912.58',
 'date': '2020-04-30',
 'max': '3921.70',
 'min': '3880.41',
 'name': '沪深300',
 'open': '3880.41',
 'volumn': '202268288802.30',
 'volumn_hand': '132917125.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '17.89',
 'change_rate': '0.46',
 'close': '3867.03',
 'date': '2020-04-29',
 'max': '3880.74',
 'min': '3833.72',
 'name': '沪深300',
 'open': '3837.51',
 'volumn': '151282103744.20',
 'volumn_hand': '95854590.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '26.38',
 'change_rate': '0.69',
 'close': '3849.15',
 'date': '2020-04-28',
 'max': '3859.68',
 'min': '3768.20',
 'name': '沪深300',
 'open': '3835.35',
 'volumn': '184179759240.30',
 'volumn_hand': '122093476.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '25.80',
 'change_rate': '0.68',
 'close': '3822.77',
 'date': '2020-04-27',
 'max': '3842.87',
 'min': '3793.77',
 'name': '沪深300',
 'open': '3808.02',
 'volumn': '145301151875.00',
 'volumn_hand': '95462735.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-32.78',
 'change_rate': '-0.86',
 'close': '3796.97',
 'date': '2020-04-24',
 'max': '3827.21',
 'min': '3787.07',
 'name': '沪深300',
 'open': '3826.31',
 'volumn': '138961200282.70',
 'volumn_hand': '94844135.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-9.63',
 'change_rate': '-0.25',
 'close': '3829.75',
 'date': '2020-04-23',
 'max': '3857.47',
 'min': '3826.56',
 'name': '沪深300',
 'open': '3851.91',
 'volumn': '142122548831.80',
 'volumn_hand': '95508450.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '31.34',
 'change_rate': '0.82',
 'close': '3839.38',
 'date': '2020-04-22',
 'max': '3839.38',
 'min': '3782.21',
 'name': '沪深300',
 'open': '3789.13',
 'volumn': '135547280790.20',
 'volumn_hand': '85899464.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-45.41',
 'change_rate': '-1.18',
 'close': '3808.05',
 'date': '2020-04-21',
 'max': '3838.23',
 'min': '3780.00',
 'name': '沪深300',
 'open': '3838.23',
 'volumn': '155077454132.00',
 'volumn_hand': '102921888.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '13.97',
 'change_rate': '0.36',
 'close': '3853.46',
 'date': '2020-04-20',
 'max': '3853.80',
 'min': '3831.55',
 'name': '沪深300',
 'open': '3845.46',
 'volumn': '151924090116.60',
 'volumn_hand': '100013115.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '37.11',
 'change_rate': '0.98',
 'close': '3839.49',
 'date': '2020-04-17',
 'max': '3863.45',
 'min': '3821.42',
 'name': '沪深300',
 'open': '3831.92',
 'volumn': '203595267033.50',
 'volumn_hand': '132004301.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '5.02',
 'change_rate': '0.13',
 'close': '3802.38',
 'date': '2020-04-16',
 'max': '3807.36',
 'min': '3774.56',
 'name': '沪深300',
 'open': '3777.80',
 'volumn': '147164302056.90',
 'volumn_hand': '95947965.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-28.34',
 'change_rate': '-0.74',
 'close': '3797.36',
 'date': '2020-04-15',
 'max': '3829.80',
 'min': '3793.44',
 'name': '沪深300',
 'open': '3820.85',
 'volumn': '169700216633.00',
 'volumn_hand': '108461984.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '72.44',
 'change_rate': '1.93',
 'close': '3825.70',
 'date': '2020-04-14',
 'max': '3825.76',
 'min': '3764.98',
 'name': '沪深300',
 'open': '3777.83',
 'volumn': '170612579792.40',
 'volumn_hand': '110637585.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-15.92',
 'change_rate': '-0.42',
 'close': '3753.26',
 'date': '2020-04-13',
 'max': '3769.88',
 'min': '3740.19',
 'name': '沪深300',
 'open': '3751.71',
 'volumn': '119874303204.60',
 'volumn_hand': '79053343.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-23.63',
 'change_rate': '-0.62',
 'close': '3769.18',
 'date': '2020-04-10',
 'max': '3824.74',
 'min': '3758.96',
 'name': '沪深300',
 'open': '3794.84',
 'volumn': '162251233800.70',
 'volumn_hand': '102444956.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '12.47',
 'change_rate': '0.33',
 'close': '3792.81',
 'date': '2020-04-09',
 'max': '3801.72',
 'min': '3785.31',
 'name': '沪深300',
 'open': '3798.49',
 'volumn': '154595318812.80',
 'volumn_hand': '100485032.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-17.68',
 'change_rate': '-0.47',
 'close': '3780.34',
 'date': '2020-04-08',
 'max': '3793.00',
 'min': '3767.29',
 'name': '沪深300',
 'open': '3776.42',
 'volumn': '161576772320.20',
 'volumn_hand': '111389513.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '84.80',
 'change_rate': '2.28',
 'close': '3798.02',
 'date': '2020-04-07',
 'max': '3803.63',
 'min': '3772.21',
 'name': '沪深300',
 'open': '3779.91',
 'volumn': '207642820316.90',
 'volumn_hand': '142778030.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-21.31',
 'change_rate': '-0.57',
 'close': '3713.22',
 'date': '2020-04-03',
 'max': '3738.83',
 'min': '3698.98',
 'name': '沪深300',
 'open': '3721.48',
 'volumn': '150132815028.50',
 'volumn_hand': '99825083.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '59.45',
 'change_rate': '1.62',
 'close': '3734.53',
 'date': '2020-04-02',
 'max': '3734.53',
 'min': '3652.32',
 'name': '沪深300',
 'open': '3656.32',
 'volumn': '168893255656.60',
 'volumn_hand': '115168209.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'change': '-11.08',
 'change_rate': '-0.30',
 'close': '3675.08',
 'date': '2020-04-01',
 'max': '3731.78',
 'min': '3670.97',
 'name': '沪深300',
 'open': '3682.30',
 'volumn': '170422568804.40',
 'volumn_hand': '119352620.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '沪深300-2020-04-01' for key 'uk_t_1'")
2020-08-02 22:59:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=2&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399300.html?year=2&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=0&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=0&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=2&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=0&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=2&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '23.18',
 'change_rate': '0.71',
 'close': '3310.01',
 'date': '2020-07-31',
 'max': '3333.79',
 'min': '3261.61',
 'name': '上证指数',
 'open': '3280.80',
 'volumn': '495778040702.20',
 'volumn_hand': '3537589.79'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-31' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-7.73',
 'change_rate': '-0.23',
 'close': '3286.82',
 'date': '2020-07-30',
 'max': '3312.45',
 'min': '3282.16',
 'name': '上证指数',
 'open': '3299.57',
 'volumn': '476974005608.80',
 'volumn_hand': '3407041.21'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '66.59',
 'change_rate': '2.06',
 'close': '3294.55',
 'date': '2020-07-29',
 'max': '3294.55',
 'min': '3209.99',
 'name': '上证指数',
 'open': '3221.99',
 'volumn': '453094399515.50',
 'volumn_hand': '3249240.62'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '22.73',
 'change_rate': '0.71',
 'close': '3227.96',
 'date': '2020-07-28',
 'max': '3245.30',
 'min': '3208.49',
 'name': '上证指数',
 'open': '3226.13',
 'volumn': '389873696214.70',
 'volumn_hand': '2893778.61'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '8.46',
 'change_rate': '0.26',
 'close': '3205.23',
 'date': '2020-07-27',
 'max': '3221.98',
 'min': '3174.66',
 'name': '上证指数',
 'open': '3210.39',
 'volumn': '402231919288.90',
 'volumn_hand': '2993190.21'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-128.34',
 'change_rate': '-3.86',
 'close': '3196.77',
 'date': '2020-07-24',
 'max': '3319.13',
 'min': '3184.96',
 'name': '上证指数',
 'open': '3310.64',
 'volumn': '584311865016.60',
 'volumn_hand': '4270540.26'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-8.05',
 'change_rate': '-0.24',
 'close': '3325.11',
 'date': '2020-07-23',
 'max': '3336.30',
 'min': '3257.83',
 'name': '上证指数',
 'open': '3306.15',
 'volumn': '546887089707.70',
 'volumn_hand': '4070424.99'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '12.27',
 'change_rate': '0.37',
 'close': '3333.16',
 'date': '2020-07-22',
 'max': '3381.98',
 'min': '3311.79',
 'name': '上证指数',
 'open': '3315.18',
 'volumn': '540577040593.60',
 'volumn_hand': '3933353.35'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '6.75',
 'change_rate': '0.20',
 'close': '3320.89',
 'date': '2020-07-21',
 'max': '3336.68',
 'min': '3300.57',
 'name': '上证指数',
 'open': '3330.55',
 'volumn': '488862180370.50',
 'volumn_hand': '3592520.29'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '100.02',
 'change_rate': '3.11',
 'close': '3314.15',
 'date': '2020-07-20',
 'max': '3314.15',
 'min': '3220.68',
 'name': '上证指数',
 'open': '3243.91',
 'volumn': '544045656232.30',
 'volumn_hand': '4185553.06'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '4.03',
 'change_rate': '0.13',
 'close': '3214.13',
 'date': '2020-07-17',
 'max': '3252.78',
 'min': '3181.27',
 'name': '上证指数',
 'open': '3214.40',
 'volumn': '486536118268.80',
 'volumn_hand': '3596524.13'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-151.21',
 'change_rate': '-4.50',
 'close': '3210.10',
 'date': '2020-07-16',
 'max': '3373.53',
 'min': '3209.73',
 'name': '上证指数',
 'open': '3356.36',
 'volumn': '679468340648.50',
 'volumn_hand': '4906131.23'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-53.31',
 'change_rate': '-1.56',
 'close': '3361.30',
 'date': '2020-07-15',
 'max': '3432.45',
 'min': '3345.75',
 'name': '上证指数',
 'open': '3422.08',
 'volumn': '674727409786.30',
 'volumn_hand': '4920305.42'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-28.67',
 'change_rate': '-0.83',
 'close': '3414.62',
 'date': '2020-07-14',
 'max': '3451.22',
 'min': '3366.08',
 'name': '上证指数',
 'open': '3435.02',
 'volumn': '707327005157.30',
 'volumn_hand': '5432114.92'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '59.96',
 'change_rate': '1.77',
 'close': '3443.29',
 'date': '2020-07-13',
 'max': '3458.79',
 'min': '3369.04',
 'name': '上证指数',
 'open': '3379.39',
 'volumn': '717397053099.20',
 'volumn_hand': '5580068.75'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-67.27',
 'change_rate': '-1.95',
 'close': '3383.32',
 'date': '2020-07-10',
 'max': '3433.11',
 'min': '3372.51',
 'name': '上证指数',
 'open': '3418.93',
 'volumn': '703197550444.50',
 'volumn_hand': '5561200.11'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '47.15',
 'change_rate': '1.39',
 'close': '3450.59',
 'date': '2020-07-09',
 'max': '3456.97',
 'min': '3393.64',
 'name': '上证指数',
 'open': '3403.48',
 'volumn': '751406830395.10',
 'volumn_hand': '6200018.23'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '58.10',
 'change_rate': '1.74',
 'close': '3403.44',
 'date': '2020-07-08',
 'max': '3421.53',
 'min': '3327.71',
 'name': '上证指数',
 'open': '3337.55',
 'volumn': '696807634537.90',
 'volumn_hand': '5870816.85'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '12.46',
 'change_rate': '0.37',
 'close': '3345.34',
 'date': '2020-07-07',
 'max': '3407.08',
 'min': '3336.24',
 'name': '上证指数',
 'open': '3380.95',
 'volumn': '793638372424.80',
 'volumn_hand': '6578401.59'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '180.07',
 'change_rate': '5.71',
 'close': '3332.88',
 'date': '2020-07-06',
 'max': '3337.27',
 'min': '3187.84',
 'name': '上证指数',
 'open': '3187.84',
 'volumn': '724153675700.80',
 'volumn_hand': '6438789.06'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '62.24',
 'change_rate': '2.01',
 'close': '3152.81',
 'date': '2020-07-03',
 'max': '3152.81',
 'min': '3104.00',
 'name': '上证指数',
 'open': '3104.00',
 'volumn': '535489334735.20',
 'volumn_hand': '4587938.51'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '64.59',
 'change_rate': '2.13',
 'close': '3090.57',
 'date': '2020-07-02',
 'max': '3092.44',
 'min': '3021.67',
 'name': '上证指数',
 'open': '3023.72',
 'volumn': '478216482346.40',
 'volumn_hand': '3911279.96'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '23.16',
 'change_rate': '0.78',
 'close': '2984.67',
 'date': '2020-06-30',
 'max': '2990.83',
 'min': '2965.11',
 'name': '上证指数',
 'open': '2965.11',
 'volumn': '297312328413.80',
 'volumn_hand': '2149572.14'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-18.03',
 'change_rate': '-0.61',
 'close': '2961.52',
 'date': '2020-06-29',
 'max': '2977.91',
 'min': '2951.77',
 'name': '上证指数',
 'open': '2973.08',
 'volumn': '293886016005.30',
 'volumn_hand': '2206227.29'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '8.93',
 'change_rate': '0.30',
 'close': '2979.55',
 'date': '2020-06-24',
 'max': '2982.94',
 'min': '2971.22',
 'name': '上证指数',
 'open': '2972.98',
 'volumn': '297008784132.40',
 'volumn_hand': '2132007.32'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '5.35',
 'change_rate': '0.18',
 'close': '2970.62',
 'date': '2020-06-23',
 'max': '2972.40',
 'min': '2949.85',
 'name': '上证指数',
 'open': '2960.89',
 'volumn': '305378770529.90',
 'volumn_hand': '2252122.08'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-2.36',
 'change_rate': '-0.08',
 'close': '2965.27',
 'date': '2020-06-22',
 'max': '2983.44',
 'min': '2959.04',
 'name': '上证指数',
 'open': '2966.90',
 'volumn': '346028748359.10',
 'volumn_hand': '2678838.34'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '28.32',
 'change_rate': '0.96',
 'close': '2967.63',
 'date': '2020-06-19',
 'max': '2973.32',
 'min': '2935.82',
 'name': '上证指数',
 'open': '2938.79',
 'volumn': '319089106631.70',
 'volumn_hand': '2643139.61'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '3.44',
 'change_rate': '0.12',
 'close': '2939.32',
 'date': '2020-06-18',
 'max': '2942.90',
 'min': '2920.11',
 'name': '上证指数',
 'open': '2929.88',
 'volumn': '289367727804.20',
 'volumn_hand': '2586913.77'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '4.12',
 'change_rate': '0.14',
 'close': '2935.87',
 'date': '2020-06-17',
 'max': '2936.62',
 'min': '2919.04',
 'name': '上证指数',
 'open': '2932.67',
 'volumn': '278007110729.60',
 'volumn_hand': '2346543.91'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '41.72',
 'change_rate': '1.44',
 'close': '2931.75',
 'date': '2020-06-16',
 'max': '2931.78',
 'min': '2909.13',
 'name': '上证指数',
 'open': '2912.83',
 'volumn': '270948558455.00',
 'volumn_hand': '2233130.65'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '41.31',
 'change_rate': '1.38',
 'close': '3025.98',
 'date': '2020-07-01',
 'max': '3026.19',
 'min': '2984.98',
 'name': '上证指数',
 'open': '2991.18',
 'volumn': '369883802296.70',
 'volumn_hand': '2733131.4'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-07-01' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-29.71',
 'change_rate': '-1.02',
 'close': '2890.03',
 'date': '2020-06-15',
 'max': '2922.54',
 'min': '2890.03',
 'name': '上证指数',
 'open': '2908.28',
 'volumn': '293361556833.60',
 'volumn_hand': '2432050.46'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-1.16',
 'change_rate': '-0.04',
 'close': '2919.74',
 'date': '2020-06-12',
 'max': '2930.26',
 'min': '2872.62',
 'name': '上证指数',
 'open': '2876.80',
 'volumn': '274321726179.00',
 'volumn_hand': '2360086.42'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-22.86',
 'change_rate': '-0.78',
 'close': '2920.90',
 'date': '2020-06-11',
 'max': '2952.65',
 'min': '2912.19',
 'name': '上证指数',
 'open': '2939.79',
 'volumn': '289023256107.00',
 'volumn_hand': '2337229.47'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-12.36',
 'change_rate': '-0.42',
 'close': '2943.75',
 'date': '2020-06-10',
 'max': '2951.33',
 'min': '2934.84',
 'name': '上证指数',
 'open': '2951.28',
 'volumn': '243968496538.10',
 'volumn_hand': '2079259.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '18.34',
 'change_rate': '0.62',
 'close': '2956.11',
 'date': '2020-06-09',
 'max': '2957.12',
 'min': '2932.94',
 'name': '上证指数',
 'open': '2939.54',
 'volumn': '251414696239.60',
 'volumn_hand': '2090485.85'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '6.97',
 'change_rate': '0.24',
 'close': '2937.77',
 'date': '2020-06-08',
 'max': '2950.07',
 'min': '2934.21',
 'name': '上证指数',
 'open': '2941.98',
 'volumn': '274611815611.00',
 'volumn_hand': '2311243.6'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '11.55',
 'change_rate': '0.40',
 'close': '2930.80',
 'date': '2020-06-05',
 'max': '2930.80',
 'min': '2909.12',
 'name': '上证指数',
 'open': '2923.19',
 'volumn': '253141142477.60',
 'volumn_hand': '2173606.73'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-05' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-4.12',
 'change_rate': '-0.14',
 'close': '2919.25',
 'date': '2020-06-04',
 'max': '2932.97',
 'min': '2910.75',
 'name': '上证指数',
 'open': '2931.84',
 'volumn': '254345984480.00',
 'volumn_hand': '2266058.73'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-04' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '1.97',
 'change_rate': '0.07',
 'close': '2923.37',
 'date': '2020-06-03',
 'max': '2942.76',
 'min': '2922.66',
 'name': '上证指数',
 'open': '2930.39',
 'volumn': '300447817007.30',
 'volumn_hand': '2556639.8'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '5.97',
 'change_rate': '0.20',
 'close': '2921.40',
 'date': '2020-06-02',
 'max': '2926.36',
 'min': '2909.13',
 'name': '上证指数',
 'open': '2916.32',
 'volumn': '294402745887.80',
 'volumn_hand': '2561080.49'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '63.08',
 'change_rate': '2.21',
 'close': '2915.43',
 'date': '2020-06-01',
 'max': '2917.15',
 'min': '2871.96',
 'name': '上证指数',
 'open': '2871.96',
 'volumn': '307416215147.80',
 'volumn_hand': '2601960.5'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-06-01' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '6.13',
 'change_rate': '0.22',
 'close': '2852.35',
 'date': '2020-05-29',
 'max': '2855.38',
 'min': '2829.63',
 'name': '上证指数',
 'open': '2835.58',
 'volumn': '233798996642.70',
 'volumn_hand': '2067928.04'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '9.42',
 'change_rate': '0.33',
 'close': '2846.22',
 'date': '2020-05-28',
 'max': '2861.92',
 'min': '2820.15',
 'name': '上证指数',
 'open': '2838.21',
 'volumn': '239234260635.90',
 'volumn_hand': '2075460.19'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-9.74',
 'change_rate': '-0.34',
 'close': '2836.80',
 'date': '2020-05-27',
 'max': '2849.00',
 'min': '2831.93',
 'name': '上证指数',
 'open': '2847.32',
 'volumn': '227934395739.40',
 'volumn_hand': '1981493.43'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '28.58',
 'change_rate': '1.01',
 'close': '2846.55',
 'date': '2020-05-26',
 'max': '2848.34',
 'min': '2825.90',
 'name': '上证指数',
 'open': '2827.90',
 'volumn': '207427833710.60',
 'volumn_hand': '1745623.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-26' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '4.20',
 'change_rate': '0.15',
 'close': '2817.97',
 'date': '2020-05-25',
 'max': '2821.50',
 'min': '2802.47',
 'name': '上证指数',
 'open': '2816.24',
 'volumn': '202115352627.30',
 'volumn_hand': '1728855.57'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-25' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-54.16',
 'change_rate': '-1.89',
 'close': '2813.77',
 'date': '2020-05-22',
 'max': '2863.05',
 'min': '2808.02',
 'name': '上证指数',
 'open': '2863.05',
 'volumn': '245229603697.90',
 'volumn_hand': '2090637.12'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-15.81',
 'change_rate': '-0.55',
 'close': '2867.92',
 'date': '2020-05-21',
 'max': '2891.52',
 'min': '2864.21',
 'name': '上证指数',
 'open': '2890.72',
 'volumn': '250569937552.80',
 'volumn_hand': '2035320.38'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-14.84',
 'change_rate': '-0.51',
 'close': '2883.74',
 'date': '2020-05-20',
 'max': '2896.47',
 'min': '2876.18',
 'name': '上证指数',
 'open': '2896.47',
 'volumn': '269176553624.70',
 'volumn_hand': '2105199.85'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '23.16',
 'change_rate': '0.81',
 'close': '2898.58',
 'date': '2020-05-19',
 'max': '2900.22',
 'min': '2887.58',
 'name': '上证指数',
 'open': '2897.69',
 'volumn': '256277803071.80',
 'volumn_hand': '1972224.05'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '6.96',
 'change_rate': '0.24',
 'close': '2875.42',
 'date': '2020-05-18',
 'max': '2889.98',
 'min': '2862.27',
 'name': '上证指数',
 'open': '2872.52',
 'volumn': '289089595543.40',
 'volumn_hand': '2260228.82'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-1.88',
 'change_rate': '-0.07',
 'close': '2868.46',
 'date': '2020-05-15',
 'max': '2884.22',
 'min': '2863.37',
 'name': '上证指数',
 'open': '2880.71',
 'volumn': '246878191080.50',
 'volumn_hand': '1889835.92'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-27.71',
 'change_rate': '-0.96',
 'close': '2870.34',
 'date': '2020-05-14',
 'max': '2887.06',
 'min': '2869.18',
 'name': '上证指数',
 'open': '2887.06',
 'volumn': '237336974703.00',
 'volumn_hand': '1977762.02'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '6.49',
 'change_rate': '0.22',
 'close': '2898.05',
 'date': '2020-05-13',
 'max': '2900.26',
 'min': '2875.54',
 'name': '上证指数',
 'open': '2882.96',
 'volumn': '223866906923.50',
 'volumn_hand': '1850613.1'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-3.25',
 'change_rate': '-0.11',
 'close': '2891.56',
 'date': '2020-05-12',
 'max': '2897.90',
 'min': '2871.23',
 'name': '上证指数',
 'open': '2894.62',
 'volumn': '238476218839.00',
 'volumn_hand': '1970829.85'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-0.54',
 'change_rate': '-0.02',
 'close': '2894.80',
 'date': '2020-05-11',
 'max': '2914.28',
 'min': '2884.38',
 'name': '上证指数',
 'open': '2901.57',
 'volumn': '271930641512.40',
 'volumn_hand': '2251204.1'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '23.82',
 'change_rate': '0.83',
 'close': '2895.34',
 'date': '2020-05-08',
 'max': '2903.80',
 'min': '2879.20',
 'name': '上证指数',
 'open': '2882.71',
 'volumn': '276562716950.30',
 'volumn_hand': '2268220.75'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-6.62',
 'change_rate': '-0.23',
 'close': '2871.52',
 'date': '2020-05-07',
 'max': '2882.02',
 'min': '2864.58',
 'name': '上证指数',
 'open': '2876.47',
 'volumn': '268607485283.60',
 'volumn_hand': '2267369.57'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '18.06',
 'change_rate': '0.63',
 'close': '2878.14',
 'date': '2020-05-06',
 'max': '2879.26',
 'min': '2830.65',
 'name': '上证指数',
 'open': '2831.63',
 'volumn': '303890031004.90',
 'volumn_hand': '2498266.16'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-05-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '37.64',
 'change_rate': '1.33',
 'close': '2860.08',
 'date': '2020-04-30',
 'max': '2865.59',
 'min': '2832.38',
 'name': '上证指数',
 'open': '2832.38',
 'volumn': '277440934007.10',
 'volumn_hand': '2424552.78'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '12.42',
 'change_rate': '0.44',
 'close': '2822.44',
 'date': '2020-04-29',
 'max': '2831.76',
 'min': '2800.74',
 'name': '上证指数',
 'open': '2801.38',
 'volumn': '222720221727.90',
 'volumn_hand': '2020618.07'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-5.47',
 'change_rate': '-0.19',
 'close': '2810.02',
 'date': '2020-04-28',
 'max': '2821.75',
 'min': '2758.25',
 'name': '上证指数',
 'open': '2819.99',
 'volumn': '270534752615.10',
 'volumn_hand': '2538727.45'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '6.97',
 'change_rate': '0.25',
 'close': '2815.49',
 'date': '2020-04-27',
 'max': '2832.67',
 'min': '2802.96',
 'name': '上证指数',
 'open': '2812.24',
 'volumn': '225293706288.50',
 'volumn_hand': '2101309.81'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-29.97',
 'change_rate': '-1.06',
 'close': '2808.53',
 'date': '2020-04-24',
 'max': '2834.94',
 'min': '2802.50',
 'name': '上证指数',
 'open': '2834.94',
 'volumn': '244122291476.80',
 'volumn_hand': '2351850.76'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-5.48',
 'change_rate': '-0.19',
 'close': '2838.50',
 'date': '2020-04-23',
 'max': '2853.64',
 'min': '2835.90',
 'name': '上证指数',
 'open': '2850.51',
 'volumn': '262662040531.80',
 'volumn_hand': '2487790.37'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '16.97',
 'change_rate': '0.60',
 'close': '2843.98',
 'date': '2020-04-22',
 'max': '2843.98',
 'min': '2808.48',
 'name': '上证指数',
 'open': '2814.07',
 'volumn': '232796777750.20',
 'volumn_hand': '2173200.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-25.54',
 'change_rate': '-0.90',
 'close': '2827.01',
 'date': '2020-04-21',
 'max': '2842.24',
 'min': '2808.02',
 'name': '上证指数',
 'open': '2842.24',
 'volumn': '248688585735.60',
 'volumn_hand': '2332358.7'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '14.06',
 'change_rate': '0.50',
 'close': '2852.55',
 'date': '2020-04-20',
 'max': '2852.99',
 'min': '2833.26',
 'name': '上证指数',
 'open': '2840.41',
 'volumn': '233759313192.60',
 'volumn_hand': '2118470.78'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '18.56',
 'change_rate': '0.66',
 'close': '2838.49',
 'date': '2020-04-17',
 'max': '2854.96',
 'min': '2830.02',
 'name': '上证指数',
 'open': '2835.56',
 'volumn': '280025229139.50',
 'volumn_hand': '2457367.5'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '8.76',
 'change_rate': '0.31',
 'close': '2819.94',
 'date': '2020-04-16',
 'max': '2823.34',
 'min': '2796.84',
 'name': '上证指数',
 'open': '2798.43',
 'volumn': '222432600865.70',
 'volumn_hand': '2030037.73'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-16.11',
 'change_rate': '-0.57',
 'close': '2811.17',
 'date': '2020-04-15',
 'max': '2829.75',
 'min': '2808.70',
 'name': '上证指数',
 'open': '2826.66',
 'volumn': '231631632235.00',
 'volumn_hand': '2056211.46'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '44.24',
 'change_rate': '1.59',
 'close': '2827.28',
 'date': '2020-04-14',
 'max': '2827.30',
 'min': '2789.43',
 'name': '上证指数',
 'open': '2794.80',
 'volumn': '223605697288.90',
 'volumn_hand': '2026965.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-13.58',
 'change_rate': '-0.49',
 'close': '2783.05',
 'date': '2020-04-13',
 'max': '2792.89',
 'min': '2774.08',
 'name': '上证指数',
 'open': '2784.60',
 'volumn': '184120284139.70',
 'volumn_hand': '1771245.54'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-29.27',
 'change_rate': '-1.04',
 'close': '2796.63',
 'date': '2020-04-10',
 'max': '2833.01',
 'min': '2789.98',
 'name': '上证指数',
 'open': '2827.19',
 'volumn': '246376307236.70',
 'volumn_hand': '2334547.68'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '10.54',
 'change_rate': '0.37',
 'close': '2825.90',
 'date': '2020-04-09',
 'max': '2832.40',
 'min': '2820.43',
 'name': '上证指数',
 'open': '2825.84',
 'volumn': '247392988028.60',
 'volumn_hand': '2381848.43'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-5.39',
 'change_rate': '-0.19',
 'close': '2815.37',
 'date': '2020-04-08',
 'max': '2823.21',
 'min': '2800.30',
 'name': '上证指数',
 'open': '2805.92',
 'volumn': '253159668052.30',
 'volumn_hand': '2435153.05'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '56.78',
 'change_rate': '2.05',
 'close': '2820.76',
 'date': '2020-04-07',
 'max': '2823.28',
 'min': '2801.84',
 'name': '上证指数',
 'open': '2806.97',
 'volumn': '286627794328.10',
 'volumn_hand': '2701981.86'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-16.65',
 'change_rate': '-0.60',
 'close': '2763.99',
 'date': '2020-04-03',
 'max': '2780.59',
 'min': '2754.07',
 'name': '上证指数',
 'open': '2773.58',
 'volumn': '214062212038.20',
 'volumn_hand': '2008374.04'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '46.12',
 'change_rate': '1.69',
 'close': '2780.64',
 'date': '2020-04-02',
 'max': '2780.64',
 'min': '2719.90',
 'name': '上证指数',
 'open': '2720.23',
 'volumn': '233111575711.20',
 'volumn_hand': '2178646.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-15.77',
 'change_rate': '-0.57',
 'close': '2734.52',
 'date': '2020-04-01',
 'max': '2773.36',
 'min': '2731.08',
 'name': '上证指数',
 'open': '2743.54',
 'volumn': '225624646571.60',
 'volumn_hand': '2172534.27'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-04-01' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=2&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=2&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_000001.html?year=0&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '3.08',
 'change_rate': '0.11',
 'close': '2750.30',
 'date': '2020-03-31',
 'max': '2771.17',
 'min': '2743.12',
 'name': '上证指数',
 'open': '2767.31',
 'volumn': '224271061569.10',
 'volumn_hand': '2185986.74'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-31' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-24.99',
 'change_rate': '-0.90',
 'close': '2747.21',
 'date': '2020-03-30',
 'max': '2759.10',
 'min': '2723.05',
 'name': '上证指数',
 'open': '2739.72',
 'volumn': '250687144232.80',
 'volumn_hand': '2397066.04'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '7.29',
 'change_rate': '0.26',
 'close': '2772.20',
 'date': '2020-03-27',
 'max': '2805.55',
 'min': '2771.76',
 'name': '上证指数',
 'open': '2792.98',
 'volumn': '253630725892.30',
 'volumn_hand': '2407640.66'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-16.68',
 'change_rate': '-0.60',
 'close': '2764.91',
 'date': '2020-03-26',
 'max': '2788.50',
 'min': '2753.43',
 'name': '上证指数',
 'open': '2761.90',
 'volumn': '248279785000.70',
 'volumn_hand': '2340840.22'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-26' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '59.15',
 'change_rate': '2.17',
 'close': '2781.59',
 'date': '2020-03-25',
 'max': '2788.64',
 'min': '2757.80',
 'name': '上证指数',
 'open': '2775.30',
 'volumn': '293191204398.70',
 'volumn_hand': '2731444.66'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-25' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '62.27',
 'change_rate': '2.34',
 'close': '2722.44',
 'date': '2020-03-24',
 'max': '2723.41',
 'min': '2667.13',
 'name': '上证指数',
 'open': '2703.02',
 'volumn': '278999306643.20',
 'volumn_hand': '2570219.3'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-85.45',
 'change_rate': '-3.11',
 'close': '2660.17',
 'date': '2020-03-23',
 'max': '2703.33',
 'min': '2656.50',
 'name': '上证指数',
 'open': '2677.59',
 'volumn': '268423241973.70',
 'volumn_hand': '2498202.5'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '43.49',
 'change_rate': '1.61',
 'close': '2745.62',
 'date': '2020-03-20',
 'max': '2751.90',
 'min': '2702.49',
 'name': '上证指数',
 'open': '2727.02',
 'volumn': '281583369664.40',
 'volumn_hand': '2520195.07'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-26.63',
 'change_rate': '-0.98',
 'close': '2702.13',
 'date': '2020-03-19',
 'max': '2736.82',
 'min': '2646.80',
 'name': '上证指数',
 'open': '2719.41',
 'volumn': '330518008489.80',
 'volumn_hand': '3023027.47'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-50.88',
 'change_rate': '-1.83',
 'close': '2728.76',
 'date': '2020-03-18',
 'max': '2815.87',
 'min': '2728.76',
 'name': '上证指数',
 'open': '2792.32',
 'volumn': '318611391559.40',
 'volumn_hand': '2911598.52'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-9.61',
 'change_rate': '-0.34',
 'close': '2779.64',
 'date': '2020-03-17',
 'max': '2826.91',
 'min': '2715.22',
 'name': '上证指数',
 'open': '2796.28',
 'volumn': '323012822799.10',
 'volumn_hand': '3061496.77'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-98.17',
 'change_rate': '-3.40',
 'close': '2789.25',
 'date': '2020-03-16',
 'max': '2898.03',
 'min': '2784.66',
 'name': '上证指数',
 'open': '2897.30',
 'volumn': '375627000794.20',
 'volumn_hand': '3518786.65'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-36.06',
 'change_rate': '-1.23',
 'close': '2887.43',
 'date': '2020-03-13',
 'max': '2910.88',
 'min': '2799.98',
 'name': '上证指数',
 'open': '2804.23',
 'volumn': '393019665228.00',
 'volumn_hand': '3664504.36'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-45.03',
 'change_rate': '-1.52',
 'close': '2923.49',
 'date': '2020-03-12',
 'max': '2944.47',
 'min': '2906.28',
 'name': '上证指数',
 'open': '2936.02',
 'volumn': '328209202377.80',
 'volumn_hand': '3077784.57'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-28.24',
 'change_rate': '-0.94',
 'close': '2968.52',
 'date': '2020-03-11',
 'max': '3010.03',
 'min': '2968.52',
 'name': '上证指数',
 'open': '3001.76',
 'volumn': '378766618968.30',
 'volumn_hand': '3524709.7'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '53.47',
 'change_rate': '1.82',
 'close': '2996.76',
 'date': '2020-03-10',
 'max': '3000.30',
 'min': '2904.80',
 'name': '上证指数',
 'open': '2918.93',
 'volumn': '425017184790.90',
 'volumn_hand': '3932966.48'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-91.22',
 'change_rate': '-3.01',
 'close': '2943.29',
 'date': '2020-03-09',
 'max': '2989.21',
 'min': '2940.71',
 'name': '上证指数',
 'open': '2987.18',
 'volumn': '438143854609.80',
 'volumn_hand': '4145607.36'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-37.17',
 'change_rate': '-1.21',
 'close': '3034.51',
 'date': '2020-03-06',
 'max': '3052.44',
 'min': '3029.46',
 'name': '上证指数',
 'open': '3039.94',
 'volumn': '377388542662.40',
 'volumn_hand': '3620615.33'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '60.01',
 'change_rate': '1.99',
 'close': '3071.68',
 'date': '2020-03-05',
 'max': '3074.26',
 'min': '3022.93',
 'name': '上证指数',
 'open': '3036.15',
 'volumn': '482770471394.00',
 'volumn_hand': '4454258.06'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-05' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '18.77',
 'change_rate': '0.63',
 'close': '3011.67',
 'date': '2020-03-04',
 'max': '3012.00',
 'min': '2974.36',
 'name': '上证指数',
 'open': '2981.81',
 'volumn': '389893917454.80',
 'volumn_hand': '3533382.78'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-04' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '21.97',
 'change_rate': '0.74',
 'close': '2992.90',
 'date': '2020-03-03',
 'max': '3026.84',
 'min': '2976.62',
 'name': '上证指数',
 'open': '3006.89',
 'volumn': '447053681543.70',
 'volumn_hand': '4101080.47'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '90.63',
 'change_rate': '3.15',
 'close': '2970.93',
 'date': '2020-03-02',
 'max': '2982.51',
 'min': '2899.31',
 'name': '上证指数',
 'open': '2899.31',
 'volumn': '397244201180.30',
 'volumn_hand': '3673333.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-03-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-111.03',
 'change_rate': '-3.71',
 'close': '2880.30',
 'date': '2020-02-28',
 'max': '2948.13',
 'min': '2878.54',
 'name': '上证指数',
 'open': '2924.64',
 'volumn': '432657775045.30',
 'volumn_hand': '4012169.14'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '3.40',
 'change_rate': '0.11',
 'close': '2991.33',
 'date': '2020-02-27',
 'max': '3009.46',
 'min': '2980.48',
 'name': '上证指数',
 'open': '2992.49',
 'volumn': '395955641513.60',
 'volumn_hand': '3505236.58'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-25.12',
 'change_rate': '-0.83',
 'close': '2987.93',
 'date': '2020-02-26',
 'max': '3028.78',
 'min': '2974.94',
 'name': '上证指数',
 'open': '2978.42',
 'volumn': '495341447273.80',
 'volumn_hand': '4690495.52'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-26' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-18.18',
 'change_rate': '-0.60',
 'close': '3013.05',
 'date': '2020-02-25',
 'max': '3016.95',
 'min': '2943.72',
 'name': '上证指数',
 'open': '2982.07',
 'volumn': '513128644550.90',
 'volumn_hand': '4416227.62'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-25' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-8.44',
 'change_rate': '-0.28',
 'close': '3031.23',
 'date': '2020-02-24',
 'max': '3042.18',
 'min': '3007.36',
 'name': '上证指数',
 'open': '3027.89',
 'volumn': '451601363084.20',
 'volumn_hand': '3704300.44'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '9.52',
 'change_rate': '0.31',
 'close': '3039.67',
 'date': '2020-02-21',
 'max': '3058.90',
 'min': '3020.14',
 'name': '上证指数',
 'open': '3022.25',
 'volumn': '445062076684.30',
 'volumn_hand': '3645572.76'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '54.75',
 'change_rate': '1.84',
 'close': '3030.15',
 'date': '2020-02-20',
 'max': '3031.37',
 'min': '2968.45',
 'name': '上证指数',
 'open': '2981.88',
 'volumn': '413761364103.00',
 'volumn_hand': '3457328.81'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-9.57',
 'change_rate': '-0.32',
 'close': '2975.40',
 'date': '2020-02-19',
 'max': '2998.27',
 'min': '2971.82',
 'name': '上证指数',
 'open': '2979.52',
 'volumn': '381331160420.50',
 'volumn_hand': '3151411.51'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '1.35',
 'change_rate': '0.05',
 'close': '2984.97',
 'date': '2020-02-18',
 'max': '2990.60',
 'min': '2960.78',
 'name': '上证指数',
 'open': '2981.41',
 'volumn': '374998562648.50',
 'volumn_hand': '3116659.13'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '66.61',
 'change_rate': '2.28',
 'close': '2983.62',
 'date': '2020-02-17',
 'max': '2983.64',
 'min': '2924.99',
 'name': '上证指数',
 'open': '2924.99',
 'volumn': '367014340128.60',
 'volumn_hand': '3131980.07'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '10.93',
 'change_rate': '0.38',
 'close': '2917.01',
 'date': '2020-02-14',
 'max': '2926.94',
 'min': '2899.57',
 'name': '上证指数',
 'open': '2899.87',
 'volumn': '308080368725.80',
 'volumn_hand': '2506506.27'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-20.83',
 'change_rate': '-0.71',
 'close': '2906.07',
 'date': '2020-02-13',
 'max': '2935.41',
 'min': '2901.24',
 'name': '上证指数',
 'open': '2927.14',
 'volumn': '334526327364.00',
 'volumn_hand': '2748048.44'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '25.22',
 'change_rate': '0.87',
 'close': '2926.90',
 'date': '2020-02-12',
 'max': '2926.90',
 'min': '2892.42',
 'name': '上证指数',
 'open': '2895.56',
 'volumn': '297534420493.40',
 'volumn_hand': '2487334.29'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '11.19',
 'change_rate': '0.39',
 'close': '2901.67',
 'date': '2020-02-11',
 'max': '2913.82',
 'min': '2882.24',
 'name': '上证指数',
 'open': '2894.54',
 'volumn': '302956847206.30',
 'volumn_hand': '2691683.35'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '14.52',
 'change_rate': '0.51',
 'close': '2890.49',
 'date': '2020-02-10',
 'max': '2891.85',
 'min': '2851.05',
 'name': '上证指数',
 'open': '2860.50',
 'volumn': '341520398250.70',
 'volumn_hand': '2949297.84'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '9.45',
 'change_rate': '0.33',
 'close': '2875.96',
 'date': '2020-02-07',
 'max': '2875.96',
 'min': '2838.77',
 'name': '上证指数',
 'open': '2858.93',
 'volumn': '362384162463.90',
 'volumn_hand': '3094796.42'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '48.42',
 'change_rate': '1.72',
 'close': '2866.51',
 'date': '2020-02-06',
 'max': '2876.59',
 'min': '2807.61',
 'name': '上证指数',
 'open': '2826.89',
 'volumn': '358582589711.00',
 'volumn_hand': '3163921.42'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '34.80',
 'change_rate': '1.25',
 'close': '2818.09',
 'date': '2020-02-05',
 'max': '2842.74',
 'min': '2778.86',
 'name': '上证指数',
 'open': '2792.37',
 'volumn': '349184114812.60',
 'volumn_hand': '3097618.23'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-05' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '36.68',
 'change_rate': '1.34',
 'close': '2783.29',
 'date': '2020-02-04',
 'max': '2786.16',
 'min': '2685.27',
 'name': '上证指数',
 'open': '2685.27',
 'volumn': '374068466756.50',
 'volumn_hand': '3640462.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-04' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-229.92',
 'change_rate': '-7.72',
 'close': '2746.61',
 'date': '2020-02-03',
 'max': '2766.58',
 'min': '2716.70',
 'name': '上证指数',
 'open': '2716.70',
 'volumn': '257019597412.50',
 'volumn_hand': '2159121.03'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-02-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-84.23',
 'change_rate': '-2.75',
 'close': '2976.53',
 'date': '2020-01-23',
 'max': '3045.04',
 'min': '2955.35',
 'name': '上证指数',
 'open': '3037.95',
 'volumn': '327490360408.20',
 'volumn_hand': '2727632.34'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '8.61',
 'change_rate': '0.28',
 'close': '3060.75',
 'date': '2020-01-22',
 'max': '3069.25',
 'min': '3006.27',
 'name': '上证指数',
 'open': '3038.49',
 'volumn': '278456923974.80',
 'volumn_hand': '2238528.65'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-43.65',
 'change_rate': '-1.41',
 'close': '3052.14',
 'date': '2020-01-21',
 'max': '3085.79',
 'min': '3051.23',
 'name': '上证指数',
 'open': '3085.79',
 'volumn': '286268098210.40',
 'volumn_hand': '2348307.39'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '20.29',
 'change_rate': '0.66',
 'close': '3095.79',
 'date': '2020-01-20',
 'max': '3096.31',
 'min': '3070.48',
 'name': '上证指数',
 'open': '3082.11',
 'volumn': '271122455433.10',
 'volumn_hand': '2104933.41'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '1.41',
 'change_rate': '0.05',
 'close': '3075.50',
 'date': '2020-01-17',
 'max': '3091.95',
 'min': '3067.25',
 'name': '上证指数',
 'open': '3081.46',
 'volumn': '242273045255.20',
 'volumn_hand': '1903042.99'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-15.96',
 'change_rate': '-0.52',
 'close': '3074.08',
 'date': '2020-01-16',
 'max': '3096.37',
 'min': '3070.88',
 'name': '上证指数',
 'open': '3095.73',
 'volumn': '236843360101.00',
 'volumn_hand': '2033754.75'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-16.78',
 'change_rate': '-0.54',
 'close': '3090.04',
 'date': '2020-01-15',
 'max': '3107.94',
 'min': '3082.04',
 'name': '上证指数',
 'open': '3103.17',
 'volumn': '232913446655.70',
 'volumn_hand': '2023130.23'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-8.75',
 'change_rate': '-0.28',
 'close': '3106.82',
 'date': '2020-01-14',
 'max': '3127.17',
 'min': '3105.60',
 'name': '上证指数',
 'open': '3120.67',
 'volumn': '271542441386.70',
 'volumn_hand': '2299737.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '23.28',
 'change_rate': '0.75',
 'close': '3115.57',
 'date': '2020-01-13',
 'max': '3115.57',
 'min': '3075.38',
 'name': '上证指数',
 'open': '3091.49',
 'volumn': '258524058004.80',
 'volumn_hand': '2106210.04'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-2.59',
 'change_rate': '-0.08',
 'close': '3092.29',
 'date': '2020-01-10',
 'max': '3105.22',
 'min': '3081.40',
 'name': '上证指数',
 'open': '3102.29',
 'volumn': '241555668060.80',
 'volumn_hand': '2104424.62'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '27.99',
 'change_rate': '0.91',
 'close': '3094.88',
 'date': '2020-01-09',
 'max': '3097.33',
 'min': '3080.13',
 'name': '上证指数',
 'open': '3082.64',
 'volumn': '271716020902.20',
 'volumn_hand': '2434356.49'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-37.91',
 'change_rate': '-1.22',
 'close': '3066.89',
 'date': '2020-01-08',
 'max': '3094.24',
 'min': '3059.13',
 'name': '上证指数',
 'open': '3094.24',
 'volumn': '306517394459.20',
 'volumn_hand': '2978725.53'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '21.39',
 'change_rate': '0.69',
 'close': '3104.80',
 'date': '2020-01-07',
 'max': '3105.45',
 'min': '3084.33',
 'name': '上证指数',
 'open': '3085.49',
 'volumn': '288159227656.60',
 'volumn_hand': '2765831.11'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-0.38',
 'change_rate': '-0.01',
 'close': '3083.41',
 'date': '2020-01-06',
 'max': '3107.20',
 'min': '3065.31',
 'name': '上证指数',
 'open': '3070.91',
 'volumn': '331182549906.10',
 'volumn_hand': '3125758.42'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '-1.41',
 'change_rate': '-0.05',
 'close': '3083.79',
 'date': '2020-01-03',
 'max': '3093.82',
 'min': '3074.52',
 'name': '上证指数',
 'open': '3089.02',
 'volumn': '289991708381.50',
 'volumn_hand': '2614966.67'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'change': '35.07',
 'change_rate': '1.15',
 'close': '3085.20',
 'date': '2020-01-02',
 'max': '3098.10',
 'min': '3066.34',
 'name': '上证指数',
 'open': '3066.34',
 'volumn': '327197122605.80',
 'volumn_hand': '2924702.08'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '上证指数-2020-01-02' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=0&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=2&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=2&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=2&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=0&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=0&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=0&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '171.03',
 'change_rate': '1.27',
 'close': '13637.88',
 'date': '2020-07-31',
 'max': '13748.03',
 'min': '13399.86',
 'name': '深证成指',
 'open': '13464.21',
 'volumn': '369370661150.81',
 'volumn_hand': '207891447.79'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-31' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-90.59',
 'change_rate': '-0.67',
 'close': '13466.85',
 'date': '2020-07-30',
 'max': '13619.49',
 'min': '13432.13',
 'name': '深证成指',
 'open': '13595.77',
 'volumn': '338166449158.36',
 'volumn_hand': '194189433.12'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-30' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '410.09',
 'change_rate': '3.12',
 'close': '13557.44',
 'date': '2020-07-29',
 'max': '13557.44',
 'min': '13085.95',
 'name': '深证成指',
 'open': '13117.19',
 'volumn': '344444481628.46',
 'volumn_hand': '188511825.8'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-29' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '170.49',
 'change_rate': '1.31',
 'close': '13147.35',
 'date': '2020-07-28',
 'max': '13196.62',
 'min': '13022.82',
 'name': '深证成指',
 'open': '13107.43',
 'volumn': '287036770251.38',
 'volumn_hand': '160214941.7'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-28' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '41.17',
 'change_rate': '0.32',
 'close': '12976.87',
 'date': '2020-07-27',
 'max': '13093.84',
 'min': '12838.87',
 'name': '深证成指',
 'open': '13013.77',
 'volumn': '302449612629.79',
 'volumn_hand': '167076239.23'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-27' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-725.80',
 'change_rate': '-5.31',
 'close': '12935.70',
 'date': '2020-07-24',
 'max': '13602.79',
 'min': '12868.95',
 'name': '深证成指',
 'open': '13547.81',
 'volumn': '431361530468.84',
 'volumn_hand': '245812417.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-24' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '4.47',
 'change_rate': '0.03',
 'close': '13661.50',
 'date': '2020-07-23',
 'max': '13699.53',
 'min': '13281.55',
 'name': '深证成指',
 'open': '13511.45',
 'volumn': '405619018798.25',
 'volumn_hand': '234151315.67'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-23' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '120.86',
 'change_rate': '0.89',
 'close': '13657.03',
 'date': '2020-07-22',
 'max': '13816.67',
 'min': '13459.88',
 'name': '深证成指',
 'open': '13507.35',
 'volumn': '381667934865.47',
 'volumn_hand': '230781137.64'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-22' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '87.32',
 'change_rate': '0.65',
 'close': '13536.17',
 'date': '2020-07-21',
 'max': '13572.93',
 'min': '13396.58',
 'name': '深证成指',
 'open': '13480.39',
 'volumn': '357391086884.56',
 'volumn_hand': '215802951.84'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-21' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '333.91',
 'change_rate': '2.55',
 'close': '13448.85',
 'date': '2020-07-20',
 'max': '13448.85',
 'min': '13032.40',
 'name': '深证成指',
 'open': '13303.80',
 'volumn': '393132486151.24',
 'volumn_hand': '234552821.15'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-20' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '118.60',
 'change_rate': '0.91',
 'close': '13114.94',
 'date': '2020-07-17',
 'max': '13315.44',
 'min': '12916.08',
 'name': '深证成指',
 'open': '13002.84',
 'volumn': '380105503645.31',
 'volumn_hand': '224851014.85'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-17' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-737.79',
 'change_rate': '-5.37',
 'close': '12996.34',
 'date': '2020-07-16',
 'max': '13853.44',
 'min': '12966.32',
 'name': '深证成指',
 'open': '13731.28',
 'volumn': '499252677394.82',
 'volumn_hand': '291310614.92'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-16' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-262.34',
 'change_rate': '-1.87',
 'close': '13734.13',
 'date': '2020-07-15',
 'max': '14077.56',
 'min': '13646.66',
 'name': '深证成指',
 'open': '14017.93',
 'volumn': '516828506092.24',
 'volumn_hand': '294500393.06'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-15' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-152.68',
 'change_rate': '-1.08',
 'close': '13996.46',
 'date': '2020-07-14',
 'max': '14151.00',
 'min': '13698.27',
 'name': '深证成指',
 'open': '14121.33',
 'volumn': '577658827749.64',
 'volumn_hand': '331465879.43'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-14' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '477.90',
 'change_rate': '3.50',
 'close': '14149.14',
 'date': '2020-07-13',
 'max': '14149.14',
 'min': '13699.22',
 'name': '深证成指',
 'open': '13699.22',
 'volumn': '558867448696.55',
 'volumn_hand': '330500867.84'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-13' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-83.50',
 'change_rate': '-0.61',
 'close': '13671.24',
 'date': '2020-07-10',
 'max': '13831.61',
 'min': '13599.03',
 'name': '深证成指',
 'open': '13662.38',
 'volumn': '524512097228.97',
 'volumn_hand': '320337421.98'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-10' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '348.37',
 'change_rate': '2.60',
 'close': '13754.74',
 'date': '2020-07-09',
 'max': '13792.63',
 'min': '13385.43',
 'name': '深证成指',
 'open': '13399.47',
 'volumn': '564055708794.95',
 'volumn_hand': '351782282.2'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-09' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '242.39',
 'change_rate': '1.84',
 'close': '13406.37',
 'date': '2020-07-08',
 'max': '13428.94',
 'min': '13059.24',
 'name': '深证成指',
 'open': '13170.20',
 'volumn': '489613108165.16',
 'volumn_hand': '314408441.02'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-08' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '222.26',
 'change_rate': '1.72',
 'close': '13163.98',
 'date': '2020-07-07',
 'max': '13407.19',
 'min': '12997.17',
 'name': '深证成指',
 'open': '13084.65',
 'volumn': '567922335759.17',
 'volumn_hand': '363542688.66'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-07' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '508.46',
 'change_rate': '4.09',
 'close': '12941.72',
 'date': '2020-07-06',
 'max': '12945.71',
 'min': '12519.50',
 'name': '深证成指',
 'open': '12519.50',
 'volumn': '508950407612.74',
 'volumn_hand': '334186556.42'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-06' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '163.78',
 'change_rate': '1.33',
 'close': '12433.26',
 'date': '2020-07-03',
 'max': '12433.68',
 'min': '12232.70',
 'name': '深证成指',
 'open': '12295.62',
 'volumn': '392304762885.00',
 'volumn_hand': '255868462.8'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-03' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '156.52',
 'change_rate': '1.29',
 'close': '12269.49',
 'date': '2020-07-02',
 'max': '12278.83',
 'min': '12055.95',
 'name': '深证成指',
 'open': '12095.85',
 'volumn': '368813273780.42',
 'volumn_hand': '238667168.48'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-02' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '120.62',
 'change_rate': '1.01',
 'close': '12112.96',
 'date': '2020-07-01',
 'max': '12130.30',
 'min': '11945.89',
 'name': '深证成指',
 'open': '12024.84',
 'volumn': '319144061183.88',
 'volumn_hand': '181958560.17'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-07-01' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '239.99',
 'change_rate': '2.04',
 'close': '11992.35',
 'date': '2020-06-30',
 'max': '12013.60',
 'min': '11827.76',
 'name': '深证成指',
 'open': '11828.53',
 'volumn': '261828882759.77',
 'volumn_hand': '150955029.65'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-30' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-61.17',
 'change_rate': '-0.52',
 'close': '11752.36',
 'date': '2020-06-29',
 'max': '11814.64',
 'min': '11695.45',
 'name': '深证成指',
 'open': '11780.65',
 'volumn': '245090581192.05',
 'volumn_hand': '149568974.49'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-29' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '19.52',
 'change_rate': '0.17',
 'close': '11813.53',
 'date': '2020-06-24',
 'max': '11854.99',
 'min': '11760.47',
 'name': '深证成指',
 'open': '11813.36',
 'volumn': '249879576457.18',
 'volumn_hand': '142505640.55'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-24' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '57.35',
 'change_rate': '0.58',
 'close': '9962.30',
 'date': '2020-03-31',
 'max': '10047.98',
 'min': '9925.68',
 'name': '深证成指',
 'open': '10008.03',
 'volumn': '177480093611.38',
 'volumn_hand': '131794426.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-31' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-204.96',
 'change_rate': '-2.03',
 'close': '9904.95',
 'date': '2020-03-30',
 'max': '9985.38',
 'min': '9791.02',
 'name': '深证成指',
 'open': '9953.04',
 'volumn': '202607837345.58',
 'volumn_hand': '150275492.36'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-30' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-45.45',
 'change_rate': '-0.45',
 'close': '10109.91',
 'date': '2020-03-27',
 'max': '10310.53',
 'min': '10105.72',
 'name': '深证成指',
 'open': '10300.62',
 'volumn': '199746324547.36',
 'volumn_hand': '142335256.48'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-27' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '91.57',
 'change_rate': '0.78',
 'close': '11794.01',
 'date': '2020-06-23',
 'max': '11796.41',
 'min': '11651.83',
 'name': '深证成指',
 'open': '11711.28',
 'volumn': '263138191429.41',
 'volumn_hand': '158257029.12'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-23' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '34.31',
 'change_rate': '0.29',
 'close': '11702.44',
 'date': '2020-06-22',
 'max': '11756.86',
 'min': '11658.81',
 'name': '深证成指',
 'open': '11680.41',
 'volumn': '279441112720.63',
 'volumn_hand': '174693356.99'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-22' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '173.58',
 'change_rate': '1.51',
 'close': '11668.13',
 'date': '2020-06-19',
 'max': '11694.89',
 'min': '11500.53',
 'name': '深证成指',
 'open': '11505.69',
 'volumn': '268463096352.12',
 'volumn_hand': '164386257.16'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-19' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '73.72',
 'change_rate': '0.65',
 'close': '11494.55',
 'date': '2020-06-18',
 'max': '11503.38',
 'min': '11397.57',
 'name': '深证成指',
 'open': '11416.08',
 'volumn': '265352827579.13',
 'volumn_hand': '173592427.77'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-18' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '21.87',
 'change_rate': '0.19',
 'close': '11420.84',
 'date': '2020-06-17',
 'max': '11421.03',
 'min': '11330.37',
 'name': '深证成指',
 'open': '11421.03',
 'volumn': '240260581537.90',
 'volumn_hand': '156297274.94'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-17' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '206.69',
 'change_rate': '1.85',
 'close': '11398.97',
 'date': '2020-06-16',
 'max': '11398.97',
 'min': '11293.90',
 'name': '深证成指',
 'open': '11312.81',
 'volumn': '240801361566.11',
 'volumn_hand': '152804533.51'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-16' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-59.43',
 'change_rate': '-0.53',
 'close': '11192.27',
 'date': '2020-06-15',
 'max': '11353.16',
 'min': '11192.27',
 'name': '深证成指',
 'open': '11241.26',
 'volumn': '256304821750.33',
 'volumn_hand': '168920812.67'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-15' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-85.72',
 'change_rate': '-0.84',
 'close': '10155.36',
 'date': '2020-03-26',
 'max': '10281.57',
 'min': '10112.62',
 'name': '深证成指',
 'open': '10161.94',
 'volumn': '201915723989.57',
 'volumn_hand': '155522359.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-26' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '319.39',
 'change_rate': '3.22',
 'close': '10241.08',
 'date': '2020-03-25',
 'max': '10255.58',
 'min': '10111.36',
 'name': '深证成指',
 'open': '10171.47',
 'volumn': '249305173056.98',
 'volumn_hand': '180916535.36'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-25' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '230.15',
 'change_rate': '2.37',
 'close': '9921.68',
 'date': '2020-03-24',
 'max': '9945.92',
 'min': '9634.97',
 'name': '深证成指',
 'open': '9900.22',
 'volumn': '226635373122.49',
 'volumn_hand': '169223218.31'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-24' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-458.59',
 'change_rate': '-4.52',
 'close': '9691.53',
 'date': '2020-03-23',
 'max': '9929.96',
 'min': '9659.35',
 'name': '深证成指',
 'open': '9828.90',
 'volumn': '219538135696.34',
 'volumn_hand': '163469530.67'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-23' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '130.27',
 'change_rate': '1.30',
 'close': '10150.13',
 'date': '2020-03-20',
 'max': '10174.51',
 'min': '9964.29',
 'name': '深证成指',
 'open': '10150.78',
 'volumn': '226726857153.69',
 'volumn_hand': '158368155.04'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-20' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-9.71',
 'change_rate': '-0.10',
 'close': '10019.86',
 'date': '2020-03-19',
 'max': '10101.80',
 'min': '9719.49',
 'name': '深证成指',
 'open': '10023.12',
 'volumn': '274066140128.34',
 'volumn_hand': '193323671.43'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-19' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-173.18',
 'change_rate': '-1.70',
 'close': '10029.57',
 'date': '2020-03-18',
 'max': '10479.78',
 'min': '10029.57',
 'name': '深证成指',
 'open': '10294.96',
 'volumn': '281177888044.68',
 'volumn_hand': '197491376.62'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-18' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-50.53',
 'change_rate': '-0.49',
 'close': '10202.75',
 'date': '2020-03-17',
 'max': '10449.33',
 'min': '9885.86',
 'name': '深证成指',
 'open': '10337.92',
 'volumn': '268684768258.39',
 'volumn_hand': '195751058.22'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-17' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-577.84',
 'change_rate': '-5.34',
 'close': '10253.28',
 'date': '2020-03-16',
 'max': '10867.66',
 'min': '10217.93',
 'name': '深证成指',
 'open': '10867.66',
 'volumn': '316881154508.24',
 'volumn_hand': '226153928.87'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-16' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '8.09',
 'change_rate': '0.07',
 'close': '11251.71',
 'date': '2020-06-12',
 'max': '11306.14',
 'min': '11003.32',
 'name': '深证成指',
 'open': '11017.15',
 'volumn': '230516094397.54',
 'volumn_hand': '155276758.25'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-12' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-92.25',
 'change_rate': '-0.81',
 'close': '11243.62',
 'date': '2020-06-11',
 'max': '11405.01',
 'min': '11180.75',
 'name': '深证成指',
 'open': '11328.10',
 'volumn': '237285331057.18',
 'volumn_hand': '158215655.27'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-11' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '51.62',
 'change_rate': '0.46',
 'close': '11335.86',
 'date': '2020-06-10',
 'max': '11338.24',
 'min': '11249.43',
 'name': '深证成指',
 'open': '11296.13',
 'volumn': '196450506926.40',
 'volumn_hand': '138186807.69'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-10' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '68.48',
 'change_rate': '0.61',
 'close': '11284.24',
 'date': '2020-06-09',
 'max': '11303.54',
 'min': '11195.00',
 'name': '深证成指',
 'open': '11238.44',
 'volumn': '192404831923.16',
 'volumn_hand': '142659128.45'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-09' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '35.16',
 'change_rate': '0.31',
 'close': '11215.76',
 'date': '2020-06-08',
 'max': '11340.03',
 'min': '11195.85',
 'name': '深证成指',
 'open': '11266.93',
 'volumn': '217702178448.90',
 'volumn_hand': '160317332.17'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-08' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '41.34',
 'change_rate': '0.37',
 'close': '11180.60',
 'date': '2020-06-05',
 'max': '11180.60',
 'min': '11087.25',
 'name': '深证成指',
 'open': '11153.27',
 'volumn': '183554094770.12',
 'volumn_hand': '136127850.46'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-05' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '30.90',
 'change_rate': '0.28',
 'close': '11139.26',
 'date': '2020-06-04',
 'max': '11165.14',
 'min': '11080.51',
 'name': '深证成指',
 'open': '11146.29',
 'volumn': '197106464396.64',
 'volumn_hand': '147924612.4'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-04' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-4.14',
 'change_rate': '-0.04',
 'close': '11108.36',
 'date': '2020-06-03',
 'max': '11204.52',
 'min': '11100.69',
 'name': '深证成指',
 'open': '11154.64',
 'volumn': '250094104945.89',
 'volumn_hand': '184721067.44'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-03' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '10.35',
 'change_rate': '0.09',
 'close': '11112.50',
 'date': '2020-06-02',
 'max': '11146.85',
 'min': '11059.19',
 'name': '深证成指',
 'open': '11133.62',
 'volumn': '253392328963.36',
 'volumn_hand': '190826325.54'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-02' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '356.07',
 'change_rate': '3.31',
 'close': '11102.15',
 'date': '2020-06-01',
 'max': '11123.19',
 'min': '10837.49',
 'name': '深证成指',
 'open': '10837.49',
 'volumn': '245646608584.13',
 'volumn_hand': '174425358.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-06-01' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '92.58',
 'change_rate': '0.87',
 'close': '10746.08',
 'date': '2020-05-29',
 'max': '10764.87',
 'min': '10588.74',
 'name': '深证成指',
 'open': '10615.14',
 'volumn': '169139402099.70',
 'volumn_hand': '121028903.93'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-29' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-109.89',
 'change_rate': '-1.00',
 'close': '10831.13',
 'date': '2020-03-13',
 'max': '10956.51',
 'min': '10380.17',
 'name': '深证成指',
 'open': '10382.22',
 'volumn': '299591950271.69',
 'volumn_hand': '224557936.13'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-13' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-259.04',
 'change_rate': '-2.31',
 'close': '10941.01',
 'date': '2020-03-12',
 'max': '11070.41',
 'min': '10842.38',
 'name': '深证成指',
 'open': '11022.40',
 'volumn': '253668861356.27',
 'volumn_hand': '186977661.77'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-12' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-203.42',
 'change_rate': '-1.78',
 'close': '11200.05',
 'date': '2020-03-11',
 'max': '11444.78',
 'min': '11197.09',
 'name': '深证成指',
 'open': '11436.44',
 'volumn': '286349128793.52',
 'volumn_hand': '204670979.03'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-11' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '294.92',
 'change_rate': '2.65',
 'close': '11403.47',
 'date': '2020-03-10',
 'max': '11406.30',
 'min': '10916.95',
 'name': '深证成指',
 'open': '11016.92',
 'volumn': '337528189517.03',
 'volumn_hand': '241226896.5'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-10' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-474.27',
 'change_rate': '-4.09',
 'close': '11108.55',
 'date': '2020-03-09',
 'max': '11407.47',
 'min': '11100.91',
 'name': '深证成指',
 'open': '11363.79',
 'volumn': '338679025537.66',
 'volumn_hand': '248908853.66'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-09' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-128.56',
 'change_rate': '-1.10',
 'close': '11582.82',
 'date': '2020-03-06',
 'max': '11690.20',
 'min': '11541.78',
 'name': '深证成指',
 'open': '11555.46',
 'volumn': '287721167009.64',
 'volumn_hand': '213662239.11'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-06' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '218.35',
 'change_rate': '1.90',
 'close': '11711.37',
 'date': '2020-03-05',
 'max': '11739.84',
 'min': '11521.29',
 'name': '深证成指',
 'open': '11644.41',
 'volumn': '369922340912.22',
 'volumn_hand': '252987360.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-05' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '8.81',
 'change_rate': '0.08',
 'close': '11493.02',
 'date': '2020-03-04',
 'max': '11501.80',
 'min': '11273.26',
 'name': '深证成指',
 'open': '11411.60',
 'volumn': '320471980993.04',
 'volumn_hand': '222190839.93'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-04' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '102.45',
 'change_rate': '0.90',
 'close': '11484.21',
 'date': '2020-03-03',
 'max': '11734.18',
 'min': '11378.76',
 'name': '深证成指',
 'open': '11597.66',
 'volumn': '396401383827.92',
 'volumn_hand': '265986270.38'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-03' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '400.99',
 'change_rate': '3.65',
 'close': '11381.76',
 'date': '2020-03-02',
 'max': '11457.42',
 'min': '11053.29',
 'name': '深证成指',
 'open': '11115.46',
 'volumn': '359669847422.14',
 'volumn_hand': '247892769.59'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-03-02' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-553.24',
 'change_rate': '-4.80',
 'close': '10980.77',
 'date': '2020-02-28',
 'max': '11338.35',
 'min': '10962.24',
 'name': '深证成指',
 'open': '11150.66',
 'volumn': '389037192883.80',
 'volumn_hand': '280023801.75'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-28' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '36.47',
 'change_rate': '0.32',
 'close': '11534.02',
 'date': '2020-02-27',
 'max': '11684.50',
 'min': '11401.32',
 'name': '深证成指',
 'open': '11555.82',
 'volumn': '357489811545.25',
 'volumn_hand': '246450263.6'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-27' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-29.21',
 'change_rate': '-0.27',
 'close': '10653.49',
 'date': '2020-05-28',
 'max': '10727.99',
 'min': '10505.79',
 'name': '深证成指',
 'open': '10680.87',
 'volumn': '166053249714.93',
 'volumn_hand': '115644650.89'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-28' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-132.73',
 'change_rate': '-1.23',
 'close': '10682.70',
 'date': '2020-05-27',
 'max': '10823.24',
 'min': '10657.81',
 'name': '深证成指',
 'open': '10823.24',
 'volumn': '168441386347.99',
 'volumn_hand': '112994179.49'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-27' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '222.59',
 'change_rate': '2.10',
 'close': '10815.43',
 'date': '2020-05-26',
 'max': '10816.71',
 'min': '10647.25',
 'name': '深证成指',
 'open': '10655.98',
 'volumn': '164154227873.47',
 'volumn_hand': '106560170.28'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-26' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-12.12',
 'change_rate': '-0.11',
 'close': '10592.84',
 'date': '2020-05-25',
 'max': '10629.61',
 'min': '10532.86',
 'name': '深证成指',
 'open': '10602.47',
 'volumn': '150151909924.89',
 'volumn_hand': '98036276.82'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-25' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-240.43',
 'change_rate': '-2.22',
 'close': '10604.97',
 'date': '2020-05-22',
 'max': '10832.91',
 'min': '10559.30',
 'name': '深证成指',
 'open': '10832.91',
 'volumn': '183208922645.80',
 'volumn_hand': '127342624.49'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-22' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-103.08',
 'change_rate': '-0.94',
 'close': '10845.40',
 'date': '2020-05-21',
 'max': '11007.14',
 'min': '10818.79',
 'name': '深证成指',
 'open': '10999.07',
 'volumn': '195912811175.43',
 'volumn_hand': '136502964.5'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-21' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-104.37',
 'change_rate': '-0.94',
 'close': '10948.48',
 'date': '2020-05-20',
 'max': '11056.98',
 'min': '10914.75',
 'name': '深证成指',
 'open': '11056.98',
 'volumn': '217645247284.58',
 'volumn_hand': '149166311.12'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-20' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '131.70',
 'change_rate': '1.21',
 'close': '11052.85',
 'date': '2020-05-19',
 'max': '11052.85',
 'min': '10978.72',
 'name': '深证成指',
 'open': '11023.43',
 'volumn': '204489334515.06',
 'volumn_hand': '131151886.65'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-19' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-43.75',
 'change_rate': '-0.40',
 'close': '10921.15',
 'date': '2020-05-18',
 'max': '11017.50',
 'min': '10858.46',
 'name': '深证成指',
 'open': '10969.08',
 'volumn': '246573339653.08',
 'volumn_hand': '161741782.91'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-18' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '2.74',
 'change_rate': '0.03',
 'close': '10964.89',
 'date': '2020-05-15',
 'max': '11039.68',
 'min': '10919.54',
 'name': '深证成指',
 'open': '11013.16',
 'volumn': '203731084106.07',
 'volumn_hand': '137353562.89'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-15' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-112.45',
 'change_rate': '-1.02',
 'close': '10962.15',
 'date': '2020-05-14',
 'max': '11047.38',
 'min': '10955.54',
 'name': '深证成指',
 'open': '11026.71',
 'volumn': '194165807241.45',
 'volumn_hand': '136773337.37'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-14' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '59.03',
 'change_rate': '0.54',
 'close': '11074.59',
 'date': '2020-05-13',
 'max': '11096.62',
 'min': '10954.69',
 'name': '深证成指',
 'open': '10978.31',
 'volumn': '193890655158.49',
 'volumn_hand': '127407705.41'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-13' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-358.53',
 'change_rate': '-3.02',
 'close': '11497.55',
 'date': '2020-02-26',
 'max': '11770.51',
 'min': '11453.69',
 'name': '深证成指',
 'open': '11677.63',
 'volumn': '450585591534.65',
 'volumn_hand': '314043764.74'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-26' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '83.71',
 'change_rate': '0.71',
 'close': '11856.08',
 'date': '2020-02-25',
 'max': '11869.41',
 'min': '11350.28',
 'name': '深证成指',
 'open': '11537.55',
 'volumn': '487860758233.57',
 'volumn_hand': '324691453.2'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-25' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '142.68',
 'change_rate': '1.23',
 'close': '11772.38',
 'date': '2020-02-24',
 'max': '11809.75',
 'min': '11548.41',
 'name': '深证成指',
 'open': '11620.63',
 'volumn': '413704908262.11',
 'volumn_hand': '277431057.4'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-24' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '120.61',
 'change_rate': '1.05',
 'close': '11629.70',
 'date': '2020-02-21',
 'max': '11727.89',
 'min': '11493.63',
 'name': '深证成指',
 'open': '11506.67',
 'volumn': '389068859805.86',
 'volumn_hand': '267470404.05'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-21' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '273.49',
 'change_rate': '2.43',
 'close': '11509.09',
 'date': '2020-02-20',
 'max': '11519.07',
 'min': '11248.90',
 'name': '深证成指',
 'open': '11278.87',
 'volumn': '355172612977.66',
 'volumn_hand': '250750797.57'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-20' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-70.89',
 'change_rate': '-0.63',
 'close': '11235.60',
 'date': '2020-02-19',
 'max': '11387.99',
 'min': '11229.55',
 'name': '深证成指',
 'open': '11300.16',
 'volumn': '344212157254.75',
 'volumn_hand': '233962709.28'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-19' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '64.99',
 'change_rate': '0.58',
 'close': '11306.49',
 'date': '2020-02-18',
 'max': '11306.49',
 'min': '11143.39',
 'name': '深证成指',
 'open': '11244.77',
 'volumn': '319288076139.65',
 'volumn_hand': '226909750.46'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-18' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '325.19',
 'change_rate': '2.98',
 'close': '11241.50',
 'date': '2020-02-17',
 'max': '11241.50',
 'min': '10974.93',
 'name': '深证成指',
 'open': '10974.93',
 'volumn': '311940306310.72',
 'volumn_hand': '216829575.05'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-17' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '51.99',
 'change_rate': '0.48',
 'close': '10916.31',
 'date': '2020-02-14',
 'max': '11017.65',
 'min': '10822.13',
 'name': '深证成指',
 'open': '10854.46',
 'volumn': '276989927087.96',
 'volumn_hand': '187036804.47'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-14' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-76.47',
 'change_rate': '-0.70',
 'close': '10864.32',
 'date': '2020-02-13',
 'max': '10988.23',
 'min': '10820.92',
 'name': '深证成指',
 'open': '10936.50',
 'volumn': '286653296055.85',
 'volumn_hand': '197433209.5'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-13' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '172.17',
 'change_rate': '1.60',
 'close': '10940.80',
 'date': '2020-02-12',
 'max': '10944.63',
 'min': '10724.08',
 'name': '深证成指',
 'open': '10735.05',
 'volumn': '265973087141.71',
 'volumn_hand': '184275271.72'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-12' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '40.17',
 'change_rate': '0.37',
 'close': '10768.63',
 'date': '2020-02-11',
 'max': '10839.19',
 'min': '10678.11',
 'name': '深证成指',
 'open': '10749.97',
 'volumn': '261115723446.12',
 'volumn_hand': '181050924.72'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-11' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '46.28',
 'change_rate': '0.42',
 'close': '11015.56',
 'date': '2020-05-12',
 'max': '11018.93',
 'min': '10871.61',
 'name': '深证成指',
 'open': '10972.05',
 'volumn': '196393928432.48',
 'volumn_hand': '132805386.52'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-12' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-32.30',
 'change_rate': '-0.29',
 'close': '10969.28',
 'date': '2020-05-11',
 'max': '11096.28',
 'min': '10902.60',
 'name': '深证成指',
 'open': '11053.82',
 'volumn': '230195001778.38',
 'volumn_hand': '156808476.3'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-11' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '138.29',
 'change_rate': '1.27',
 'close': '11001.58',
 'date': '2020-05-08',
 'max': '11054.31',
 'min': '10904.88',
 'name': '深证成指',
 'open': '10923.61',
 'volumn': '223784049123.56',
 'volumn_hand': '154649573.95'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-08' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-19.93',
 'change_rate': '-0.18',
 'close': '10863.29',
 'date': '2020-05-07',
 'max': '10926.83',
 'min': '10832.09',
 'name': '深证成指',
 'open': '10899.92',
 'volumn': '212988611313.57',
 'volumn_hand': '148525234.51'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-07' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '161.44',
 'change_rate': '1.51',
 'close': '10883.22',
 'date': '2020-05-06',
 'max': '10884.34',
 'min': '10613.89',
 'name': '深证成指',
 'open': '10618.17',
 'volumn': '243941944356.89',
 'volumn_hand': '167997745.35'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-05-06' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '207.61',
 'change_rate': '1.97',
 'close': '10721.78',
 'date': '2020-04-30',
 'max': '10751.75',
 'min': '10575.52',
 'name': '深证成指',
 'open': '10575.52',
 'volumn': '232867836870.80',
 'volumn_hand': '159674899.01'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-30' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '13.03',
 'change_rate': '0.12',
 'close': '10514.17',
 'date': '2020-04-29',
 'max': '10586.57',
 'min': '10449.37',
 'name': '深证成指',
 'open': '10460.99',
 'volumn': '163975994369.25',
 'volumn_hand': '118618955.38'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-29' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '48.98',
 'change_rate': '0.47',
 'close': '10501.15',
 'date': '2020-04-28',
 'max': '10547.75',
 'min': '10194.15',
 'name': '深证成指',
 'open': '10477.76',
 'volumn': '215045192961.01',
 'volumn_hand': '159031254.48'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-28' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '28.71',
 'change_rate': '0.28',
 'close': '10452.17',
 'date': '2020-04-27',
 'max': '10531.39',
 'min': '10367.29',
 'name': '深证成指',
 'open': '10449.13',
 'volumn': '167311005809.75',
 'volumn_hand': '123617765.28'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-27' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-140.58',
 'change_rate': '-1.33',
 'close': '10423.46',
 'date': '2020-04-24',
 'max': '10577.03',
 'min': '10388.66',
 'name': '深证成指',
 'open': '10565.09',
 'volumn': '180234594137.41',
 'volumn_hand': '135268148.49'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-24' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-53.15',
 'change_rate': '-0.50',
 'close': '10564.05',
 'date': '2020-04-23',
 'max': '10667.01',
 'min': '10557.94',
 'name': '深证成指',
 'open': '10657.40',
 'volumn': '199292172829.94',
 'volumn_hand': '142141470.09'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-23' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '116.91',
 'change_rate': '1.10',
 'close': '10728.46',
 'date': '2020-02-10',
 'max': '10730.05',
 'min': '10551.54',
 'name': '深证成指',
 'open': '10577.56',
 'volumn': '294002814309.91',
 'volumn_hand': '205295566.97'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-10' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '10.21',
 'change_rate': '0.10',
 'close': '10611.55',
 'date': '2020-02-07',
 'max': '10629.15',
 'min': '10441.90',
 'name': '深证成指',
 'open': '10569.65',
 'volumn': '311415287241.32',
 'volumn_hand': '216128400.26'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-07' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '295.84',
 'change_rate': '2.87',
 'close': '10601.34',
 'date': '2020-02-06',
 'max': '10633.17',
 'min': '10214.81',
 'name': '深证成指',
 'open': '10306.12',
 'volumn': '325697987326.15',
 'volumn_hand': '228075736.88'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-06' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '215.83',
 'change_rate': '2.14',
 'close': '10305.50',
 'date': '2020-02-05',
 'max': '10445.09',
 'min': '10148.24',
 'name': '深证成指',
 'open': '10159.55',
 'volumn': '308120146047.41',
 'volumn_hand': '214902959.97'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-05' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '310.00',
 'change_rate': '3.17',
 'close': '10089.67',
 'date': '2020-02-04',
 'max': '10095.69',
 'min': '9578.87',
 'name': '深证成指',
 'open': '9578.87',
 'volumn': '309994092119.79',
 'volumn_hand': '239323329.48'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-04' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-902.24',
 'change_rate': '-8.45',
 'close': '9779.67',
 'date': '2020-02-03',
 'max': '9934.35',
 'min': '9706.58',
 'name': '深证成指',
 'open': '9706.58',
 'volumn': '184479001934.82',
 'volumn_hand': '104871496.0'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-02-03' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-390.15',
 'change_rate': '-3.52',
 'close': '10681.90',
 'date': '2020-01-23',
 'max': '11026.00',
 'min': '10572.27',
 'name': '深证成指',
 'open': '10947.86',
 'volumn': '273292004900.32',
 'volumn_hand': '186029517.86'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-23' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '118.64',
 'change_rate': '1.08',
 'close': '11072.06',
 'date': '2020-01-22',
 'max': '11105.69',
 'min': '10761.68',
 'name': '深证成指',
 'open': '10896.55',
 'volumn': '237040923279.32',
 'volumn_hand': '159169709.85'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-22' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-162.47',
 'change_rate': '-1.46',
 'close': '10953.41',
 'date': '2020-01-21',
 'max': '11078.04',
 'min': '10948.58',
 'name': '深证成指',
 'open': '11077.66',
 'volumn': '218854933898.93',
 'volumn_hand': '153388280.11'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-21' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '161.50',
 'change_rate': '1.47',
 'close': '11115.88',
 'date': '2020-01-20',
 'max': '11115.88',
 'min': '10936.80',
 'name': '深证成指',
 'open': '10981.50',
 'volumn': '225109963075.99',
 'volumn_hand': '151944038.92'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-20' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-13.05',
 'change_rate': '-0.12',
 'close': '10954.39',
 'date': '2020-01-17',
 'max': '11045.25',
 'min': '10927.84',
 'name': '深证成指',
 'open': '11001.68',
 'volumn': '187293461152.59',
 'volumn_hand': '132755224.18'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-17' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-4.88',
 'change_rate': '-0.04',
 'close': '10967.44',
 'date': '2020-01-16',
 'max': '11008.21',
 'min': '10934.72',
 'name': '深证成指',
 'open': '10986.65',
 'volumn': '193665531188.83',
 'volumn_hand': '140490137.09'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-16' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '110.34',
 'change_rate': '1.05',
 'close': '10617.19',
 'date': '2020-04-22',
 'max': '10617.19',
 'min': '10409.85',
 'name': '深证成指',
 'open': '10424.45',
 'volumn': '183480776027.13',
 'volumn_hand': '129711669.36'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-22' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-114.64',
 'change_rate': '-1.08',
 'close': '10506.86',
 'date': '2020-04-21',
 'max': '10577.72',
 'min': '10394.44',
 'name': '深证成指',
 'open': '10577.72',
 'volumn': '208245198150.01',
 'volumn_hand': '146429769.7'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-21' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '93.51',
 'change_rate': '0.89',
 'close': '10621.50',
 'date': '2020-04-20',
 'max': '10621.50',
 'min': '10523.59',
 'name': '深证成指',
 'open': '10553.55',
 'volumn': '202360446337.50',
 'volumn_hand': '142118817.54'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-20' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '57.20',
 'change_rate': '0.55',
 'close': '10527.99',
 'date': '2020-04-17',
 'max': '10624.54',
 'min': '10507.80',
 'name': '深证成指',
 'open': '10562.90',
 'volumn': '253762911652.15',
 'volumn_hand': '171153618.16'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-17' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '53.42',
 'change_rate': '0.51',
 'close': '10470.79',
 'date': '2020-04-16',
 'max': '10489.13',
 'min': '10346.11',
 'name': '深证成指',
 'open': '10361.77',
 'volumn': '189450490552.77',
 'volumn_hand': '138326657.24'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-16' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-58.33',
 'change_rate': '-0.56',
 'close': '10417.37',
 'date': '2020-04-15',
 'max': '10528.73',
 'min': '10404.51',
 'name': '深证成指',
 'open': '10468.46',
 'volumn': '218518185049.28',
 'volumn_hand': '154763083.89'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-15' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '252.54',
 'change_rate': '2.47',
 'close': '10475.71',
 'date': '2020-04-14',
 'max': '10475.71',
 'min': '10276.37',
 'name': '深证成指',
 'open': '10300.96',
 'volumn': '202437566790.43',
 'volumn_hand': '138360507.89'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-14' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-75.25',
 'change_rate': '-0.73',
 'close': '10223.16',
 'date': '2020-04-13',
 'max': '10295.17',
 'min': '10173.12',
 'name': '深证成指',
 'open': '10225.53',
 'volumn': '159173552659.23',
 'volumn_hand': '114525723.75'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-13' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-164.63',
 'change_rate': '-1.57',
 'close': '10298.41',
 'date': '2020-04-10',
 'max': '10509.00',
 'min': '10265.88',
 'name': '深证成指',
 'open': '10459.70',
 'volumn': '207572867405.09',
 'volumn_hand': '144923754.72'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-10' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '76.50',
 'change_rate': '0.74',
 'close': '10463.05',
 'date': '2020-04-09',
 'max': '10485.30',
 'min': '10401.17',
 'name': '深证成指',
 'open': '10453.86',
 'volumn': '197748951159.69',
 'volumn_hand': '138672282.39'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-09' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-42.37',
 'change_rate': '-0.41',
 'close': '10386.55',
 'date': '2020-04-08',
 'max': '10426.40',
 'min': '10344.44',
 'name': '深证成指',
 'open': '10372.76',
 'volumn': '205979023294.36',
 'volumn_hand': '153837062.21'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-08' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '318.80',
 'change_rate': '3.15',
 'close': '10428.91',
 'date': '2020-04-07',
 'max': '10441.74',
 'min': '10296.72',
 'name': '深证成指',
 'open': '10312.71',
 'volumn': '237868515573.09',
 'volumn_hand': '170643516.77'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-07' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-16.45',
 'change_rate': '-0.15',
 'close': '10972.32',
 'date': '2020-01-15',
 'max': '11001.81',
 'min': '10882.79',
 'name': '深证成指',
 'open': '10978.28',
 'volumn': '190461844040.96',
 'volumn_hand': '139070682.38'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-15' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-51.43',
 'change_rate': '-0.47',
 'close': '10988.77',
 'date': '2020-01-14',
 'max': '11086.81',
 'min': '10983.42',
 'name': '深证成指',
 'open': '11074.89',
 'volumn': '222275061482.62',
 'volumn_hand': '164697177.11'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-14' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '160.36',
 'change_rate': '1.47',
 'close': '11040.20',
 'date': '2020-01-13',
 'max': '11040.20',
 'min': '10851.72',
 'name': '深证成指',
 'open': '10894.00',
 'volumn': '220325366421.73',
 'volumn_hand': '151152915.64'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-13' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-18.32',
 'change_rate': '-0.17',
 'close': '10879.84',
 'date': '2020-01-10',
 'max': '10933.81',
 'min': '10833.52',
 'name': '深证成指',
 'open': '10927.98',
 'volumn': '201257499323.61',
 'volumn_hand': '145734688.37'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-10' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '191.30',
 'change_rate': '1.79',
 'close': '10898.17',
 'date': '2020-01-09',
 'max': '10899.48',
 'min': '10807.04',
 'name': '深证成指',
 'open': '10807.04',
 'volumn': '227475180479.21',
 'volumn_hand': '170035555.33'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-09' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-122.18',
 'change_rate': '-1.13',
 'close': '10706.87',
 'date': '2020-01-08',
 'max': '10851.28',
 'min': '10681.02',
 'name': '深证成指',
 'open': '10776.71',
 'volumn': '243513425862.60',
 'volumn_hand': '202946131.43'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-08' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '130.77',
 'change_rate': '1.22',
 'close': '10829.05',
 'date': '2020-01-07',
 'max': '10829.05',
 'min': '10723.86',
 'name': '深证成指',
 'open': '10725.18',
 'volumn': '226003447280.63',
 'volumn_hand': '171829698.54'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-07' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '41.87',
 'change_rate': '0.39',
 'close': '10698.27',
 'date': '2020-01-06',
 'max': '10799.58',
 'min': '10577.78',
 'name': '深证成指',
 'open': '10599.41',
 'volumn': '254019604505.39',
 'volumn_hand': '187661316.68'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-06' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '17.58',
 'change_rate': '0.17',
 'close': '10656.41',
 'date': '2020-01-03',
 'max': '10689.59',
 'min': '10594.36',
 'name': '深证成指',
 'open': '10666.66',
 'volumn': '208864062502.70',
 'volumn_hand': '159019101.81'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-03' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '208.06',
 'change_rate': '1.99',
 'close': '10638.82',
 'date': '2020-01-02',
 'max': '10663.55',
 'min': '10479.77',
 'name': '深证成指',
 'open': '10509.12',
 'volumn': '237728016856.83',
 'volumn_hand': '183719153.45'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-01-02' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-69.09',
 'change_rate': '-0.68',
 'close': '10110.11',
 'date': '2020-04-03',
 'max': '10212.91',
 'min': '10069.64',
 'name': '深证成指',
 'open': '10155.56',
 'volumn': '189201377882.31',
 'volumn_hand': '132176770.13'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-03' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '227.37',
 'change_rate': '2.28',
 'close': '10179.20',
 'date': '2020-04-02',
 'max': '10179.20',
 'min': '9896.65',
 'name': '深证成指',
 'open': '9910.38',
 'volumn': '201021330760.71',
 'volumn_hand': '144546720.1'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-02' for key 'uk_t_1'")
2020-08-02 22:59:12 [scrapy.core.scraper] ERROR: Error processing {'change': '-10.47',
 'change_rate': '-0.11',
 'close': '9951.84',
 'date': '2020-04-01',
 'max': '10127.10',
 'min': '9927.92',
 'name': '深证成指',
 'open': '9967.12',
 'volumn': '197563310686.46',
 'volumn_hand': '148831476.16'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/index163/index163/pipelines.py", line 15, in process_item
    item['close'], item['change'], item['change_rate'], item['volumn_hand'], item['volumn'],
  File "/home/glacier/scrapy/index163/index163/dbutil.py", line 30, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '深证成指-2020-04-01' for key 'uk_t_1'")
2020-08-02 22:59:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_zhishu_399001.html?year=2&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:13 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-02 22:59:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 35010,
 'downloader/request_count': 29,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 27,
 'downloader/response_bytes': 723380,
 'downloader/response_count': 29,
 'downloader/response_status_count/200': 28,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 24,
 'elapsed_time_seconds': 11.599362,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 2, 14, 59, 13, 162047),
 'log_count/DEBUG': 30,
 'log_count/ERROR': 420,
 'log_count/INFO': 10,
 'memusage/max': 53604352,
 'memusage/startup': 53604352,
 'request_depth_max': 1,
 'response_received_count': 29,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 54,
 'scheduler/dequeued/memory': 54,
 'scheduler/enqueued': 54,
 'scheduler/enqueued/memory': 54,
 'splash/execute/request_count': 27,
 'splash/execute/response_count/200': 27,
 'start_time': datetime.datetime(2020, 8, 2, 14, 59, 1, 562685)}
2020-08-02 22:59:13 [scrapy.core.engine] INFO: Spider closed (finished)
