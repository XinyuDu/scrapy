2020-08-02 22:59:01 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: stocks163)
2020-08-02 22:59:01 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.6.0 |Continuum Analytics, Inc.| (default, Dec 23 2016, 12:22:00) - [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-4.15.0-74-generic-x86_64-with-debian-buster-sid
2020-08-02 22:59:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'stocks163', 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter', 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage', 'NEWSPIDER_MODULE': 'stocks163.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['stocks163.spiders']}
2020-08-02 22:59:01 [scrapy.extensions.telnet] INFO: Telnet Password: 2e303f5da029d06b
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-08-02 22:59:01 [scrapy.middleware] INFO: Enabled item pipelines:
['stocks163.pipelines.Stocks163Pipeline']
2020-08-02 22:59:01 [scrapy.core.engine] INFO: Spider opened
2020-08-02 22:59:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-08-02 22:59:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-08-02 22:59:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/robots.txt> (referer: None)
2020-08-02 22:59:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://localhost:8050/robots.txt> (referer: None)
2020-08-02 22:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:04 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=2&season=1> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=0&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=0&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=2&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=2&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=2&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=0&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=0&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_600036.html?year=2&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.95',
 'change': '0.08',
 'change_rate': '0.24',
 'close': '33.72',
 'date': '2020-06-30',
 'max': '33.96',
 'min': '33.64',
 'name': '招商银行',
 'open': '33.85',
 'turnover_rate': '0.19',
 'volumn': '132216',
 'volumn_hand': '391568'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.39',
 'change': '-0.26',
 'change_rate': '-0.77',
 'close': '33.64',
 'date': '2020-06-29',
 'max': '34.30',
 'min': '33.49',
 'name': '招商银行',
 'open': '34.17',
 'turnover_rate': '0.28',
 'volumn': '191510',
 'volumn_hand': '567297'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.35',
 'change': '0.55',
 'change_rate': '1.65',
 'close': '33.90',
 'date': '2020-06-24',
 'max': '33.96',
 'min': '33.51',
 'name': '招商银行',
 'open': '33.52',
 'turnover_rate': '0.23',
 'volumn': '162158',
 'volumn_hand': '479891'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.28',
 'change': '-0.15',
 'change_rate': '-0.45',
 'close': '33.35',
 'date': '2020-06-23',
 'max': '33.54',
 'min': '33.11',
 'name': '招商银行',
 'open': '33.30',
 'turnover_rate': '0.22',
 'volumn': '150930',
 'volumn_hand': '452529'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.54',
 'change': '-0.36',
 'change_rate': '-1.06',
 'close': '33.50',
 'date': '2020-06-22',
 'max': '33.85',
 'min': '33.33',
 'name': '招商银行',
 'open': '33.66',
 'turnover_rate': '0.29',
 'volumn': '199759',
 'volumn_hand': '595815'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.18',
 'change': '-0.03',
 'change_rate': '-0.09',
 'close': '33.86',
 'date': '2020-06-19',
 'max': '34.34',
 'min': '33.60',
 'name': '招商银行',
 'open': '33.80',
 'turnover_rate': '0.33',
 'volumn': '229955',
 'volumn_hand': '679496'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.04',
 'change': '-0.31',
 'change_rate': '-0.91',
 'close': '33.89',
 'date': '2020-06-18',
 'max': '34.06',
 'min': '33.02',
 'name': '招商银行',
 'open': '33.88',
 'turnover_rate': '0.45',
 'volumn': '309099',
 'volumn_hand': '922939'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.41',
 'change': '0.06',
 'change_rate': '0.18',
 'close': '34.20',
 'date': '2020-06-17',
 'max': '34.31',
 'min': '33.83',
 'name': '招商银行',
 'open': '34.00',
 'turnover_rate': '0.15',
 'volumn': '104278',
 'volumn_hand': '306278'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.10',
 'change': '0.57',
 'change_rate': '1.70',
 'close': '34.14',
 'date': '2020-06-16',
 'max': '34.18',
 'min': '33.81',
 'name': '招商银行',
 'open': '34.00',
 'turnover_rate': '0.19',
 'volumn': '129898',
 'volumn_hand': '381631'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.09',
 'change': '-0.93',
 'change_rate': '-2.70',
 'close': '33.57',
 'date': '2020-06-15',
 'max': '34.18',
 'min': '33.46',
 'name': '招商银行',
 'open': '34.04',
 'turnover_rate': '0.32',
 'volumn': '220902',
 'volumn_hand': '654343'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.32',
 'change': '0.03',
 'change_rate': '0.09',
 'close': '34.50',
 'date': '2020-06-12',
 'max': '34.50',
 'min': '33.70',
 'name': '招商银行',
 'open': '33.99',
 'turnover_rate': '0.27',
 'volumn': '186505',
 'volumn_hand': '546616'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.86',
 'change': '-0.87',
 'change_rate': '-2.46',
 'close': '34.47',
 'date': '2020-06-11',
 'max': '35.32',
 'min': '34.31',
 'name': '招商银行',
 'open': '35.21',
 'turnover_rate': '0.29',
 'volumn': '204071',
 'volumn_hand': '588927'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.32',
 'change': '-0.19',
 'change_rate': '-0.53',
 'close': '35.34',
 'date': '2020-06-10',
 'max': '35.65',
 'min': '35.18',
 'name': '招商银行',
 'open': '35.64',
 'turnover_rate': '0.13',
 'volumn': '96477',
 'volumn_hand': '272731'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.21',
 'change': '-0.14',
 'change_rate': '-0.39',
 'close': '35.53',
 'date': '2020-06-09',
 'max': '35.69',
 'min': '35.26',
 'name': '招商银行',
 'open': '35.61',
 'turnover_rate': '0.15',
 'volumn': '106728',
 'volumn_hand': '300931'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.96',
 'change': '0.43',
 'change_rate': '1.22',
 'close': '35.67',
 'date': '2020-06-08',
 'max': '36.19',
 'min': '35.50',
 'name': '招商银行',
 'open': '35.55',
 'turnover_rate': '0.24',
 'volumn': '179659',
 'volumn_hand': '501810'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.88',
 'change': '0.09',
 'change_rate': '0.26',
 'close': '35.24',
 'date': '2020-06-05',
 'max': '35.47',
 'min': '34.81',
 'name': '招商银行',
 'open': '35.30',
 'turnover_rate': '0.16',
 'volumn': '114650',
 'volumn_hand': '327173'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-05' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.36',
 'change': '-0.07',
 'change_rate': '-0.20',
 'close': '35.15',
 'date': '2020-06-04',
 'max': '35.55',
 'min': '35.07',
 'name': '招商银行',
 'open': '35.50',
 'turnover_rate': '0.12',
 'volumn': '90922',
 'volumn_hand': '257561'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-04' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.80',
 'change': '0.18',
 'change_rate': '0.51',
 'close': '35.22',
 'date': '2020-06-03',
 'max': '36.00',
 'min': '35.02',
 'name': '招商银行',
 'open': '35.45',
 'turnover_rate': '0.30',
 'volumn': '216975',
 'volumn_hand': '610187'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.07',
 'change': '0.22',
 'change_rate': '0.63',
 'close': '35.04',
 'date': '2020-06-02',
 'max': '35.26',
 'min': '34.54',
 'name': '招商银行',
 'open': '34.55',
 'turnover_rate': '0.24',
 'volumn': '172660',
 'volumn_hand': '492957'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.57',
 'change': '1.00',
 'change_rate': '2.96',
 'close': '34.82',
 'date': '2020-06-01',
 'max': '34.97',
 'min': '34.10',
 'name': '招商银行',
 'open': '34.15',
 'turnover_rate': '0.24',
 'volumn': '169398',
 'volumn_hand': '488237'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-06-01' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.26',
 'change': '-0.40',
 'change_rate': '-1.17',
 'close': '33.82',
 'date': '2020-05-29',
 'max': '34.13',
 'min': '33.70',
 'name': '招商银行',
 'open': '33.86',
 'turnover_rate': '0.18',
 'volumn': '126091',
 'volumn_hand': '372375'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.80',
 'change': '0.79',
 'change_rate': '2.36',
 'close': '34.22',
 'date': '2020-05-28',
 'max': '34.70',
 'min': '33.43',
 'name': '招商银行',
 'open': '33.58',
 'turnover_rate': '0.34',
 'volumn': '237862',
 'volumn_hand': '693623'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.21',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '33.43',
 'date': '2020-05-27',
 'max': '33.98',
 'min': '33.24',
 'name': '招商银行',
 'open': '33.57',
 'turnover_rate': '0.16',
 'volumn': '107725',
 'volumn_hand': '320833'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.21',
 'change': '0.34',
 'change_rate': '1.03',
 'close': '33.43',
 'date': '2020-05-26',
 'max': '33.49',
 'min': '33.09',
 'name': '招商银行',
 'open': '33.30',
 'turnover_rate': '0.16',
 'volumn': '107293',
 'volumn_hand': '322461'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-26' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.09',
 'change': '-0.54',
 'change_rate': '-1.61',
 'close': '33.09',
 'date': '2020-05-25',
 'max': '33.94',
 'min': '32.90',
 'name': '招商银行',
 'open': '33.92',
 'turnover_rate': '0.21',
 'volumn': '143482',
 'volumn_hand': '432649'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-25' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.11',
 'change': '-1.10',
 'change_rate': '-3.17',
 'close': '33.63',
 'date': '2020-05-22',
 'max': '34.69',
 'min': '33.61',
 'name': '招商银行',
 'open': '34.49',
 'turnover_rate': '0.21',
 'volumn': '143909',
 'volumn_hand': '423964'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.49',
 'change': '0.24',
 'change_rate': '0.69',
 'close': '34.80',
 'date': '2020-07-31',
 'max': '35.35',
 'min': '34.49',
 'name': '招商银行',
 'open': '34.60',
 'turnover_rate': '0.48',
 'volumn': '345676',
 'volumn_hand': '989895'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-31' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.97',
 'change': '-0.51',
 'change_rate': '-1.45',
 'close': '34.56',
 'date': '2020-07-30',
 'max': '35.17',
 'min': '34.48',
 'name': '招商银行',
 'open': '35.05',
 'turnover_rate': '0.39',
 'volumn': '277683',
 'volumn_hand': '798879'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.24',
 'change': '0.49',
 'change_rate': '1.42',
 'close': '35.07',
 'date': '2020-07-29',
 'max': '35.35',
 'min': '34.23',
 'name': '招商银行',
 'open': '34.50',
 'turnover_rate': '0.47',
 'volumn': '338177',
 'volumn_hand': '969131'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.96',
 'change': '0.33',
 'change_rate': '0.96',
 'close': '34.58',
 'date': '2020-07-28',
 'max': '34.88',
 'min': '34.21',
 'name': '招商银行',
 'open': '34.66',
 'turnover_rate': '0.38',
 'volumn': '269324',
 'volumn_hand': '780351'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.77',
 'change': '-0.35',
 'change_rate': '-1.01',
 'close': '34.25',
 'date': '2020-07-27',
 'max': '34.97',
 'min': '34.01',
 'name': '招商银行',
 'open': '34.94',
 'turnover_rate': '0.43',
 'volumn': '306221',
 'volumn_hand': '893469'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.69',
 'change': '-1.00',
 'change_rate': '-2.81',
 'close': '34.60',
 'date': '2020-07-24',
 'max': '35.80',
 'min': '34.13',
 'name': '招商银行',
 'open': '35.50',
 'turnover_rate': '0.63',
 'volumn': '455597',
 'volumn_hand': '1304194'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.18',
 'change': '-0.84',
 'change_rate': '-2.31',
 'close': '35.60',
 'date': '2020-07-23',
 'max': '36.41',
 'min': '35.25',
 'name': '招商银行',
 'open': '36.18',
 'turnover_rate': '0.58',
 'volumn': '427204',
 'volumn_hand': '1197076'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.50',
 'change': '0.05',
 'change_rate': '0.14',
 'close': '34.73',
 'date': '2020-05-21',
 'max': '35.18',
 'min': '34.66',
 'name': '招商银行',
 'open': '34.91',
 'turnover_rate': '0.18',
 'volumn': '126300',
 'volumn_hand': '362527'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.71',
 'change': '0.41',
 'change_rate': '1.20',
 'close': '34.68',
 'date': '2020-05-20',
 'max': '35.03',
 'min': '34.10',
 'name': '招商银行',
 'open': '34.27',
 'turnover_rate': '0.18',
 'volumn': '131343',
 'volumn_hand': '380518'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.24',
 'change': '0.47',
 'change_rate': '1.39',
 'close': '34.27',
 'date': '2020-05-19',
 'max': '34.48',
 'min': '34.06',
 'name': '招商银行',
 'open': '34.40',
 'turnover_rate': '0.13',
 'volumn': '90499',
 'volumn_hand': '264304'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.33',
 'change': '-0.05',
 'change_rate': '-0.15',
 'close': '33.80',
 'date': '2020-05-18',
 'max': '34.30',
 'min': '33.51',
 'name': '招商银行',
 'open': '33.62',
 'turnover_rate': '0.18',
 'volumn': '123386',
 'volumn_hand': '363701'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.65',
 'change': '-0.08',
 'change_rate': '-0.24',
 'close': '33.85',
 'date': '2020-05-15',
 'max': '34.26',
 'min': '33.70',
 'name': '招商银行',
 'open': '34.19',
 'turnover_rate': '0.18',
 'volumn': '122613',
 'volumn_hand': '361928'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.80',
 'change': '-0.61',
 'change_rate': '-1.77',
 'close': '33.93',
 'date': '2020-05-14',
 'max': '34.42',
 'min': '33.80',
 'name': '招商银行',
 'open': '34.39',
 'turnover_rate': '0.20',
 'volumn': '143036',
 'volumn_hand': '420630'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.68',
 'change': '-0.05',
 'change_rate': '-0.14',
 'close': '34.54',
 'date': '2020-05-13',
 'max': '34.68',
 'min': '34.10',
 'name': '招商银行',
 'open': '34.40',
 'turnover_rate': '0.14',
 'volumn': '96167',
 'volumn_hand': '279835'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.72',
 'change': '-0.37',
 'change_rate': '-1.06',
 'close': '34.59',
 'date': '2020-05-12',
 'max': '35.04',
 'min': '34.44',
 'name': '招商银行',
 'open': '34.99',
 'turnover_rate': '0.17',
 'volumn': '121300',
 'volumn_hand': '349634'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.72',
 'change': '-0.01',
 'change_rate': '-0.03',
 'close': '34.96',
 'date': '2020-05-11',
 'max': '35.48',
 'min': '34.88',
 'name': '招商银行',
 'open': '34.98',
 'turnover_rate': '0.14',
 'volumn': '104065',
 'volumn_hand': '295848'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.51',
 'change': '-0.37',
 'change_rate': '-1.13',
 'close': '32.28',
 'date': '2020-03-31',
 'max': '32.98',
 'min': '32.16',
 'name': '招商银行',
 'open': '32.92',
 'turnover_rate': '0.18',
 'volumn': '122838',
 'volumn_hand': '377540'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-31' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.81',
 'change': '-0.07',
 'change_rate': '-0.21',
 'close': '32.65',
 'date': '2020-03-30',
 'max': '32.72',
 'min': '31.80',
 'name': '招商银行',
 'open': '32.18',
 'turnover_rate': '0.23',
 'volumn': '154107',
 'volumn_hand': '477494'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.60',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '32.72',
 'date': '2020-03-27',
 'max': '33.33',
 'min': '32.48',
 'name': '招商银行',
 'open': '33.12',
 'turnover_rate': '0.28',
 'volumn': '191113',
 'volumn_hand': '581775'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.19',
 'change': '0.23',
 'change_rate': '0.71',
 'close': '32.72',
 'date': '2020-03-26',
 'max': '33.42',
 'min': '32.06',
 'name': '招商银行',
 'open': '32.10',
 'turnover_rate': '0.34',
 'volumn': '228146',
 'volumn_hand': '694636'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-26' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.62',
 'change': '0.98',
 'change_rate': '3.11',
 'close': '32.49',
 'date': '2020-03-25',
 'max': '32.68',
 'min': '32.17',
 'name': '招商银行',
 'open': '32.23',
 'turnover_rate': '0.39',
 'volumn': '262958',
 'volumn_hand': '809527'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-25' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.79',
 'change': '1.35',
 'change_rate': '4.48',
 'close': '31.51',
 'date': '2020-03-24',
 'max': '31.65',
 'min': '30.81',
 'name': '招商银行',
 'open': '31.15',
 'turnover_rate': '0.40',
 'volumn': '258555',
 'volumn_hand': '825359'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.03',
 'change': '-0.88',
 'change_rate': '-2.84',
 'close': '30.16',
 'date': '2020-03-23',
 'max': '30.51',
 'min': '29.88',
 'name': '招商银行',
 'open': '30.01',
 'turnover_rate': '0.45',
 'volumn': '280411',
 'volumn_hand': '928971'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.28',
 'change': '-0.40',
 'change_rate': '-1.09',
 'close': '36.44',
 'date': '2020-07-22',
 'max': '37.10',
 'min': '36.26',
 'name': '招商银行',
 'open': '36.78',
 'turnover_rate': '0.48',
 'volumn': '365673',
 'volumn_hand': '998812'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.47',
 'change': '-0.43',
 'change_rate': '-1.15',
 'close': '36.84',
 'date': '2020-07-21',
 'max': '37.44',
 'min': '36.52',
 'name': '招商银行',
 'open': '37.27',
 'turnover_rate': '0.40',
 'volumn': '306299',
 'volumn_hand': '831621'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.43',
 'change': '1.19',
 'change_rate': '3.30',
 'close': '37.27',
 'date': '2020-07-20',
 'max': '37.45',
 'min': '35.85',
 'name': '招商银行',
 'open': '36.10',
 'turnover_rate': '0.77',
 'volumn': '588459',
 'volumn_hand': '1594157'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.50',
 'change': '0.48',
 'change_rate': '1.35',
 'close': '36.08',
 'date': '2020-07-17',
 'max': '36.20',
 'min': '35.31',
 'name': '招商银行',
 'open': '35.87',
 'turnover_rate': '0.57',
 'volumn': '418275',
 'volumn_hand': '1169918'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.76',
 'change': '-0.26',
 'change_rate': '-0.73',
 'close': '35.60',
 'date': '2020-07-16',
 'max': '36.58',
 'min': '35.59',
 'name': '招商银行',
 'open': '36.05',
 'turnover_rate': '0.69',
 'volumn': '515363',
 'volumn_hand': '1429523'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.62',
 'change': '-0.65',
 'change_rate': '-1.78',
 'close': '35.86',
 'date': '2020-07-15',
 'max': '37.02',
 'min': '35.70',
 'name': '招商银行',
 'open': '36.99',
 'turnover_rate': '0.65',
 'volumn': '483852',
 'volumn_hand': '1341142'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.19',
 'change': '-0.79',
 'change_rate': '-2.12',
 'close': '36.51',
 'date': '2020-07-14',
 'max': '37.42',
 'min': '36.23',
 'name': '招商银行',
 'open': '37.07',
 'turnover_rate': '0.64',
 'volumn': '482106',
 'volumn_hand': '1310866'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.57',
 'change': '0.05',
 'change_rate': '0.13',
 'close': '37.30',
 'date': '2020-07-13',
 'max': '38.00',
 'min': '36.67',
 'name': '招商银行',
 'open': '37.01',
 'turnover_rate': '0.79',
 'volumn': '608629',
 'volumn_hand': '1634064'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.04',
 'change': '-1.46',
 'change_rate': '-3.77',
 'close': '37.25',
 'date': '2020-07-10',
 'max': '39.00',
 'min': '37.05',
 'name': '招商银行',
 'open': '38.71',
 'turnover_rate': '0.74',
 'volumn': '578478',
 'volumn_hand': '1528159'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.69',
 'change': '-0.59',
 'change_rate': '-1.46',
 'close': '39.91',
 'date': '2020-07-09',
 'max': '40.62',
 'min': '39.53',
 'name': '招商银行',
 'open': '40.51',
 'turnover_rate': '0.82',
 'volumn': '675956',
 'volumn_hand': '1693236'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.83',
 'change': '0.52',
 'change_rate': '1.51',
 'close': '34.97',
 'date': '2020-05-08',
 'max': '35.18',
 'min': '34.55',
 'name': '招商银行',
 'open': '34.77',
 'turnover_rate': '0.19',
 'volumn': '137165',
 'volumn_hand': '392155'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.65',
 'change': '-0.18',
 'change_rate': '-0.52',
 'close': '34.45',
 'date': '2020-05-07',
 'max': '34.62',
 'min': '34.05',
 'name': '招商银行',
 'open': '34.60',
 'turnover_rate': '0.15',
 'volumn': '102879',
 'volumn_hand': '299485'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.71',
 'change': '-0.46',
 'change_rate': '-1.31',
 'close': '34.63',
 'date': '2020-05-06',
 'max': '34.78',
 'min': '34.18',
 'name': '招商银行',
 'open': '34.53',
 'turnover_rate': '0.24',
 'volumn': '173170',
 'volumn_hand': '501736'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-05-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.86',
 'change': '0.07',
 'change_rate': '0.20',
 'close': '35.09',
 'date': '2020-04-30',
 'max': '36.05',
 'min': '35.05',
 'name': '招商银行',
 'open': '35.15',
 'turnover_rate': '0.35',
 'volumn': '254480',
 'volumn_hand': '715332'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-30' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.57',
 'change': '1.16',
 'change_rate': '3.43',
 'close': '35.02',
 'date': '2020-04-29',
 'max': '35.10',
 'min': '33.89',
 'name': '招商银行',
 'open': '33.90',
 'turnover_rate': '0.32',
 'volumn': '228873',
 'volumn_hand': '658766'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-29' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.79',
 'change': '0.28',
 'change_rate': '0.83',
 'close': '33.86',
 'date': '2020-04-28',
 'max': '33.90',
 'min': '33.30',
 'name': '招商银行',
 'open': '33.60',
 'turnover_rate': '0.18',
 'volumn': '123443',
 'volumn_hand': '366511'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.88',
 'change': '1.07',
 'change_rate': '3.29',
 'close': '33.58',
 'date': '2020-04-27',
 'max': '33.98',
 'min': '32.72',
 'name': '招商银行',
 'open': '32.75',
 'turnover_rate': '0.32',
 'volumn': '219752',
 'volumn_hand': '653415'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.95',
 'change': '-0.18',
 'change_rate': '-0.55',
 'close': '32.51',
 'date': '2020-04-24',
 'max': '32.72',
 'min': '32.41',
 'name': '招商银行',
 'open': '32.72',
 'turnover_rate': '0.11',
 'volumn': '72377',
 'volumn_hand': '222598'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.95',
 'change': '-0.04',
 'change_rate': '-0.12',
 'close': '32.69',
 'date': '2020-04-23',
 'max': '32.96',
 'min': '32.65',
 'name': '招商银行',
 'open': '32.82',
 'turnover_rate': '0.12',
 'volumn': '80722',
 'volumn_hand': '246146'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.47',
 'change': '1.73',
 'change_rate': '5.90',
 'close': '31.04',
 'date': '2020-03-20',
 'max': '31.11',
 'min': '29.80',
 'name': '招商银行',
 'open': '29.80',
 'turnover_rate': '0.65',
 'volumn': '410190',
 'volumn_hand': '1343153'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.74',
 'change': '-1.51',
 'change_rate': '-4.90',
 'close': '29.31',
 'date': '2020-03-19',
 'max': '30.48',
 'min': '28.71',
 'name': '招商银行',
 'open': '30.48',
 'turnover_rate': '0.76',
 'volumn': '459189',
 'volumn_hand': '1559457'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.79',
 'change': '-0.91',
 'change_rate': '-2.87',
 'close': '30.82',
 'date': '2020-03-18',
 'max': '32.28',
 'min': '30.76',
 'name': '招商银行',
 'open': '31.88',
 'turnover_rate': '0.40',
 'volumn': '260492',
 'volumn_hand': '824317'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.74',
 'change': '0.06',
 'change_rate': '0.19',
 'close': '31.73',
 'date': '2020-03-17',
 'max': '32.61',
 'min': '31.11',
 'name': '招商银行',
 'open': '31.65',
 'turnover_rate': '0.41',
 'volumn': '267543',
 'volumn_hand': '843441'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.24',
 'change': '-1.74',
 'change_rate': '-5.21',
 'close': '31.67',
 'date': '2020-03-16',
 'max': '33.39',
 'min': '31.64',
 'name': '招商银行',
 'open': '33.39',
 'turnover_rate': '0.52',
 'volumn': '344534',
 'volumn_hand': '1066027'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.40',
 'change': '-0.75',
 'change_rate': '-2.20',
 'close': '33.41',
 'date': '2020-03-13',
 'max': '33.56',
 'min': '32.40',
 'name': '招商银行',
 'open': '32.80',
 'turnover_rate': '0.55',
 'volumn': '374837',
 'volumn_hand': '1140958'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.65',
 'change': '-0.29',
 'change_rate': '-0.84',
 'close': '34.16',
 'date': '2020-03-12',
 'max': '34.59',
 'min': '34.02',
 'name': '招商银行',
 'open': '34.37',
 'turnover_rate': '0.30',
 'volumn': '211826',
 'volumn_hand': '619180'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.67',
 'change': '-0.23',
 'change_rate': '-0.66',
 'close': '34.45',
 'date': '2020-03-11',
 'max': '34.99',
 'min': '34.41',
 'name': '招商银行',
 'open': '34.76',
 'turnover_rate': '0.27',
 'volumn': '196576',
 'volumn_hand': '566551'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.52',
 'change': '0.50',
 'change_rate': '1.46',
 'close': '34.68',
 'date': '2020-03-10',
 'max': '34.94',
 'min': '34.08',
 'name': '招商银行',
 'open': '34.19',
 'turnover_rate': '0.32',
 'volumn': '230986',
 'volumn_hand': '668298'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.63',
 'change': '-0.56',
 'change_rate': '-1.36',
 'close': '40.50',
 'date': '2020-07-08',
 'max': '41.87',
 'min': '39.97',
 'name': '招商银行',
 'open': '40.90',
 'turnover_rate': '0.89',
 'volumn': '745426',
 'volumn_hand': '1827039'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.93',
 'change': '0.65',
 'change_rate': '1.61',
 'close': '41.06',
 'date': '2020-07-07',
 'max': '43.30',
 'min': '40.50',
 'name': '招商银行',
 'open': '41.80',
 'turnover_rate': '0.98',
 'volumn': '838989',
 'volumn_hand': '2016338'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '8.79',
 'change': '3.67',
 'change_rate': '9.99',
 'close': '40.41',
 'date': '2020-07-06',
 'max': '40.41',
 'min': '37.18',
 'name': '招商银行',
 'open': '37.18',
 'turnover_rate': '0.91',
 'volumn': '736966',
 'volumn_hand': '1874929'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.99',
 'change': '1.44',
 'change_rate': '4.08',
 'close': '36.74',
 'date': '2020-07-03',
 'max': '36.76',
 'min': '35.35',
 'name': '招商银行',
 'open': '35.40',
 'turnover_rate': '0.74',
 'volumn': '558363',
 'volumn_hand': '1535704'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.36',
 'change': '0.51',
 'change_rate': '1.47',
 'close': '35.30',
 'date': '2020-07-02',
 'max': '35.47',
 'min': '34.30',
 'name': '招商银行',
 'open': '34.65',
 'turnover_rate': '0.60',
 'volumn': '434749',
 'volumn_hand': '1245178'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.53',
 'change': '1.07',
 'change_rate': '3.17',
 'close': '34.79',
 'date': '2020-07-01',
 'max': '34.80',
 'min': '33.61',
 'name': '招商银行',
 'open': '33.79',
 'turnover_rate': '0.39',
 'volumn': '274132',
 'volumn_hand': '799096'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-07-01' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.29',
 'change': '0.08',
 'change_rate': '0.25',
 'close': '32.73',
 'date': '2020-04-22',
 'max': '32.75',
 'min': '32.33',
 'name': '招商银行',
 'open': '32.45',
 'turnover_rate': '0.14',
 'volumn': '91010',
 'volumn_hand': '279435'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.40',
 'change': '-0.25',
 'change_rate': '-0.76',
 'close': '32.65',
 'date': '2020-04-21',
 'max': '33.04',
 'min': '32.58',
 'name': '招商银行',
 'open': '32.90',
 'turnover_rate': '0.16',
 'volumn': '107733',
 'volumn_hand': '328715'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.61',
 'change': '0.04',
 'change_rate': '0.12',
 'close': '32.90',
 'date': '2020-04-20',
 'max': '33.08',
 'min': '32.55',
 'name': '招商银行',
 'open': '32.89',
 'turnover_rate': '0.16',
 'volumn': '110435',
 'volumn_hand': '336024'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.68',
 'change': '0.76',
 'change_rate': '2.37',
 'close': '32.86',
 'date': '2020-04-17',
 'max': '33.20',
 'min': '32.34',
 'name': '招商银行',
 'open': '32.45',
 'turnover_rate': '0.34',
 'volumn': '229397',
 'volumn_hand': '697952'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.39',
 'change': '-0.32',
 'change_rate': '-0.99',
 'close': '32.10',
 'date': '2020-04-16',
 'max': '32.41',
 'min': '31.96',
 'name': '招商银行',
 'open': '32.20',
 'turnover_rate': '0.14',
 'volumn': '94745',
 'volumn_hand': '295000'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.95',
 'change': '-0.29',
 'change_rate': '-0.89',
 'close': '32.42',
 'date': '2020-04-15',
 'max': '32.63',
 'min': '32.32',
 'name': '招商银行',
 'open': '32.59',
 'turnover_rate': '0.12',
 'volumn': '77113',
 'volumn_hand': '237838'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.97',
 'change': '0.78',
 'change_rate': '2.44',
 'close': '32.71',
 'date': '2020-04-14',
 'max': '32.71',
 'min': '32.08',
 'name': '招商银行',
 'open': '32.18',
 'turnover_rate': '0.21',
 'volumn': '138601',
 'volumn_hand': '427079'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.18',
 'change': '-0.17',
 'change_rate': '-0.53',
 'close': '31.93',
 'date': '2020-04-13',
 'max': '32.20',
 'min': '31.82',
 'name': '招商银行',
 'open': '31.92',
 'turnover_rate': '0.11',
 'volumn': '73788',
 'volumn_hand': '230555'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.01',
 'change': '-0.20',
 'change_rate': '-0.62',
 'close': '32.10',
 'date': '2020-04-10',
 'max': '32.56',
 'min': '31.91',
 'name': '招商银行',
 'open': '32.41',
 'turnover_rate': '0.21',
 'volumn': '140944',
 'volumn_hand': '437432'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.74',
 'change': '0.08',
 'change_rate': '0.25',
 'close': '32.30',
 'date': '2020-04-09',
 'max': '32.35',
 'min': '32.11',
 'name': '招商银行',
 'open': '32.29',
 'turnover_rate': '0.14',
 'volumn': '92426',
 'volumn_hand': '286646'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.98',
 'change': '-1.23',
 'change_rate': '-3.47',
 'close': '34.18',
 'date': '2020-03-09',
 'max': '34.88',
 'min': '34.18',
 'name': '招商银行',
 'open': '34.88',
 'turnover_rate': '0.47',
 'volumn': '331807',
 'volumn_hand': '966592'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.68',
 'change': '-0.82',
 'change_rate': '-2.26',
 'close': '35.41',
 'date': '2020-03-06',
 'max': '36.02',
 'min': '35.41',
 'name': '招商银行',
 'open': '35.84',
 'turnover_rate': '0.33',
 'volumn': '238976',
 'volumn_hand': '670674'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.37',
 'change': '1.45',
 'change_rate': '4.17',
 'close': '36.23',
 'date': '2020-03-05',
 'max': '36.32',
 'min': '34.80',
 'name': '招商银行',
 'open': '34.99',
 'turnover_rate': '0.66',
 'volumn': '484061',
 'volumn_hand': '1355413'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-05' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.04',
 'change': '0.16',
 'change_rate': '0.46',
 'close': '34.78',
 'date': '2020-03-04',
 'max': '34.80',
 'min': '34.44',
 'name': '招商银行',
 'open': '34.68',
 'turnover_rate': '0.27',
 'volumn': '194180',
 'volumn_hand': '560886'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-04' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.96',
 'change': '-0.13',
 'change_rate': '-0.37',
 'close': '34.62',
 'date': '2020-03-03',
 'max': '35.10',
 'min': '34.42',
 'name': '招商银行',
 'open': '34.93',
 'turnover_rate': '0.33',
 'volumn': '238042',
 'volumn_hand': '686073'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.28',
 'change': '0.55',
 'change_rate': '1.61',
 'close': '34.75',
 'date': '2020-03-02',
 'max': '34.88',
 'min': '34.10',
 'name': '招商银行',
 'open': '34.24',
 'turnover_rate': '0.34',
 'volumn': '243803',
 'volumn_hand': '704291'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-03-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.78',
 'change': '-1.02',
 'change_rate': '-2.90',
 'close': '34.20',
 'date': '2020-02-28',
 'max': '35.18',
 'min': '34.20',
 'name': '招商银行',
 'open': '34.85',
 'turnover_rate': '0.40',
 'volumn': '288540',
 'volumn_hand': '835341'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-28' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.87',
 'change': '0.39',
 'change_rate': '1.12',
 'close': '35.22',
 'date': '2020-02-27',
 'max': '35.35',
 'min': '34.70',
 'name': '招商银行',
 'open': '34.79',
 'turnover_rate': '0.33',
 'volumn': '242207',
 'volumn_hand': '689379'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-27' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.14',
 'change': '0.20',
 'change_rate': '0.58',
 'close': '34.83',
 'date': '2020-02-26',
 'max': '34.99',
 'min': '34.25',
 'name': '招商银行',
 'open': '34.41',
 'turnover_rate': '0.38',
 'volumn': '270759',
 'volumn_hand': '779705'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-26' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.17',
 'change': '-0.30',
 'change_rate': '-0.92',
 'close': '32.22',
 'date': '2020-04-08',
 'max': '32.50',
 'min': '32.12',
 'name': '招商银行',
 'open': '32.50',
 'turnover_rate': '0.15',
 'volumn': '102496',
 'volumn_hand': '318134'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.49',
 'change': '0.37',
 'change_rate': '1.15',
 'close': '32.52',
 'date': '2020-04-07',
 'max': '32.88',
 'min': '32.40',
 'name': '招商银行',
 'open': '32.84',
 'turnover_rate': '0.21',
 'volumn': '140673',
 'volumn_hand': '431844'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.02',
 'change': '-0.19',
 'change_rate': '-0.59',
 'close': '32.15',
 'date': '2020-04-03',
 'max': '32.32',
 'min': '31.99',
 'name': '招商银行',
 'open': '32.00',
 'turnover_rate': '0.12',
 'volumn': '80870',
 'volumn_hand': '251618'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.96',
 'change': '0.21',
 'change_rate': '0.65',
 'close': '32.34',
 'date': '2020-04-02',
 'max': '32.34',
 'min': '31.71',
 'name': '招商银行',
 'open': '31.75',
 'turnover_rate': '0.14',
 'volumn': '92919',
 'volumn_hand': '289601'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-02' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.01',
 'change': '-0.15',
 'change_rate': '-0.46',
 'close': '32.13',
 'date': '2020-04-01',
 'max': '32.65',
 'min': '32.00',
 'name': '招商银行',
 'open': '32.12',
 'turnover_rate': '0.17',
 'volumn': '115735',
 'volumn_hand': '358143'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-04-01' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.65',
 'change': '-0.42',
 'change_rate': '-1.20',
 'close': '34.63',
 'date': '2020-02-25',
 'max': '35.08',
 'min': '34.50',
 'name': '招商银行',
 'open': '34.81',
 'turnover_rate': '0.42',
 'volumn': '303221',
 'volumn_hand': '873734'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-25' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.85',
 'change': '-0.59',
 'change_rate': '-1.66',
 'close': '35.05',
 'date': '2020-02-24',
 'max': '35.69',
 'min': '35.03',
 'name': '招商银行',
 'open': '35.49',
 'turnover_rate': '0.39',
 'volumn': '281204',
 'volumn_hand': '798565'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-24' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.28',
 'change': '-0.34',
 'change_rate': '-0.95',
 'close': '35.64',
 'date': '2020-02-21',
 'max': '35.93',
 'min': '35.47',
 'name': '招商银行',
 'open': '35.90',
 'turnover_rate': '0.35',
 'volumn': '260311',
 'volumn_hand': '730315'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.39',
 'change': '0.45',
 'change_rate': '1.27',
 'close': '35.98',
 'date': '2020-02-20',
 'max': '36.05',
 'min': '35.20',
 'name': '招商银行',
 'open': '35.66',
 'turnover_rate': '0.36',
 'volumn': '265812',
 'volumn_hand': '746006'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.20',
 'change': '-0.17',
 'change_rate': '-0.48',
 'close': '35.53',
 'date': '2020-02-19',
 'max': '35.89',
 'min': '35.46',
 'name': '招商银行',
 'open': '35.60',
 'turnover_rate': '0.20',
 'volumn': '149614',
 'volumn_hand': '419521'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-19' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.11',
 'change': '-0.47',
 'change_rate': '-1.30',
 'close': '35.70',
 'date': '2020-02-18',
 'max': '36.00',
 'min': '35.60',
 'name': '招商银行',
 'open': '36.00',
 'turnover_rate': '0.25',
 'volumn': '184626',
 'volumn_hand': '516397'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-18' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.22',
 'change': '0.53',
 'change_rate': '1.49',
 'close': '36.17',
 'date': '2020-02-17',
 'max': '36.17',
 'min': '35.38',
 'name': '招商银行',
 'open': '35.63',
 'turnover_rate': '0.32',
 'volumn': '239666',
 'volumn_hand': '669425'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.42',
 'change': '0.37',
 'change_rate': '1.05',
 'close': '35.64',
 'date': '2020-02-14',
 'max': '35.71',
 'min': '35.21',
 'name': '招商银行',
 'open': '35.21',
 'turnover_rate': '0.20',
 'volumn': '143181',
 'volumn_hand': '403397'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.98',
 'change': '-0.33',
 'change_rate': '-0.93',
 'close': '35.27',
 'date': '2020-02-13',
 'max': '35.55',
 'min': '35.20',
 'name': '招商银行',
 'open': '35.53',
 'turnover_rate': '0.20',
 'volumn': '149378',
 'volumn_hand': '422351'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.18',
 'change': '0.03',
 'change_rate': '0.08',
 'close': '35.60',
 'date': '2020-02-12',
 'max': '35.66',
 'min': '35.24',
 'name': '招商银行',
 'open': '35.50',
 'turnover_rate': '0.20',
 'volumn': '143718',
 'volumn_hand': '405390'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-12' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.99',
 'change': '0.47',
 'change_rate': '1.34',
 'close': '35.57',
 'date': '2020-02-11',
 'max': '35.85',
 'min': '35.15',
 'name': '招商银行',
 'open': '35.30',
 'turnover_rate': '0.27',
 'volumn': '198377',
 'volumn_hand': '557436'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-11' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.82',
 'change': '-0.32',
 'change_rate': '-0.90',
 'close': '35.10',
 'date': '2020-02-10',
 'max': '35.24',
 'min': '34.95',
 'name': '招商银行',
 'open': '35.13',
 'turnover_rate': '0.28',
 'volumn': '201640',
 'volumn_hand': '575042'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.26',
 'change': '-0.33',
 'change_rate': '-0.92',
 'close': '35.42',
 'date': '2020-02-07',
 'max': '35.46',
 'min': '35.01',
 'name': '招商银行',
 'open': '35.10',
 'turnover_rate': '0.33',
 'volumn': '237419',
 'volumn_hand': '675525'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.98',
 'change': '0.39',
 'change_rate': '1.10',
 'close': '35.75',
 'date': '2020-02-06',
 'max': '35.83',
 'min': '35.13',
 'name': '招商银行',
 'open': '35.50',
 'turnover_rate': '0.35',
 'volumn': '258947',
 'volumn_hand': '730702'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.92',
 'change': '0.01',
 'change_rate': '0.03',
 'close': '35.36',
 'date': '2020-02-05',
 'max': '35.51',
 'min': '34.83',
 'name': '招商银行',
 'open': '35.34',
 'turnover_rate': '0.39',
 'volumn': '282686',
 'volumn_hand': '802572'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-05' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.28',
 'change': '0.32',
 'change_rate': '0.91',
 'close': '35.35',
 'date': '2020-02-04',
 'max': '35.48',
 'min': '34.68',
 'name': '招商银行',
 'open': '35.04',
 'turnover_rate': '0.60',
 'volumn': '431305',
 'volumn_hand': '1229677'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-04' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.62',
 'change': '-1.78',
 'change_rate': '-4.84',
 'close': '35.03',
 'date': '2020-02-03',
 'max': '35.50',
 'min': '33.80',
 'name': '招商银行',
 'open': '33.80',
 'turnover_rate': '0.55',
 'volumn': '394480',
 'volumn_hand': '1131062'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-02-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.31',
 'change': '-1.01',
 'change_rate': '-2.67',
 'close': '36.81',
 'date': '2020-01-23',
 'max': '37.70',
 'min': '36.45',
 'name': '招商银行',
 'open': '37.53',
 'turnover_rate': '0.38',
 'volumn': '291230',
 'volumn_hand': '787503'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-23' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.51',
 'change': '0.03',
 'change_rate': '0.08',
 'close': '37.82',
 'date': '2020-01-22',
 'max': '38.10',
 'min': '37.15',
 'name': '招商银行',
 'open': '37.70',
 'turnover_rate': '0.26',
 'volumn': '200062',
 'volumn_hand': '531255'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-22' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.17',
 'change': '-0.52',
 'change_rate': '-1.36',
 'close': '37.79',
 'date': '2020-01-21',
 'max': '38.15',
 'min': '37.70',
 'name': '招商银行',
 'open': '37.95',
 'turnover_rate': '0.20',
 'volumn': '158033',
 'volumn_hand': '417202'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-21' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.71',
 'change': '0.38',
 'change_rate': '1.00',
 'close': '38.31',
 'date': '2020-01-20',
 'max': '38.65',
 'min': '38.00',
 'name': '招商银行',
 'open': '38.22',
 'turnover_rate': '0.28',
 'volumn': '224427',
 'volumn_hand': '585809'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-20' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.29',
 'change': '-0.03',
 'change_rate': '-0.08',
 'close': '37.93',
 'date': '2020-01-17',
 'max': '38.17',
 'min': '37.68',
 'name': '招商银行',
 'open': '38.06',
 'turnover_rate': '0.20',
 'volumn': '159579',
 'volumn_hand': '421357'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-17' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.55',
 'change': '-0.16',
 'change_rate': '-0.42',
 'close': '37.96',
 'date': '2020-01-16',
 'max': '38.35',
 'min': '37.76',
 'name': '招商银行',
 'open': '38.22',
 'turnover_rate': '0.22',
 'volumn': '172328',
 'volumn_hand': '453848'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-16' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.24',
 'change': '-0.69',
 'change_rate': '-1.78',
 'close': '38.12',
 'date': '2020-01-15',
 'max': '38.89',
 'min': '38.02',
 'name': '招商银行',
 'open': '38.84',
 'turnover_rate': '0.24',
 'volumn': '187005',
 'volumn_hand': '488599'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-15' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.38',
 'change': '-0.29',
 'change_rate': '-0.74',
 'close': '38.81',
 'date': '2020-01-14',
 'max': '39.63',
 'min': '38.70',
 'name': '招商银行',
 'open': '39.14',
 'turnover_rate': '0.16',
 'volumn': '131443',
 'volumn_hand': '335646'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-14' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.36',
 'change': '0.06',
 'change_rate': '0.15',
 'close': '39.10',
 'date': '2020-01-13',
 'max': '39.28',
 'min': '38.75',
 'name': '招商银行',
 'open': '39.28',
 'turnover_rate': '0.16',
 'volumn': '127907',
 'volumn_hand': '327809'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-13' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.36',
 'change': '0.14',
 'change_rate': '0.36',
 'close': '39.04',
 'date': '2020-01-10',
 'max': '39.28',
 'min': '38.75',
 'name': '招商银行',
 'open': '38.90',
 'turnover_rate': '0.14',
 'volumn': '111690',
 'volumn_hand': '285931'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-10' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.09',
 'change': '0.49',
 'change_rate': '1.28',
 'close': '38.90',
 'date': '2020-01-09',
 'max': '39.00',
 'min': '38.58',
 'name': '招商银行',
 'open': '38.84',
 'turnover_rate': '0.15',
 'volumn': '117700',
 'volumn_hand': '303360'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-09' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.38',
 'change': '-0.74',
 'change_rate': '-1.89',
 'close': '38.41',
 'date': '2020-01-08',
 'max': '38.95',
 'min': '38.41',
 'name': '招商银行',
 'open': '38.95',
 'turnover_rate': '0.18',
 'volumn': '140386',
 'volumn_hand': '363234'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-08' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.14',
 'change': '-0.09',
 'change_rate': '-0.23',
 'close': '39.15',
 'date': '2020-01-07',
 'max': '39.94',
 'min': '39.10',
 'name': '招商银行',
 'open': '39.55',
 'turnover_rate': '0.17',
 'volumn': '136930',
 'volumn_hand': '347671'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-07' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.20',
 'change': '-0.16',
 'change_rate': '-0.41',
 'close': '39.24',
 'date': '2020-01-06',
 'max': '40.16',
 'min': '38.90',
 'name': '招商银行',
 'open': '39.19',
 'turnover_rate': '0.27',
 'volumn': '217158',
 'volumn_hand': '548877'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-06' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.80',
 'change': '0.52',
 'change_rate': '1.34',
 'close': '39.40',
 'date': '2020-01-03',
 'max': '39.62',
 'min': '38.92',
 'name': '招商银行',
 'open': '38.95',
 'turnover_rate': '0.25',
 'volumn': '204523',
 'volumn_hand': '520106'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-03' for key 'uk_t_1'")
2020-08-02 22:59:06 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.93',
 'change': '1.30',
 'change_rate': '3.46',
 'close': '38.88',
 'date': '2020-01-02',
 'max': '39.12',
 'min': '38.02',
 'name': '招商银行',
 'open': '38.03',
 'turnover_rate': '0.40',
 'volumn': '319118',
 'volumn_hand': '826245'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '招商银行-2020-01-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=2&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=0&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=2&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=2&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=0&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=0&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=2&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_601398.html?year=0&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.30',
 'change': '-0.07',
 'change_rate': '-1.34',
 'close': '5.15',
 'date': '2020-03-31',
 'max': '5.24',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.22',
 'turnover_rate': '0.07',
 'volumn': '91232',
 'volumn_hand': '1761032'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-31' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.73',
 'change': '0.01',
 'change_rate': '0.19',
 'close': '5.22',
 'date': '2020-03-30',
 'max': '5.24',
 'min': '5.15',
 'name': '工商银行',
 'open': '5.18',
 'turnover_rate': '0.07',
 'volumn': '101661',
 'volumn_hand': '1953885'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.35',
 'change': '0.03',
 'change_rate': '0.58',
 'close': '5.21',
 'date': '2020-03-27',
 'max': '5.25',
 'min': '5.18',
 'name': '工商银行',
 'open': '5.21',
 'turnover_rate': '0.06',
 'volumn': '90105',
 'volumn_hand': '1727365'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.12',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.18',
 'date': '2020-03-26',
 'max': '5.22',
 'min': '5.11',
 'name': '工商银行',
 'open': '5.13',
 'turnover_rate': '0.06',
 'volumn': '80514',
 'volumn_hand': '1556128'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-26' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.56',
 'change': '0.06',
 'change_rate': '1.17',
 'close': '5.18',
 'date': '2020-03-25',
 'max': '5.18',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.17',
 'turnover_rate': '0.09',
 'volumn': '119548',
 'volumn_hand': '2321786'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-25' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.00',
 'change': '0.13',
 'change_rate': '2.61',
 'close': '5.12',
 'date': '2020-03-24',
 'max': '5.12',
 'min': '5.02',
 'name': '工商银行',
 'open': '5.02',
 'turnover_rate': '0.09',
 'volumn': '116651',
 'volumn_hand': '2303316'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.98',
 'change': '-0.09',
 'change_rate': '-1.77',
 'close': '4.99',
 'date': '2020-03-23',
 'max': '5.03',
 'min': '4.98',
 'name': '工商银行',
 'open': '5.00',
 'turnover_rate': '0.05',
 'volumn': '69917',
 'volumn_hand': '1399893'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.20',
 'change': '0.09',
 'change_rate': '1.80',
 'close': '5.08',
 'date': '2020-03-20',
 'max': '5.11',
 'min': '5.00',
 'name': '工商银行',
 'open': '5.02',
 'turnover_rate': '0.08',
 'volumn': '107351',
 'volumn_hand': '2125136'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.72',
 'change': '-0.12',
 'change_rate': '-2.35',
 'close': '4.99',
 'date': '2020-03-19',
 'max': '5.12',
 'min': '4.93',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.11',
 'volumn': '145221',
 'volumn_hand': '2898850'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.74',
 'change': '-0.06',
 'change_rate': '-1.16',
 'close': '5.11',
 'date': '2020-03-18',
 'max': '5.20',
 'min': '5.11',
 'name': '工商银行',
 'open': '5.18',
 'turnover_rate': '0.08',
 'volumn': '104518',
 'volumn_hand': '2025068'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.13',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.17',
 'date': '2020-03-17',
 'max': '5.23',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.16',
 'turnover_rate': '0.10',
 'volumn': '132926',
 'volumn_hand': '2577129'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.87',
 'change': '-0.05',
 'change_rate': '-0.96',
 'close': '5.17',
 'date': '2020-03-16',
 'max': '5.29',
 'min': '5.14',
 'name': '工商银行',
 'open': '5.22',
 'turnover_rate': '0.11',
 'volumn': '158644',
 'volumn_hand': '3044663'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.65',
 'change': '-0.07',
 'change_rate': '-1.32',
 'close': '5.22',
 'date': '2020-03-13',
 'max': '5.27',
 'min': '5.13',
 'name': '工商银行',
 'open': '5.16',
 'turnover_rate': '0.11',
 'volumn': '155365',
 'volumn_hand': '2997241'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.94',
 'change': '-0.03',
 'change_rate': '-0.56',
 'close': '5.29',
 'date': '2020-03-12',
 'max': '5.32',
 'min': '5.27',
 'name': '工商银行',
 'open': '5.30',
 'turnover_rate': '0.09',
 'volumn': '130300',
 'volumn_hand': '2462965'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.93',
 'change': '-0.04',
 'change_rate': '-0.75',
 'close': '5.32',
 'date': '2020-03-11',
 'max': '5.37',
 'min': '5.32',
 'name': '工商银行',
 'open': '5.35',
 'turnover_rate': '0.06',
 'volumn': '90448',
 'volumn_hand': '1694070'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.51',
 'change': '0.05',
 'change_rate': '0.94',
 'close': '5.36',
 'date': '2020-03-10',
 'max': '5.37',
 'min': '5.29',
 'name': '工商银行',
 'open': '5.29',
 'turnover_rate': '0.09',
 'volumn': '133620',
 'volumn_hand': '2508208'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.92',
 'change': '-0.10',
 'change_rate': '-1.85',
 'close': '5.31',
 'date': '2020-03-09',
 'max': '5.35',
 'min': '5.30',
 'name': '工商银行',
 'open': '5.34',
 'turnover_rate': '0.11',
 'volumn': '153268',
 'volumn_hand': '2880620'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.73',
 'change': '-0.05',
 'change_rate': '-0.92',
 'close': '5.41',
 'date': '2020-03-06',
 'max': '5.43',
 'min': '5.39',
 'name': '工商银行',
 'open': '5.42',
 'turnover_rate': '0.07',
 'volumn': '105930',
 'volumn_hand': '1959499'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.48',
 'change': '0.07',
 'change_rate': '1.30',
 'close': '5.46',
 'date': '2020-03-05',
 'max': '5.46',
 'min': '5.38',
 'name': '工商银行',
 'open': '5.40',
 'turnover_rate': '0.12',
 'volumn': '179497',
 'volumn_hand': '3305398'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-05' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.56',
 'change': '0.01',
 'change_rate': '0.19',
 'close': '5.39',
 'date': '2020-03-04',
 'max': '5.39',
 'min': '5.36',
 'name': '工商银行',
 'open': '5.37',
 'turnover_rate': '0.05',
 'volumn': '72191',
 'volumn_hand': '1342816'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-04' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.93',
 'change': '0.02',
 'change_rate': '0.37',
 'close': '5.38',
 'date': '2020-03-03',
 'max': '5.40',
 'min': '5.35',
 'name': '工商银行',
 'open': '5.37',
 'turnover_rate': '0.09',
 'volumn': '137400',
 'volumn_hand': '2554032'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.32',
 'change': '0.06',
 'change_rate': '1.13',
 'close': '5.36',
 'date': '2020-03-02',
 'max': '5.36',
 'min': '5.29',
 'name': '工商银行',
 'open': '5.30',
 'turnover_rate': '0.09',
 'volumn': '127983',
 'volumn_hand': '2399023'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-03-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.85',
 'change': '-0.10',
 'change_rate': '-1.85',
 'close': '5.30',
 'date': '2020-02-28',
 'max': '5.38',
 'min': '5.28',
 'name': '工商银行',
 'open': '5.37',
 'turnover_rate': '0.16',
 'volumn': '225622',
 'volumn_hand': '4229371'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.55',
 'change': '-0.01',
 'change_rate': '-0.18',
 'close': '5.40',
 'date': '2020-02-27',
 'max': '5.42',
 'min': '5.39',
 'name': '工商银行',
 'open': '5.40',
 'turnover_rate': '0.08',
 'volumn': '120222',
 'volumn_hand': '2225556'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.48',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.41',
 'date': '2020-02-26',
 'max': '5.44',
 'min': '5.36',
 'name': '工商银行',
 'open': '5.38',
 'turnover_rate': '0.10',
 'volumn': '139332',
 'volumn_hand': '2579688'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-26' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.40',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '4.98',
 'date': '2020-06-30',
 'max': '5.03',
 'min': '4.96',
 'name': '工商银行',
 'open': '5.00',
 'turnover_rate': '0.08',
 'volumn': '106443',
 'volumn_hand': '2135599'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.11',
 'change': '0.03',
 'change_rate': '0.57',
 'close': '5.25',
 'date': '2020-06-29',
 'max': '5.31',
 'min': '5.20',
 'name': '工商银行',
 'open': '5.28',
 'turnover_rate': '0.11',
 'volumn': '157489',
 'volumn_hand': '3000963'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.95',
 'change': '0.08',
 'change_rate': '1.56',
 'close': '5.22',
 'date': '2020-06-24',
 'max': '5.24',
 'min': '5.14',
 'name': '工商银行',
 'open': '5.15',
 'turnover_rate': '0.07',
 'volumn': '100833',
 'volumn_hand': '1941728'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.14',
 'date': '2020-06-23',
 'max': '5.16',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.16',
 'turnover_rate': '0.07',
 'volumn': '92436',
 'volumn_hand': '1798935'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.15',
 'change': '-0.04',
 'change_rate': '-0.77',
 'close': '5.16',
 'date': '2020-06-22',
 'max': '5.22',
 'min': '5.16',
 'name': '工商银行',
 'open': '5.20',
 'turnover_rate': '0.06',
 'volumn': '81437',
 'volumn_hand': '1569840'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.16',
 'change': '0.01',
 'change_rate': '0.19',
 'close': '5.20',
 'date': '2020-06-19',
 'max': '5.21',
 'min': '5.15',
 'name': '工商银行',
 'open': '5.18',
 'turnover_rate': '0.07',
 'volumn': '102945',
 'volumn_hand': '1986051'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.55',
 'change': '-0.03',
 'change_rate': '-0.55',
 'close': '5.41',
 'date': '2020-02-25',
 'max': '5.42',
 'min': '5.39',
 'name': '工商银行',
 'open': '5.40',
 'turnover_rate': '0.09',
 'volumn': '124347',
 'volumn_hand': '2301333'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-25' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.09',
 'change': '-0.05',
 'change_rate': '-0.91',
 'close': '5.44',
 'date': '2020-02-24',
 'max': '5.49',
 'min': '5.43',
 'name': '工商银行',
 'open': '5.48',
 'turnover_rate': '0.07',
 'volumn': '105369',
 'volumn_hand': '1933292'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.91',
 'change': '-0.02',
 'change_rate': '-0.36',
 'close': '5.49',
 'date': '2020-02-21',
 'max': '5.52',
 'min': '5.47',
 'name': '工商银行',
 'open': '5.49',
 'turnover_rate': '0.08',
 'volumn': '122819',
 'volumn_hand': '2237103'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.46',
 'change': '0.03',
 'change_rate': '0.55',
 'close': '5.51',
 'date': '2020-02-20',
 'max': '5.52',
 'min': '5.44',
 'name': '工商银行',
 'open': '5.48',
 'turnover_rate': '0.11',
 'volumn': '155248',
 'volumn_hand': '2836681'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.92',
 'change': '0.02',
 'change_rate': '0.37',
 'close': '5.48',
 'date': '2020-02-19',
 'max': '5.50',
 'min': '5.45',
 'name': '工商银行',
 'open': '5.45',
 'turnover_rate': '0.08',
 'volumn': '111599',
 'volumn_hand': '2040524'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.73',
 'change': '-0.03',
 'change_rate': '-0.55',
 'close': '5.46',
 'date': '2020-02-18',
 'max': '5.48',
 'min': '5.44',
 'name': '工商银行',
 'open': '5.47',
 'turnover_rate': '0.07',
 'volumn': '100706',
 'volumn_hand': '1845424'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.47',
 'change': '0.06',
 'change_rate': '1.11',
 'close': '5.49',
 'date': '2020-02-17',
 'max': '5.49',
 'min': '5.41',
 'name': '工商银行',
 'open': '5.42',
 'turnover_rate': '0.08',
 'volumn': '116912',
 'volumn_hand': '2141949'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.92',
 'change': '0.02',
 'change_rate': '0.37',
 'close': '5.43',
 'date': '2020-02-14',
 'max': '5.44',
 'min': '5.39',
 'name': '工商银行',
 'open': '5.40',
 'turnover_rate': '0.05',
 'volumn': '76713',
 'volumn_hand': '1415764'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.92',
 'change': '-0.05',
 'change_rate': '-0.92',
 'close': '5.41',
 'date': '2020-02-13',
 'max': '5.45',
 'min': '5.40',
 'name': '工商银行',
 'open': '5.45',
 'turnover_rate': '0.07',
 'volumn': '108201',
 'volumn_hand': '1995658'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.14',
 'change': '-0.07',
 'change_rate': '-1.33',
 'close': '5.19',
 'date': '2020-06-18',
 'max': '5.22',
 'min': '5.16',
 'name': '工商银行',
 'open': '5.20',
 'turnover_rate': '0.08',
 'volumn': '109507',
 'volumn_hand': '2109655'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.94',
 'change': '-0.04',
 'change_rate': '-0.75',
 'close': '5.26',
 'date': '2020-06-17',
 'max': '5.30',
 'min': '5.25',
 'name': '工商银行',
 'open': '5.28',
 'turnover_rate': '0.03',
 'volumn': '46348',
 'volumn_hand': '879845'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.95',
 'change': '0.06',
 'change_rate': '1.15',
 'close': '5.30',
 'date': '2020-06-16',
 'max': '5.31',
 'min': '5.26',
 'name': '工商银行',
 'open': '5.27',
 'turnover_rate': '0.05',
 'volumn': '65085',
 'volumn_hand': '1230380'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.53',
 'change': '0.02',
 'change_rate': '0.38',
 'close': '5.24',
 'date': '2020-06-15',
 'max': '5.31',
 'min': '5.23',
 'name': '工商银行',
 'open': '5.24',
 'turnover_rate': '0.08',
 'volumn': '113790',
 'volumn_hand': '2160776'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.28',
 'change': '-0.05',
 'change_rate': '-0.95',
 'close': '5.22',
 'date': '2020-06-12',
 'max': '5.32',
 'min': '5.20',
 'name': '工商银行',
 'open': '5.23',
 'turnover_rate': '0.14',
 'volumn': '200267',
 'volumn_hand': '3797260'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.14',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.27',
 'date': '2020-06-11',
 'max': '5.30',
 'min': '5.24',
 'name': '工商银行',
 'open': '5.27',
 'turnover_rate': '0.07',
 'volumn': '106508',
 'volumn_hand': '2019545'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.57',
 'change': '0.01',
 'change_rate': '0.19',
 'close': '5.27',
 'date': '2020-06-10',
 'max': '5.28',
 'min': '5.25',
 'name': '工商银行',
 'open': '5.27',
 'turnover_rate': '0.05',
 'volumn': '68577',
 'volumn_hand': '1301162'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.95',
 'change': '0.02',
 'change_rate': '0.38',
 'close': '5.26',
 'date': '2020-06-09',
 'max': '5.28',
 'min': '5.23',
 'name': '工商银行',
 'open': '5.24',
 'turnover_rate': '0.04',
 'volumn': '62418',
 'volumn_hand': '1186765'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.15',
 'change': '0.03',
 'change_rate': '0.58',
 'close': '5.24',
 'date': '2020-06-08',
 'max': '5.26',
 'min': '5.20',
 'name': '工商银行',
 'open': '5.22',
 'turnover_rate': '0.06',
 'volumn': '89467',
 'volumn_hand': '1709294'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.20',
 'change': '-0.02',
 'change_rate': '-0.40',
 'close': '4.96',
 'date': '2020-07-31',
 'max': '5.01',
 'min': '4.95',
 'name': '工商银行',
 'open': '4.98',
 'turnover_rate': '0.09',
 'volumn': '126835',
 'volumn_hand': '2549673'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-31' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.80',
 'change': '-0.04',
 'change_rate': '-0.80',
 'close': '4.98',
 'date': '2020-07-30',
 'max': '5.02',
 'min': '4.98',
 'name': '工商银行',
 'open': '5.02',
 'turnover_rate': '0.06',
 'volumn': '76844',
 'volumn_hand': '1537829'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.81',
 'change': '0.04',
 'change_rate': '0.80',
 'close': '5.02',
 'date': '2020-07-29',
 'max': '5.02',
 'min': '4.93',
 'name': '工商银行',
 'open': '4.97',
 'turnover_rate': '0.10',
 'volumn': '137557',
 'volumn_hand': '2758567'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.80',
 'change': '0.01',
 'change_rate': '0.20',
 'close': '4.98',
 'date': '2020-07-28',
 'max': '5.00',
 'min': '4.96',
 'name': '工商银行',
 'open': '4.99',
 'turnover_rate': '0.06',
 'volumn': '87035',
 'volumn_hand': '1748446'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.00',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '4.97',
 'date': '2020-07-27',
 'max': '5.00',
 'min': '4.95',
 'name': '工商银行',
 'open': '4.98',
 'turnover_rate': '0.08',
 'volumn': '108202',
 'volumn_hand': '2176345'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.39',
 'change': '-0.05',
 'change_rate': '-0.99',
 'close': '4.98',
 'date': '2020-07-24',
 'max': '5.03',
 'min': '4.96',
 'name': '工商银行',
 'open': '5.03',
 'turnover_rate': '0.13',
 'volumn': '181704',
 'volumn_hand': '3637610'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.18',
 'change': '-0.06',
 'change_rate': '-1.18',
 'close': '5.03',
 'date': '2020-07-23',
 'max': '5.08',
 'min': '5.02',
 'name': '工商银行',
 'open': '5.07',
 'turnover_rate': '0.14',
 'volumn': '189016',
 'volumn_hand': '3751366'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.37',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '5.09',
 'date': '2020-07-22',
 'max': '5.14',
 'min': '5.07',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.11',
 'volumn': '149337',
 'volumn_hand': '2926611'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.92',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.46',
 'date': '2020-02-12',
 'max': '5.47',
 'min': '5.42',
 'name': '工商银行',
 'open': '5.46',
 'turnover_rate': '0.08',
 'volumn': '110915',
 'volumn_hand': '2039144'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.11',
 'change': '0.04',
 'change_rate': '0.74',
 'close': '5.46',
 'date': '2020-02-11',
 'max': '5.47',
 'min': '5.41',
 'name': '工商银行',
 'open': '5.43',
 'turnover_rate': '0.07',
 'volumn': '108100',
 'volumn_hand': '1984985'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.92',
 'change': '-0.02',
 'change_rate': '-0.37',
 'close': '5.42',
 'date': '2020-02-10',
 'max': '5.43',
 'min': '5.38',
 'name': '工商银行',
 'open': '5.41',
 'turnover_rate': '0.07',
 'volumn': '102765',
 'volumn_hand': '1902386'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.27',
 'change': '-0.06',
 'change_rate': '-1.09',
 'close': '5.44',
 'date': '2020-02-07',
 'max': '5.47',
 'min': '5.40',
 'name': '工商银行',
 'open': '5.47',
 'turnover_rate': '0.09',
 'volumn': '128843',
 'volumn_hand': '2373190'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.64',
 'change': '0.01',
 'change_rate': '0.18',
 'close': '5.50',
 'date': '2020-02-06',
 'max': '5.53',
 'min': '5.44',
 'name': '工商银行',
 'open': '5.50',
 'turnover_rate': '0.10',
 'volumn': '153896',
 'volumn_hand': '2809954'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.82',
 'change': '-0.01',
 'change_rate': '-0.18',
 'close': '5.49',
 'date': '2020-02-05',
 'max': '5.52',
 'min': '5.42',
 'name': '工商银行',
 'open': '5.49',
 'turnover_rate': '0.09',
 'volumn': '137446',
 'volumn_hand': '2508538'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-05' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.14',
 'change': '0.08',
 'change_rate': '1.48',
 'close': '5.50',
 'date': '2020-02-04',
 'max': '5.53',
 'min': '5.36',
 'name': '工商银行',
 'open': '5.39',
 'turnover_rate': '0.15',
 'volumn': '217887',
 'volumn_hand': '4013853'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-04' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.90',
 'change': '-0.30',
 'change_rate': '-5.24',
 'close': '5.42',
 'date': '2020-02-03',
 'max': '5.58',
 'min': '5.30',
 'name': '工商银行',
 'open': '5.30',
 'turnover_rate': '0.17',
 'volumn': '252427',
 'volumn_hand': '4680399'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-02-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.38',
 'change': '-0.07',
 'change_rate': '-1.21',
 'close': '5.72',
 'date': '2020-01-23',
 'max': '5.78',
 'min': '5.70',
 'name': '工商银行',
 'open': '5.76',
 'turnover_rate': '0.07',
 'volumn': '114624',
 'volumn_hand': '2000377'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.39',
 'change': '0.02',
 'change_rate': '0.35',
 'close': '5.79',
 'date': '2020-01-22',
 'max': '5.79',
 'min': '5.71',
 'name': '工商银行',
 'open': '5.76',
 'turnover_rate': '0.05',
 'volumn': '73887',
 'volumn_hand': '1283708'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.20',
 'change': '-0.07',
 'change_rate': '-1.20',
 'close': '5.77',
 'date': '2020-01-21',
 'max': '5.83',
 'min': '5.76',
 'name': '工商银行',
 'open': '5.82',
 'turnover_rate': '0.05',
 'volumn': '82827',
 'volumn_hand': '1432237'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.16',
 'change': '0.03',
 'change_rate': '0.58',
 'close': '5.21',
 'date': '2020-06-05',
 'max': '5.22',
 'min': '5.16',
 'name': '工商银行',
 'open': '5.19',
 'turnover_rate': '0.04',
 'volumn': '56991',
 'volumn_hand': '1098658'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-05' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.77',
 'change': '-0.01',
 'change_rate': '-0.19',
 'close': '5.18',
 'date': '2020-06-04',
 'max': '5.21',
 'min': '5.17',
 'name': '工商银行',
 'open': '5.20',
 'turnover_rate': '0.03',
 'volumn': '39606',
 'volumn_hand': '763941'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-04' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.16',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.19',
 'date': '2020-06-03',
 'max': '5.24',
 'min': '5.18',
 'name': '工商银行',
 'open': '5.20',
 'turnover_rate': '0.05',
 'volumn': '70010',
 'volumn_hand': '1345468'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.16',
 'change': '0.03',
 'change_rate': '0.58',
 'close': '5.19',
 'date': '2020-06-02',
 'max': '5.19',
 'min': '5.13',
 'name': '工商银行',
 'open': '5.15',
 'turnover_rate': '0.06',
 'volumn': '78875',
 'volumn_hand': '1528292'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '0.04',
 'change_rate': '0.78',
 'close': '5.16',
 'date': '2020-06-01',
 'max': '5.16',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.13',
 'turnover_rate': '0.04',
 'volumn': '54014',
 'volumn_hand': '1050079'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-06-01' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.97',
 'change': '-0.05',
 'change_rate': '-0.97',
 'close': '5.12',
 'date': '2020-05-29',
 'max': '5.15',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.14',
 'turnover_rate': '0.05',
 'volumn': '64433',
 'volumn_hand': '1257614'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.17',
 'change': '0.05',
 'change_rate': '0.98',
 'close': '5.17',
 'date': '2020-05-28',
 'max': '5.18',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.12',
 'turnover_rate': '0.05',
 'volumn': '75133',
 'volumn_hand': '1457287'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.98',
 'change': '0.04',
 'change_rate': '0.79',
 'close': '5.12',
 'date': '2020-05-27',
 'max': '5.13',
 'min': '5.08',
 'name': '工商银行',
 'open': '5.08',
 'turnover_rate': '0.04',
 'volumn': '61169',
 'volumn_hand': '1195940'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '5.08',
 'date': '2020-05-26',
 'max': '5.11',
 'min': '5.08',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.03',
 'volumn': '47120',
 'volumn_hand': '925221'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-26' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.97',
 'change': '-0.03',
 'change_rate': '-0.58',
 'close': '5.10',
 'date': '2020-07-21',
 'max': '5.14',
 'min': '5.09',
 'name': '工商银行',
 'open': '5.13',
 'turnover_rate': '0.08',
 'volumn': '115445',
 'volumn_hand': '2262538'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.78',
 'change': '0.07',
 'change_rate': '1.38',
 'close': '5.13',
 'date': '2020-07-20',
 'max': '5.14',
 'min': '5.05',
 'name': '工商银行',
 'open': '5.07',
 'turnover_rate': '0.14',
 'volumn': '197450',
 'volumn_hand': '3865924'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.99',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.06',
 'date': '2020-07-17',
 'max': '5.08',
 'min': '5.03',
 'name': '工商银行',
 'open': '5.06',
 'turnover_rate': '0.11',
 'volumn': '150416',
 'volumn_hand': '2975298'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.57',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.06',
 'date': '2020-07-16',
 'max': '5.13',
 'min': '5.05',
 'name': '工商银行',
 'open': '5.08',
 'turnover_rate': '0.18',
 'volumn': '250598',
 'volumn_hand': '4922858'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.14',
 'change': '-0.06',
 'change_rate': '-1.17',
 'close': '5.08',
 'date': '2020-07-15',
 'max': '5.18',
 'min': '5.07',
 'name': '工商银行',
 'open': '5.16',
 'turnover_rate': '0.17',
 'volumn': '235502',
 'volumn_hand': '4611494'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.34',
 'change': '-0.07',
 'change_rate': '-1.34',
 'close': '5.14',
 'date': '2020-07-14',
 'max': '5.20',
 'min': '5.13',
 'name': '工商银行',
 'open': '5.19',
 'turnover_rate': '0.17',
 'volumn': '239744',
 'volumn_hand': '4639221'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.72',
 'change': '-0.01',
 'change_rate': '-0.19',
 'close': '5.21',
 'date': '2020-07-13',
 'max': '5.25',
 'min': '5.16',
 'name': '工商银行',
 'open': '5.20',
 'turnover_rate': '0.23',
 'volumn': '316753',
 'volumn_hand': '6089284'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.16',
 'change': '-0.16',
 'change_rate': '-2.97',
 'close': '5.22',
 'date': '2020-07-10',
 'max': '5.37',
 'min': '5.20',
 'name': '工商银行',
 'open': '5.36',
 'turnover_rate': '0.23',
 'volumn': '330259',
 'volumn_hand': '6260793'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.83',
 'change': '-0.09',
 'change_rate': '-1.65',
 'close': '5.38',
 'date': '2020-07-09',
 'max': '5.45',
 'min': '5.35',
 'name': '工商银行',
 'open': '5.43',
 'turnover_rate': '0.21',
 'volumn': '306447',
 'volumn_hand': '5693420'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.03',
 'change': '0.02',
 'change_rate': '0.34',
 'close': '5.84',
 'date': '2020-01-20',
 'max': '5.86',
 'min': '5.80',
 'name': '工商银行',
 'open': '5.81',
 'turnover_rate': '0.04',
 'volumn': '60279',
 'volumn_hand': '1033400'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.69',
 'change': '0.02',
 'change_rate': '0.34',
 'close': '5.82',
 'date': '2020-01-17',
 'max': '5.84',
 'min': '5.80',
 'name': '工商银行',
 'open': '5.81',
 'turnover_rate': '0.04',
 'volumn': '60508',
 'volumn_hand': '1039490'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.70',
 'change': '-0.08',
 'change_rate': '-1.36',
 'close': '5.80',
 'date': '2020-01-16',
 'max': '5.89',
 'min': '5.79',
 'name': '工商银行',
 'open': '5.87',
 'turnover_rate': '0.10',
 'volumn': '157201',
 'volumn_hand': '2690314'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.18',
 'change': '-0.06',
 'change_rate': '-1.01',
 'close': '5.88',
 'date': '2020-01-15',
 'max': '5.94',
 'min': '5.87',
 'name': '工商银行',
 'open': '5.93',
 'turnover_rate': '0.05',
 'volumn': '75951',
 'volumn_hand': '1288908'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.84',
 'change': '0.01',
 'change_rate': '0.17',
 'close': '5.94',
 'date': '2020-01-14',
 'max': '5.96',
 'min': '5.91',
 'name': '工商银行',
 'open': '5.92',
 'turnover_rate': '0.05',
 'volumn': '81239',
 'volumn_hand': '1367701'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.02',
 'change': '0.02',
 'change_rate': '0.34',
 'close': '5.93',
 'date': '2020-01-13',
 'max': '5.93',
 'min': '5.87',
 'name': '工商银行',
 'open': '5.90',
 'turnover_rate': '0.04',
 'volumn': '64279',
 'volumn_hand': '1089910'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.18',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.91',
 'date': '2020-01-10',
 'max': '5.93',
 'min': '5.86',
 'name': '工商银行',
 'open': '5.91',
 'turnover_rate': '0.04',
 'volumn': '57658',
 'volumn_hand': '978378'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.35',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.91',
 'date': '2020-01-09',
 'max': '5.96',
 'min': '5.88',
 'name': '工商银行',
 'open': '5.95',
 'turnover_rate': '0.05',
 'volumn': '81381',
 'volumn_hand': '1377134'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.16',
 'change': '-0.10',
 'change_rate': '-1.66',
 'close': '5.91',
 'date': '2020-01-08',
 'max': '5.97',
 'min': '5.90',
 'name': '工商银行',
 'open': '5.96',
 'turnover_rate': '0.06',
 'volumn': '94055',
 'volumn_hand': '1585591'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.19',
 'change': '0.04',
 'change_rate': '0.79',
 'close': '5.09',
 'date': '2020-05-25',
 'max': '5.10',
 'min': '5.04',
 'name': '工商银行',
 'open': '5.06',
 'turnover_rate': '0.04',
 'volumn': '53541',
 'volumn_hand': '1055065'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-25' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.18',
 'change': '-0.05',
 'change_rate': '-0.98',
 'close': '5.05',
 'date': '2020-05-22',
 'max': '5.11',
 'min': '5.05',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.05',
 'volumn': '72786',
 'volumn_hand': '1433771'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.10',
 'date': '2020-05-21',
 'max': '5.13',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.12',
 'turnover_rate': '0.03',
 'volumn': '41449',
 'volumn_hand': '810031'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.39',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.12',
 'date': '2020-05-20',
 'max': '5.12',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.03',
 'volumn': '44333',
 'volumn_hand': '867649'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '0.02',
 'change_rate': '0.39',
 'close': '5.12',
 'date': '2020-05-19',
 'max': '5.13',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.12',
 'turnover_rate': '0.05',
 'volumn': '69626',
 'volumn_hand': '1361801'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-19' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '0.01',
 'change_rate': '0.20',
 'close': '5.10',
 'date': '2020-05-18',
 'max': '5.10',
 'min': '5.07',
 'name': '工商银行',
 'open': '5.09',
 'turnover_rate': '0.03',
 'volumn': '47619',
 'volumn_hand': '936179'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-18' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '5.09',
 'date': '2020-05-15',
 'max': '5.12',
 'min': '5.08',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.04',
 'volumn': '48846',
 'volumn_hand': '959061'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '-0.03',
 'change_rate': '-0.58',
 'close': '5.10',
 'date': '2020-05-14',
 'max': '5.13',
 'min': '5.09',
 'name': '工商银行',
 'open': '5.12',
 'turnover_rate': '0.03',
 'volumn': '41444',
 'volumn_hand': '811525'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.39',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.13',
 'date': '2020-05-13',
 'max': '5.13',
 'min': '5.11',
 'name': '工商银行',
 'open': '5.12',
 'turnover_rate': '0.02',
 'volumn': '28480',
 'volumn_hand': '556280'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.78',
 'change': '-0.09',
 'change_rate': '-1.62',
 'close': '5.47',
 'date': '2020-07-08',
 'max': '5.59',
 'min': '5.38',
 'name': '工商银行',
 'open': '5.52',
 'turnover_rate': '0.23',
 'volumn': '335735',
 'volumn_hand': '6130511'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.18',
 'change': '-0.04',
 'change_rate': '-0.71',
 'close': '5.56',
 'date': '2020-07-07',
 'max': '5.85',
 'min': '5.56',
 'name': '工商银行',
 'open': '5.67',
 'turnover_rate': '0.23',
 'volumn': '351840',
 'volumn_hand': '6224565'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '8.14',
 'change': '0.44',
 'change_rate': '8.53',
 'close': '5.60',
 'date': '2020-07-06',
 'max': '5.61',
 'min': '5.19',
 'name': '工商银行',
 'open': '5.20',
 'turnover_rate': '0.28',
 'volumn': '404417',
 'volumn_hand': '7463596'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.37',
 'change': '0.10',
 'change_rate': '1.98',
 'close': '5.16',
 'date': '2020-07-03',
 'max': '5.18',
 'min': '5.06',
 'name': '工商银行',
 'open': '5.06',
 'turnover_rate': '0.13',
 'volumn': '179128',
 'volumn_hand': '3494608'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.20',
 'change': '0.07',
 'change_rate': '1.40',
 'close': '5.06',
 'date': '2020-07-02',
 'max': '5.07',
 'min': '4.96',
 'name': '工商银行',
 'open': '4.98',
 'turnover_rate': '0.12',
 'volumn': '167285',
 'volumn_hand': '3336395'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.41',
 'change': '0.01',
 'change_rate': '0.20',
 'close': '4.99',
 'date': '2020-07-01',
 'max': '4.99',
 'min': '4.92',
 'name': '工商银行',
 'open': '4.98',
 'turnover_rate': '0.07',
 'volumn': '96808',
 'volumn_hand': '1953424'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-07-01' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.01',
 'change': '0.04',
 'change_rate': '0.67',
 'close': '6.01',
 'date': '2020-01-07',
 'max': '6.04',
 'min': '5.98',
 'name': '工商银行',
 'open': '5.98',
 'turnover_rate': '0.04',
 'volumn': '70162',
 'volumn_hand': '1168044'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.67',
 'change': '-0.02',
 'change_rate': '-0.33',
 'close': '5.97',
 'date': '2020-01-06',
 'max': '6.05',
 'min': '5.95',
 'name': '工商银行',
 'open': '5.96',
 'turnover_rate': '0.08',
 'volumn': '135992',
 'volumn_hand': '2265097'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.01',
 'change': '0.02',
 'change_rate': '0.34',
 'close': '5.99',
 'date': '2020-01-03',
 'max': '6.02',
 'min': '5.96',
 'name': '工商银行',
 'open': '5.97',
 'turnover_rate': '0.06',
 'volumn': '91195',
 'volumn_hand': '1522130'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.04',
 'change': '0.09',
 'change_rate': '1.53',
 'close': '5.97',
 'date': '2020-01-02',
 'max': '6.03',
 'min': '5.91',
 'name': '工商银行',
 'open': '5.92',
 'turnover_rate': '0.09',
 'volumn': '140444',
 'volumn_hand': '2349494'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-01-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '-0.01',
 'change_rate': '-0.19',
 'close': '5.13',
 'date': '2020-05-12',
 'max': '5.15',
 'min': '5.11',
 'name': '工商银行',
 'open': '5.13',
 'turnover_rate': '0.04',
 'volumn': '52129',
 'volumn_hand': '1016321'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-12' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '0.04',
 'change_rate': '0.78',
 'close': '5.14',
 'date': '2020-05-11',
 'max': '5.14',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.04',
 'volumn': '57942',
 'volumn_hand': '1130519'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-11' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '5.10',
 'date': '2020-05-08',
 'max': '5.12',
 'min': '5.09',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.04',
 'volumn': '58630',
 'volumn_hand': '1148278'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.39',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '5.10',
 'date': '2020-05-07',
 'max': '5.11',
 'min': '5.09',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.03',
 'volumn': '40234',
 'volumn_hand': '788982'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.77',
 'change': '-0.06',
 'change_rate': '-1.16',
 'close': '5.11',
 'date': '2020-05-06',
 'max': '5.12',
 'min': '5.08',
 'name': '工商银行',
 'open': '5.12',
 'turnover_rate': '0.06',
 'volumn': '82675',
 'volumn_hand': '1620612'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-05-06' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '0.02',
 'change_rate': '0.39',
 'close': '5.17',
 'date': '2020-04-30',
 'max': '5.18',
 'min': '5.14',
 'name': '工商银行',
 'open': '5.15',
 'turnover_rate': '0.04',
 'volumn': '53793',
 'volumn_hand': '1040639'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-30' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.37',
 'change': '0.04',
 'change_rate': '0.78',
 'close': '5.15',
 'date': '2020-04-29',
 'max': '5.15',
 'min': '5.08',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.04',
 'volumn': '62118',
 'volumn_hand': '1210796'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-29' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.57',
 'change': '0.02',
 'change_rate': '0.39',
 'close': '5.11',
 'date': '2020-04-28',
 'max': '5.12',
 'min': '5.04',
 'name': '工商银行',
 'open': '5.09',
 'turnover_rate': '0.06',
 'volumn': '76631',
 'volumn_hand': '1505136'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-28' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.19',
 'change': '0.04',
 'change_rate': '0.79',
 'close': '5.09',
 'date': '2020-04-27',
 'max': '5.11',
 'min': '5.05',
 'name': '工商银行',
 'open': '5.05',
 'turnover_rate': '0.04',
 'volumn': '59698',
 'volumn_hand': '1172997'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-27' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.05',
 'date': '2020-04-24',
 'max': '5.07',
 'min': '5.04',
 'name': '工商银行',
 'open': '5.06',
 'turnover_rate': '0.03',
 'volumn': '34760',
 'volumn_hand': '687952'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-24' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.79',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.07',
 'date': '2020-04-23',
 'max': '5.09',
 'min': '5.05',
 'name': '工商银行',
 'open': '5.09',
 'turnover_rate': '0.04',
 'volumn': '52378',
 'volumn_hand': '1033422'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-23' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.98',
 'change': '0.01',
 'change_rate': '0.20',
 'close': '5.09',
 'date': '2020-04-22',
 'max': '5.10',
 'min': '5.05',
 'name': '工商银行',
 'open': '5.07',
 'turnover_rate': '0.03',
 'volumn': '44511',
 'volumn_hand': '876584'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-22' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.98',
 'change': '-0.04',
 'change_rate': '-0.78',
 'close': '5.08',
 'date': '2020-04-21',
 'max': '5.12',
 'min': '5.07',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.04',
 'volumn': '59829',
 'volumn_hand': '1176049'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-21' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.58',
 'change': '-0.03',
 'change_rate': '-0.58',
 'close': '5.12',
 'date': '2020-04-20',
 'max': '5.15',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.14',
 'turnover_rate': '0.04',
 'volumn': '53209',
 'volumn_hand': '1038087'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-20' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.17',
 'change': '0.03',
 'change_rate': '0.59',
 'close': '5.15',
 'date': '2020-04-17',
 'max': '5.17',
 'min': '5.11',
 'name': '工商银行',
 'open': '5.13',
 'turnover_rate': '0.05',
 'volumn': '71082',
 'volumn_hand': '1382449'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-17' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.58',
 'change': '-0.01',
 'change_rate': '-0.19',
 'close': '5.12',
 'date': '2020-04-16',
 'max': '5.13',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.03',
 'volumn': '35839',
 'volumn_hand': '700632'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-16' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '0.01',
 'change_rate': '0.20',
 'close': '5.13',
 'date': '2020-04-15',
 'max': '5.13',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.04',
 'volumn': '48441',
 'volumn_hand': '946035'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-15' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.59',
 'change': '0.02',
 'change_rate': '0.39',
 'close': '5.12',
 'date': '2020-04-14',
 'max': '5.13',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.11',
 'turnover_rate': '0.03',
 'volumn': '45193',
 'volumn_hand': '883218'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-14' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '-0.01',
 'change_rate': '-0.20',
 'close': '5.10',
 'date': '2020-04-13',
 'max': '5.13',
 'min': '5.09',
 'name': '工商银行',
 'open': '5.10',
 'turnover_rate': '0.03',
 'volumn': '43641',
 'volumn_hand': '855087'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-13' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.78',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.11',
 'date': '2020-04-10',
 'max': '5.14',
 'min': '5.10',
 'name': '工商银行',
 'open': '5.13',
 'turnover_rate': '0.04',
 'volumn': '50048',
 'volumn_hand': '978069'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-10' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.58',
 'change': '-0.01',
 'change_rate': '-0.19',
 'close': '5.13',
 'date': '2020-04-09',
 'max': '5.15',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.14',
 'turnover_rate': '0.03',
 'volumn': '37779',
 'volumn_hand': '735821'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-09' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '0.58',
 'change': '-0.02',
 'change_rate': '-0.39',
 'close': '5.14',
 'date': '2020-04-08',
 'max': '5.15',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.14',
 'turnover_rate': '0.04',
 'volumn': '53102',
 'volumn_hand': '1034743'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-08' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.17',
 'change': '0.02',
 'change_rate': '0.39',
 'close': '5.16',
 'date': '2020-04-07',
 'max': '5.19',
 'min': '5.13',
 'name': '工商银行',
 'open': '5.18',
 'turnover_rate': '0.06',
 'volumn': '87802',
 'volumn_hand': '1703016'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-07' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.16',
 'change': '-0.05',
 'change_rate': '-0.96',
 'close': '5.14',
 'date': '2020-04-03',
 'max': '5.18',
 'min': '5.12',
 'name': '工商银行',
 'open': '5.16',
 'turnover_rate': '0.04',
 'volumn': '56412',
 'volumn_hand': '1096046'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-03' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.55',
 'change': '0.03',
 'change_rate': '0.58',
 'close': '5.19',
 'date': '2020-04-02',
 'max': '5.19',
 'min': '5.11',
 'name': '工商银行',
 'open': '5.14',
 'turnover_rate': '0.05',
 'volumn': '63237',
 'volumn_hand': '1228856'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-02' for key 'uk_t_1'")
2020-08-02 22:59:09 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.17',
 'change': '0.01',
 'change_rate': '0.19',
 'close': '5.16',
 'date': '2020-04-01',
 'max': '5.19',
 'min': '5.13',
 'name': '工商银行',
 'open': '5.15',
 'turnover_rate': '0.04',
 'volumn': '52562',
 'volumn_hand': '1018584'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '工商银行-2020-04-01' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=0&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=0&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=2&season=3 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=0&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=2&season=1 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=2&season=4 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=2&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.money.163.com/trade/lsjysj_002594.html?year=0&season=2 via http://localhost:8050/execute> (referer: None)
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.76',
 'change': '0.39',
 'change_rate': '0.46',
 'close': '85.39',
 'date': '2020-07-31',
 'max': '86.66',
 'min': '83.46',
 'name': '比亚迪',
 'open': '84.96',
 'turnover_rate': '1.42',
 'volumn': '220196',
 'volumn_hand': '258123'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-31' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.83',
 'change': '-1.93',
 'change_rate': '-2.22',
 'close': '85.00',
 'date': '2020-07-30',
 'max': '87.63',
 'min': '84.30',
 'name': '比亚迪',
 'open': '87.02',
 'turnover_rate': '1.24',
 'volumn': '191785',
 'volumn_hand': '224493'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-30' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.93',
 'change': '3.02',
 'change_rate': '3.60',
 'close': '86.93',
 'date': '2020-07-29',
 'max': '87.50',
 'min': '82.52',
 'name': '比亚迪',
 'open': '83.31',
 'turnover_rate': '1.59',
 'volumn': '246489',
 'volumn_hand': '287976'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-29' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.38',
 'change': '0.39',
 'change_rate': '0.47',
 'close': '83.91',
 'date': '2020-07-28',
 'max': '86.66',
 'min': '83.00',
 'name': '比亚迪',
 'open': '85.98',
 'turnover_rate': '1.19',
 'volumn': '182941',
 'volumn_hand': '216441'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-28' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.49',
 'change': '0.52',
 'change_rate': '0.63',
 'close': '83.52',
 'date': '2020-07-27',
 'max': '85.20',
 'min': '82.30',
 'name': '比亚迪',
 'open': '83.50',
 'turnover_rate': '1.15',
 'volumn': '175328',
 'volumn_hand': '208828'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-27' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.34',
 'change': '-5.99',
 'change_rate': '-6.73',
 'close': '83.00',
 'date': '2020-07-24',
 'max': '88.14',
 'min': '82.50',
 'name': '比亚迪',
 'open': '87.78',
 'turnover_rate': '2.14',
 'volumn': '329803',
 'volumn_hand': '388174'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-24' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.92',
 'change': '1.80',
 'change_rate': '2.06',
 'close': '88.99',
 'date': '2020-07-23',
 'max': '89.00',
 'min': '85.58',
 'name': '比亚迪',
 'open': '86.06',
 'turnover_rate': '1.81',
 'volumn': '286984',
 'volumn_hand': '327287'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-23' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.52',
 'change': '-0.90',
 'change_rate': '-1.02',
 'close': '87.19',
 'date': '2020-07-22',
 'max': '89.48',
 'min': '85.50',
 'name': '比亚迪',
 'open': '86.00',
 'turnover_rate': '1.49',
 'volumn': '236799',
 'volumn_hand': '269545'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-22' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.19',
 'change': '0.92',
 'change_rate': '1.06',
 'close': '88.09',
 'date': '2020-07-21',
 'max': '91.33',
 'min': '87.68',
 'name': '比亚迪',
 'open': '89.90',
 'turnover_rate': '1.75',
 'volumn': '283438',
 'volumn_hand': '317222'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-21' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '9.43',
 'change': '5.58',
 'change_rate': '6.84',
 'close': '87.17',
 'date': '2020-07-20',
 'max': '89.30',
 'min': '81.61',
 'name': '比亚迪',
 'open': '83.70',
 'turnover_rate': '2.38',
 'volumn': '368454',
 'volumn_hand': '431730'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-20' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.22',
 'change': '-3.46',
 'change_rate': '-4.07',
 'close': '81.59',
 'date': '2020-07-17',
 'max': '85.36',
 'min': '80.07',
 'name': '比亚迪',
 'open': '83.02',
 'turnover_rate': '2.38',
 'volumn': '354910',
 'volumn_hand': '430969'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-17' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '11.06',
 'change': '-9.45',
 'change_rate': '-10.00',
 'close': '85.05',
 'date': '2020-07-16',
 'max': '95.50',
 'min': '85.05',
 'name': '比亚迪',
 'open': '94.40',
 'turnover_rate': '3.09',
 'volumn': '498454',
 'volumn_hand': '560467'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-16' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.76',
 'change': '-2.05',
 'change_rate': '-2.12',
 'close': '94.50',
 'date': '2020-07-15',
 'max': '97.29',
 'min': '92.69',
 'name': '比亚迪',
 'open': '97.00',
 'turnover_rate': '2.14',
 'volumn': '369903',
 'volumn_hand': '388696'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-15' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.49',
 'change': '-1.35',
 'change_rate': '-1.38',
 'close': '96.55',
 'date': '2020-07-14',
 'max': '97.91',
 'min': '90.58',
 'name': '比亚迪',
 'open': '97.90',
 'turnover_rate': '2.96',
 'volumn': '507582',
 'volumn_hand': '536389'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-14' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.30',
 'change': '8.90',
 'change_rate': '10.00',
 'close': '97.90',
 'date': '2020-07-13',
 'max': '97.90',
 'min': '92.29',
 'name': '比亚迪',
 'open': '92.60',
 'turnover_rate': '3.20',
 'volumn': '553651',
 'volumn_hand': '579871'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-13' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '11.02',
 'change': '4.54',
 'change_rate': '5.38',
 'close': '89.00',
 'date': '2020-07-10',
 'max': '92.36',
 'min': '83.05',
 'name': '比亚迪',
 'open': '84.47',
 'turnover_rate': '2.18',
 'volumn': '349516',
 'volumn_hand': '396029'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-10' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.85',
 'change': '1.71',
 'change_rate': '2.07',
 'close': '84.46',
 'date': '2020-07-09',
 'max': '86.30',
 'min': '81.46',
 'name': '比亚迪',
 'open': '82.75',
 'turnover_rate': '1.81',
 'volumn': '276411',
 'volumn_hand': '327974'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-09' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.92',
 'change': '-0.25',
 'change_rate': '-0.30',
 'close': '82.75',
 'date': '2020-07-08',
 'max': '84.28',
 'min': '81.86',
 'name': '比亚迪',
 'open': '81.94',
 'turnover_rate': '1.76',
 'volumn': '264776',
 'volumn_hand': '319156'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-08' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.80',
 'change': '2.10',
 'change_rate': '2.60',
 'close': '83.00',
 'date': '2020-07-07',
 'max': '88.50',
 'min': '83.00',
 'name': '比亚迪',
 'open': '84.76',
 'turnover_rate': '2.57',
 'volumn': '397864',
 'volumn_hand': '466706'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-07' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.27',
 'change': '1.55',
 'change_rate': '1.95',
 'close': '80.90',
 'date': '2020-07-06',
 'max': '81.59',
 'min': '77.41',
 'name': '比亚迪',
 'open': '79.33',
 'turnover_rate': '2.54',
 'volumn': '366152',
 'volumn_hand': '461224'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-06' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '8.48',
 'change': '7.21',
 'change_rate': '9.99',
 'close': '79.35',
 'date': '2020-07-03',
 'max': '79.35',
 'min': '73.23',
 'name': '比亚迪',
 'open': '73.30',
 'turnover_rate': '2.51',
 'volumn': '349772',
 'volumn_hand': '455388'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-03' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.88',
 'change': '-0.33',
 'change_rate': '-0.46',
 'close': '72.14',
 'date': '2020-07-02',
 'max': '74.61',
 'min': '71.80',
 'name': '比亚迪',
 'open': '72.63',
 'turnover_rate': '1.18',
 'volumn': '155973',
 'volumn_hand': '214074'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-02' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.16',
 'change': '0.67',
 'change_rate': '0.93',
 'close': '72.47',
 'date': '2020-07-01',
 'max': '75.45',
 'min': '71.03',
 'name': '比亚迪',
 'open': '73.21',
 'turnover_rate': '1.30',
 'volumn': '172622',
 'volumn_hand': '235093'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-07-01' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '8.07',
 'change': '3.74',
 'change_rate': '6.65',
 'close': '59.97',
 'date': '2020-03-31',
 'max': '59.99',
 'min': '55.45',
 'name': '比亚迪',
 'open': '56.76',
 'turnover_rate': '1.93',
 'volumn': '203707',
 'volumn_hand': '350174'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-31' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.31',
 'change': '1.45',
 'change_rate': '2.65',
 'close': '56.23',
 'date': '2020-03-30',
 'max': '57.78',
 'min': '54.87',
 'name': '比亚迪',
 'open': '55.00',
 'turnover_rate': '1.81',
 'volumn': '185591',
 'volumn_hand': '328937'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-30' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.97',
 'change': '0.51',
 'change_rate': '0.94',
 'close': '54.78',
 'date': '2020-03-27',
 'max': '56.05',
 'min': '54.44',
 'name': '比亚迪',
 'open': '55.40',
 'turnover_rate': '1.27',
 'volumn': '126953',
 'volumn_hand': '229972'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-27' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.83',
 'change': '2.02',
 'change_rate': '3.87',
 'close': '54.27',
 'date': '2020-03-26',
 'max': '55.18',
 'min': '51.61',
 'name': '比亚迪',
 'open': '52.50',
 'turnover_rate': '1.64',
 'volumn': '158850',
 'volumn_hand': '296621'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-26' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.54',
 'change': '2.52',
 'change_rate': '5.07',
 'close': '52.25',
 'date': '2020-03-25',
 'max': '52.80',
 'min': '51.04',
 'name': '比亚迪',
 'open': '51.55',
 'turnover_rate': '1.60',
 'volumn': '150480',
 'volumn_hand': '289787'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-25' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.17',
 'change': '1.58',
 'change_rate': '3.28',
 'close': '49.73',
 'date': '2020-03-24',
 'max': '49.88',
 'min': '47.39',
 'name': '比亚迪',
 'open': '49.26',
 'turnover_rate': '1.13',
 'volumn': '100213',
 'volumn_hand': '205027'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-24' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.80',
 'change': '1.20',
 'change_rate': '1.70',
 'close': '71.80',
 'date': '2020-06-30',
 'max': '72.85',
 'min': '70.87',
 'name': '比亚迪',
 'open': '71.41',
 'turnover_rate': '0.94',
 'volumn': '122321',
 'volumn_hand': '169831'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-30' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.97',
 'change': '-1.10',
 'change_rate': '-1.53',
 'close': '70.60',
 'date': '2020-06-29',
 'max': '72.43',
 'min': '70.30',
 'name': '比亚迪',
 'open': '71.50',
 'turnover_rate': '0.96',
 'volumn': '123331',
 'volumn_hand': '173376'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-29' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.24',
 'change': '0.67',
 'change_rate': '0.94',
 'close': '71.70',
 'date': '2020-06-24',
 'max': '73.06',
 'min': '70.76',
 'name': '比亚迪',
 'open': '71.10',
 'turnover_rate': '1.08',
 'volumn': '141443',
 'volumn_hand': '196681'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-24' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.49',
 'change': '3.03',
 'change_rate': '4.46',
 'close': '71.03',
 'date': '2020-06-23',
 'max': '72.09',
 'min': '67.00',
 'name': '比亚迪',
 'open': '67.57',
 'turnover_rate': '1.44',
 'volumn': '181261',
 'volumn_hand': '260375'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-23' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.72',
 'change': '1.01',
 'change_rate': '1.51',
 'close': '68.00',
 'date': '2020-06-22',
 'max': '68.78',
 'min': '66.29',
 'name': '比亚迪',
 'open': '66.60',
 'turnover_rate': '1.08',
 'volumn': '132581',
 'volumn_hand': '196255'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-22' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.57',
 'change': '0.25',
 'change_rate': '0.37',
 'close': '66.99',
 'date': '2020-06-19',
 'max': '68.68',
 'min': '66.30',
 'name': '比亚迪',
 'open': '66.69',
 'turnover_rate': '1.22',
 'volumn': '148725',
 'volumn_hand': '220619'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-19' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.96',
 'change': '2.63',
 'change_rate': '4.10',
 'close': '66.74',
 'date': '2020-06-18',
 'max': '66.76',
 'min': '62.94',
 'name': '比亚迪',
 'open': '63.80',
 'turnover_rate': '1.54',
 'volumn': '182990',
 'volumn_hand': '279033'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-18' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.73',
 'change': '0.01',
 'change_rate': '0.02',
 'close': '64.11',
 'date': '2020-06-17',
 'max': '64.11',
 'min': '62.36',
 'name': '比亚迪',
 'open': '64.00',
 'turnover_rate': '0.80',
 'volumn': '91207',
 'volumn_hand': '144378'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-17' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.54',
 'change': '-4.37',
 'change_rate': '-8.32',
 'close': '48.15',
 'date': '2020-03-23',
 'max': '50.80',
 'min': '47.89',
 'name': '比亚迪',
 'open': '50.25',
 'turnover_rate': '1.34',
 'volumn': '119054',
 'volumn_hand': '242740'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-23' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.71',
 'change': '1.16',
 'change_rate': '2.26',
 'close': '52.52',
 'date': '2020-03-20',
 'max': '52.79',
 'min': '51.40',
 'name': '比亚迪',
 'open': '52.30',
 'turnover_rate': '0.82',
 'volumn': '77292',
 'volumn_hand': '148296'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-20' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.07',
 'change': '-0.73',
 'change_rate': '-1.40',
 'close': '51.36',
 'date': '2020-03-19',
 'max': '52.52',
 'min': '49.88',
 'name': '比亚迪',
 'open': '52.11',
 'turnover_rate': '1.07',
 'volumn': '99368',
 'volumn_hand': '194450'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-19' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.00',
 'change': '-0.95',
 'change_rate': '-1.79',
 'close': '52.09',
 'date': '2020-03-18',
 'max': '54.67',
 'min': '52.02',
 'name': '比亚迪',
 'open': '53.59',
 'turnover_rate': '0.95',
 'volumn': '92570',
 'volumn_hand': '172684'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-18' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.72',
 'change': '-0.84',
 'change_rate': '-1.56',
 'close': '53.04',
 'date': '2020-03-17',
 'max': '54.96',
 'min': '51.88',
 'name': '比亚迪',
 'open': '53.88',
 'turnover_rate': '1.00',
 'volumn': '96159',
 'volumn_hand': '180919'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-17' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.20',
 'change': '-1.78',
 'change_rate': '-3.20',
 'close': '53.88',
 'date': '2020-03-16',
 'max': '57.33',
 'min': '53.88',
 'name': '比亚迪',
 'open': '56.59',
 'turnover_rate': '1.32',
 'volumn': '132636',
 'volumn_hand': '238773'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-16' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.28',
 'change': '-1.37',
 'change_rate': '-2.40',
 'close': '55.66',
 'date': '2020-03-13',
 'max': '56.50',
 'min': '52.35',
 'name': '比亚迪',
 'open': '53.80',
 'turnover_rate': '1.18',
 'volumn': '116229',
 'volumn_hand': '213198'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-13' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.00',
 'change': '-1.72',
 'change_rate': '-2.93',
 'close': '57.03',
 'date': '2020-03-12',
 'max': '57.66',
 'min': '55.90',
 'name': '比亚迪',
 'open': '57.31',
 'turnover_rate': '1.28',
 'volumn': '131905',
 'volumn_hand': '232383'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-12' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.24',
 'change': '-1.42',
 'change_rate': '-2.36',
 'close': '58.75',
 'date': '2020-03-11',
 'max': '61.15',
 'min': '58.60',
 'name': '比亚迪',
 'open': '60.77',
 'turnover_rate': '1.23',
 'volumn': '132780',
 'volumn_hand': '222212'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-11' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.01',
 'change': '0.72',
 'change_rate': '1.21',
 'close': '60.17',
 'date': '2020-03-10',
 'max': '61.50',
 'min': '57.33',
 'name': '比亚迪',
 'open': '57.60',
 'turnover_rate': '1.47',
 'volumn': '157809',
 'volumn_hand': '266805'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-10' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.29',
 'change': '-5.91',
 'change_rate': '-9.04',
 'close': '59.45',
 'date': '2020-03-09',
 'max': '63.29',
 'min': '59.18',
 'name': '比亚迪',
 'open': '63.29',
 'turnover_rate': '1.61',
 'volumn': '178914',
 'volumn_hand': '292479'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-09' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.13',
 'change': '1.60',
 'change_rate': '2.56',
 'close': '64.10',
 'date': '2020-06-16',
 'max': '64.46',
 'min': '63.13',
 'name': '比亚迪',
 'open': '63.80',
 'turnover_rate': '1.18',
 'volumn': '136778',
 'volumn_hand': '214116'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-16' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.28',
 'change': '1.02',
 'change_rate': '1.66',
 'close': '62.50',
 'date': '2020-06-15',
 'max': '63.88',
 'min': '61.25',
 'name': '比亚迪',
 'open': '62.50',
 'turnover_rate': '1.08',
 'volumn': '122543',
 'volumn_hand': '195740'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-15' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.07',
 'change': '-1.36',
 'change_rate': '-2.16',
 'close': '61.48',
 'date': '2020-06-12',
 'max': '61.93',
 'min': '60.63',
 'name': '比亚迪',
 'open': '61.40',
 'turnover_rate': '0.97',
 'volumn': '107589',
 'volumn_hand': '175497'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-12' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.41',
 'change': '1.79',
 'change_rate': '2.93',
 'close': '62.84',
 'date': '2020-06-11',
 'max': '64.20',
 'min': '61.51',
 'name': '比亚迪',
 'open': '61.87',
 'turnover_rate': '1.55',
 'volumn': '176468',
 'volumn_hand': '280233'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-11' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.81',
 'change': '-0.93',
 'change_rate': '-1.50',
 'close': '61.05',
 'date': '2020-06-10',
 'max': '62.42',
 'min': '60.68',
 'name': '比亚迪',
 'open': '62.26',
 'turnover_rate': '1.03',
 'volumn': '114063',
 'volumn_hand': '186194'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-10' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.33',
 'change': '-0.81',
 'change_rate': '-1.29',
 'close': '61.98',
 'date': '2020-06-09',
 'max': '64.41',
 'min': '61.69',
 'name': '比亚迪',
 'open': '63.00',
 'turnover_rate': '1.13',
 'volumn': '128554',
 'volumn_hand': '204431'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-09' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.18',
 'change': '-0.41',
 'change_rate': '-0.65',
 'close': '62.79',
 'date': '2020-06-08',
 'max': '63.83',
 'min': '62.45',
 'name': '比亚迪',
 'open': '63.00',
 'turnover_rate': '0.95',
 'volumn': '108701',
 'volumn_hand': '172441'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-08' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.91',
 'change': '3.09',
 'change_rate': '5.14',
 'close': '63.20',
 'date': '2020-06-05',
 'max': '63.28',
 'min': '60.33',
 'name': '比亚迪',
 'open': '61.00',
 'turnover_rate': '1.46',
 'volumn': '164386',
 'volumn_hand': '265451'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-05' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.49',
 'change': '0.18',
 'change_rate': '0.30',
 'close': '60.11',
 'date': '2020-06-04',
 'max': '61.20',
 'min': '59.71',
 'name': '比亚迪',
 'open': '60.48',
 'turnover_rate': '0.58',
 'volumn': '63780',
 'volumn_hand': '105743'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-04' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.57',
 'change': '-1.07',
 'change_rate': '-1.75',
 'close': '59.93',
 'date': '2020-06-03',
 'max': '61.05',
 'min': '59.48',
 'name': '比亚迪',
 'open': '60.79',
 'turnover_rate': '0.81',
 'volumn': '88260',
 'volumn_hand': '146357'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-03' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.56',
 'change': '1.67',
 'change_rate': '2.81',
 'close': '61.00',
 'date': '2020-06-02',
 'max': '62.18',
 'min': '58.88',
 'name': '比亚迪',
 'open': '59.57',
 'turnover_rate': '1.13',
 'volumn': '123551',
 'volumn_hand': '204796'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-02' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.32',
 'change': '-1.45',
 'change_rate': '-2.17',
 'close': '65.36',
 'date': '2020-03-06',
 'max': '67.55',
 'min': '65.33',
 'name': '比亚迪',
 'open': '65.50',
 'turnover_rate': '0.81',
 'volumn': '97261',
 'volumn_hand': '147210'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-06' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.18',
 'change': '0.23',
 'change_rate': '0.35',
 'close': '66.81',
 'date': '2020-03-05',
 'max': '67.62',
 'min': '65.50',
 'name': '比亚迪',
 'open': '67.02',
 'turnover_rate': '0.94',
 'volumn': '112829',
 'volumn_hand': '170004'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-05' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.54',
 'change': '-1.29',
 'change_rate': '-1.90',
 'close': '66.58',
 'date': '2020-03-04',
 'max': '67.80',
 'min': '64.72',
 'name': '比亚迪',
 'open': '66.95',
 'turnover_rate': '1.00',
 'volumn': '119853',
 'volumn_hand': '180933'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-04' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.10',
 'change': '1.02',
 'change_rate': '1.53',
 'close': '67.87',
 'date': '2020-03-03',
 'max': '70.20',
 'min': '67.46',
 'name': '比亚迪',
 'open': '69.80',
 'turnover_rate': '1.51',
 'volumn': '188075',
 'volumn_hand': '274253'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-03' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.94',
 'change': '1.48',
 'change_rate': '2.26',
 'close': '66.85',
 'date': '2020-03-02',
 'max': '67.23',
 'min': '64.00',
 'name': '比亚迪',
 'open': '65.60',
 'turnover_rate': '1.24',
 'volumn': '149211',
 'volumn_hand': '225643'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-03-02' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.77',
 'change': '-4.68',
 'change_rate': '-6.68',
 'close': '65.37',
 'date': '2020-02-28',
 'max': '68.99',
 'min': '64.95',
 'name': '比亚迪',
 'open': '66.66',
 'turnover_rate': '1.87',
 'volumn': '225195',
 'volumn_hand': '338254'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-28' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.07',
 'change': '-1.65',
 'change_rate': '-2.30',
 'close': '70.05',
 'date': '2020-02-27',
 'max': '73.15',
 'min': '68.08',
 'name': '比亚迪',
 'open': '71.68',
 'turnover_rate': '1.50',
 'volumn': '191269',
 'volumn_hand': '272700'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-27' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '9.60',
 'change': '0.85',
 'change_rate': '1.20',
 'close': '71.70',
 'date': '2020-02-26',
 'max': '75.80',
 'min': '69.00',
 'name': '比亚迪',
 'open': '69.78',
 'turnover_rate': '2.88',
 'volumn': '377451',
 'volumn_hand': '522768'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-26' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '12.11',
 'change': '4.65',
 'change_rate': '7.02',
 'close': '70.85',
 'date': '2020-02-25',
 'max': '72.19',
 'min': '64.17',
 'name': '比亚迪',
 'open': '64.40',
 'turnover_rate': '2.25',
 'volumn': '278664',
 'volumn_hand': '407434'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-25' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.23',
 'change': '-1.30',
 'change_rate': '-1.93',
 'close': '66.20',
 'date': '2020-02-24',
 'max': '67.14',
 'min': '64.96',
 'name': '比亚迪',
 'open': '65.42',
 'turnover_rate': '1.97',
 'volumn': '235174',
 'volumn_hand': '357969'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-24' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.80',
 'change': '-0.60',
 'change_rate': '-0.88',
 'close': '67.50',
 'date': '2020-02-21',
 'max': '68.27',
 'min': '65.68',
 'name': '比亚迪',
 'open': '67.00',
 'turnover_rate': '2.51',
 'volumn': '304619',
 'volumn_hand': '455189'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-21' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.92',
 'change': '1.92',
 'change_rate': '3.34',
 'close': '59.33',
 'date': '2020-06-01',
 'max': '59.69',
 'min': '57.44',
 'name': '比亚迪',
 'open': '57.75',
 'turnover_rate': '0.89',
 'volumn': '94998',
 'volumn_hand': '161068'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-06-01' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.11',
 'change': '-0.07',
 'change_rate': '-0.12',
 'close': '57.41',
 'date': '2020-05-29',
 'max': '58.02',
 'min': '56.81',
 'name': '比亚迪',
 'open': '57.12',
 'turnover_rate': '0.38',
 'volumn': '39088',
 'volumn_hand': '68036'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-29' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.19',
 'change': '0.18',
 'change_rate': '0.31',
 'close': '57.48',
 'date': '2020-05-28',
 'max': '58.23',
 'min': '56.40',
 'name': '比亚迪',
 'open': '57.35',
 'turnover_rate': '0.48',
 'volumn': '49468',
 'volumn_hand': '86300'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-28' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.94',
 'change': '-1.00',
 'change_rate': '-1.72',
 'close': '57.30',
 'date': '2020-05-27',
 'max': '59.95',
 'min': '57.07',
 'name': '比亚迪',
 'open': '59.60',
 'turnover_rate': '0.63',
 'volumn': '66280',
 'volumn_hand': '113617'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-27' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.80',
 'change': '1.78',
 'change_rate': '3.15',
 'close': '58.30',
 'date': '2020-05-26',
 'max': '58.38',
 'min': '56.80',
 'name': '比亚迪',
 'open': '56.80',
 'turnover_rate': '0.54',
 'volumn': '57042',
 'volumn_hand': '98544'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-26' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.21',
 'change': '0.49',
 'change_rate': '0.87',
 'close': '56.52',
 'date': '2020-05-25',
 'max': '56.55',
 'min': '55.31',
 'name': '比亚迪',
 'open': '56.03',
 'turnover_rate': '0.33',
 'volumn': '33437',
 'volumn_hand': '59697'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-25' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.78',
 'change': '-1.12',
 'change_rate': '-1.96',
 'close': '56.03',
 'date': '2020-05-22',
 'max': '57.67',
 'min': '55.51',
 'name': '比亚迪',
 'open': '57.16',
 'turnover_rate': '0.51',
 'volumn': '52277',
 'volumn_hand': '92350'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-22' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.00',
 'change': '-1.86',
 'change_rate': '-3.15',
 'close': '57.15',
 'date': '2020-05-21',
 'max': '59.37',
 'min': '57.01',
 'name': '比亚迪',
 'open': '59.11',
 'turnover_rate': '0.67',
 'volumn': '69705',
 'volumn_hand': '120968'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-21' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.80',
 'change': '0.79',
 'change_rate': '1.36',
 'close': '59.01',
 'date': '2020-05-20',
 'max': '60.30',
 'min': '58.67',
 'name': '比亚迪',
 'open': '58.70',
 'turnover_rate': '0.91',
 'volumn': '98128',
 'volumn_hand': '164708'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-20' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.49',
 'change': '1.04',
 'change_rate': '1.82',
 'close': '58.22',
 'date': '2020-05-19',
 'max': '58.60',
 'min': '57.75',
 'name': '比亚迪',
 'open': '58.00',
 'turnover_rate': '0.52',
 'volumn': '54714',
 'volumn_hand': '94042'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-19' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.45',
 'change': '-0.78',
 'change_rate': '-1.35',
 'close': '57.18',
 'date': '2020-05-18',
 'max': '58.40',
 'min': '56.40',
 'name': '比亚迪',
 'open': '57.40',
 'turnover_rate': '0.58',
 'volumn': '60111',
 'volumn_hand': '104743'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-18' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '8.06',
 'change': '6.19',
 'change_rate': '10.00',
 'close': '68.10',
 'date': '2020-02-20',
 'max': '68.10',
 'min': '63.11',
 'name': '比亚迪',
 'open': '63.17',
 'turnover_rate': '3.58',
 'volumn': '436608',
 'volumn_hand': '649391'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-20' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.74',
 'change': '2.44',
 'change_rate': '4.10',
 'close': '61.91',
 'date': '2020-02-19',
 'max': '64.48',
 'min': '61.66',
 'name': '比亚迪',
 'open': '64.47',
 'turnover_rate': '2.41',
 'volumn': '277361',
 'volumn_hand': '437477'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-19' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.81',
 'change': '0.99',
 'change_rate': '1.69',
 'close': '59.47',
 'date': '2020-02-18',
 'max': '60.00',
 'min': '57.77',
 'name': '比亚迪',
 'open': '57.80',
 'turnover_rate': '1.26',
 'volumn': '135097',
 'volumn_hand': '228365'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-18' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.90',
 'change': '1.58',
 'change_rate': '2.78',
 'close': '58.48',
 'date': '2020-02-17',
 'max': '58.56',
 'min': '56.91',
 'name': '比亚迪',
 'open': '56.91',
 'turnover_rate': '1.16',
 'volumn': '121525',
 'volumn_hand': '209889'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-17' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.54',
 'change': '-0.65',
 'change_rate': '-1.13',
 'close': '56.90',
 'date': '2020-02-14',
 'max': '57.90',
 'min': '56.44',
 'name': '比亚迪',
 'open': '57.56',
 'turnover_rate': '1.16',
 'volumn': '120598',
 'volumn_hand': '211174'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-14' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.44',
 'change': '-1.64',
 'change_rate': '-2.77',
 'close': '57.55',
 'date': '2020-02-13',
 'max': '60.13',
 'min': '57.50',
 'name': '比亚迪',
 'open': '58.50',
 'turnover_rate': '1.31',
 'volumn': '138706',
 'volumn_hand': '236947'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-13' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.81',
 'change': '0.15',
 'change_rate': '0.25',
 'close': '59.19',
 'date': '2020-02-12',
 'max': '60.60',
 'min': '58.35',
 'name': '比亚迪',
 'open': '59.04',
 'turnover_rate': '1.09',
 'volumn': '117167',
 'volumn_hand': '197456'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-12' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.02',
 'change': '-1.89',
 'change_rate': '-3.10',
 'close': '59.04',
 'date': '2020-02-11',
 'max': '60.12',
 'min': '58.28',
 'name': '比亚迪',
 'open': '60.00',
 'turnover_rate': '1.08',
 'volumn': '116231',
 'volumn_hand': '196176'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-11' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.79',
 'change': '3.03',
 'change_rate': '5.23',
 'close': '60.93',
 'date': '2020-02-10',
 'max': '63.36',
 'min': '58.85',
 'name': '比亚迪',
 'open': '59.20',
 'turnover_rate': '1.95',
 'volumn': '214378',
 'volumn_hand': '352796'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-10' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.72',
 'change': '-2.85',
 'change_rate': '-4.69',
 'close': '57.90',
 'date': '2020-02-07',
 'max': '60.74',
 'min': '56.66',
 'name': '比亚迪',
 'open': '60.74',
 'turnover_rate': '1.77',
 'volumn': '186890',
 'volumn_hand': '321282'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-07' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.03',
 'change': '-0.06',
 'change_rate': '-0.10',
 'close': '60.75',
 'date': '2020-02-06',
 'max': '60.85',
 'min': '58.40',
 'name': '比亚迪',
 'open': '58.45',
 'turnover_rate': '1.66',
 'volumn': '179209',
 'volumn_hand': '301132'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-06' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.22',
 'change': '0.27',
 'change_rate': '0.47',
 'close': '57.96',
 'date': '2020-05-15',
 'max': '58.58',
 'min': '57.30',
 'name': '比亚迪',
 'open': '57.79',
 'turnover_rate': '0.57',
 'volumn': '59582',
 'volumn_hand': '102771'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-15' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.29',
 'change': '-1.30',
 'change_rate': '-2.20',
 'close': '57.69',
 'date': '2020-05-14',
 'max': '58.90',
 'min': '57.55',
 'name': '比亚迪',
 'open': '58.90',
 'turnover_rate': '0.65',
 'volumn': '68832',
 'volumn_hand': '118363'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-14' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.11',
 'change': '-0.14',
 'change_rate': '-0.24',
 'close': '58.99',
 'date': '2020-05-13',
 'max': '59.75',
 'min': '58.50',
 'name': '比亚迪',
 'open': '59.13',
 'turnover_rate': '0.61',
 'volumn': '65774',
 'volumn_hand': '111115'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-13' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.60',
 'change': '0.25',
 'change_rate': '0.42',
 'close': '59.13',
 'date': '2020-05-12',
 'max': '59.14',
 'min': '58.20',
 'name': '比亚迪',
 'open': '58.89',
 'turnover_rate': '0.57',
 'volumn': '61012',
 'volumn_hand': '104020'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-12' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.59',
 'change': '-0.90',
 'change_rate': '-1.51',
 'close': '58.88',
 'date': '2020-05-11',
 'max': '59.66',
 'min': '58.11',
 'name': '比亚迪',
 'open': '59.29',
 'turnover_rate': '1.05',
 'volumn': '112181',
 'volumn_hand': '190716'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-11' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.00',
 'change': '-0.31',
 'change_rate': '-0.52',
 'close': '59.78',
 'date': '2020-05-08',
 'max': '60.50',
 'min': '59.30',
 'name': '比亚迪',
 'open': '60.11',
 'turnover_rate': '0.95',
 'volumn': '102557',
 'volumn_hand': '171472'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-08' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.52',
 'change': '-2.09',
 'change_rate': '-3.36',
 'close': '60.09',
 'date': '2020-05-07',
 'max': '62.17',
 'min': '59.98',
 'name': '比亚迪',
 'open': '62.17',
 'turnover_rate': '1.24',
 'volumn': '136300',
 'volumn_hand': '225118'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-07' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.67',
 'change': '2.22',
 'change_rate': '3.70',
 'close': '62.18',
 'date': '2020-05-06',
 'max': '62.50',
 'min': '59.10',
 'name': '比亚迪',
 'open': '59.40',
 'turnover_rate': '1.28',
 'volumn': '142010',
 'volumn_hand': '231906'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-05-06' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.57',
 'change': '1.96',
 'change_rate': '3.38',
 'close': '59.96',
 'date': '2020-04-30',
 'max': '60.58',
 'min': '58.51',
 'name': '比亚迪',
 'open': '58.82',
 'turnover_rate': '1.21',
 'volumn': '130350',
 'volumn_hand': '218876'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-30' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.32',
 'change': '1.02',
 'change_rate': '1.79',
 'close': '58.00',
 'date': '2020-04-29',
 'max': '59.45',
 'min': '57.56',
 'name': '比亚迪',
 'open': '58.20',
 'turnover_rate': '0.91',
 'volumn': '96456',
 'volumn_hand': '165126'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-29' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.97',
 'change': '0.00',
 'change_rate': '0.00',
 'close': '56.98',
 'date': '2020-04-28',
 'max': '57.59',
 'min': '54.76',
 'name': '比亚迪',
 'open': '57.00',
 'turnover_rate': '0.71',
 'volumn': '72537',
 'volumn_hand': '128658'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-28' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '8.89',
 'change': '4.45',
 'change_rate': '7.90',
 'close': '60.81',
 'date': '2020-02-05',
 'max': '62.00',
 'min': '56.99',
 'name': '比亚迪',
 'open': '57.70',
 'turnover_rate': '2.46',
 'volumn': '269823',
 'volumn_hand': '446230'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-05' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.50',
 'change': '2.51',
 'change_rate': '4.66',
 'close': '56.36',
 'date': '2020-02-04',
 'max': '57.50',
 'min': '54.00',
 'name': '比亚迪',
 'open': '54.00',
 'turnover_rate': '2.03',
 'volumn': '205791',
 'volumn_hand': '367775'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-04' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.05',
 'change': '-5.98',
 'change_rate': '-10.00',
 'close': '53.85',
 'date': '2020-02-03',
 'max': '54.48',
 'min': '53.85',
 'name': '比亚迪',
 'open': '53.85',
 'turnover_rate': '0.55',
 'volumn': '54074',
 'volumn_hand': '100398'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-02-03' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.37',
 'change': '0.56',
 'change_rate': '0.94',
 'close': '59.83',
 'date': '2020-01-23',
 'max': '61.88',
 'min': '57.51',
 'name': '比亚迪',
 'open': '57.99',
 'turnover_rate': '1.61',
 'volumn': '173537',
 'volumn_hand': '291585'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-23' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '7.76',
 'change': '2.55',
 'change_rate': '4.50',
 'close': '59.27',
 'date': '2020-01-22',
 'max': '60.50',
 'min': '56.10',
 'name': '比亚迪',
 'open': '56.50',
 'turnover_rate': '1.81',
 'volumn': '192742',
 'volumn_hand': '327980'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-22' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.01',
 'change': '-2.04',
 'change_rate': '-3.47',
 'close': '56.72',
 'date': '2020-01-21',
 'max': '57.73',
 'min': '56.55',
 'name': '比亚迪',
 'open': '57.72',
 'turnover_rate': '1.12',
 'volumn': '116144',
 'volumn_hand': '203837'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-21' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.87',
 'change': '0.81',
 'change_rate': '1.40',
 'close': '58.76',
 'date': '2020-01-20',
 'max': '59.90',
 'min': '56.50',
 'name': '比亚迪',
 'open': '57.30',
 'turnover_rate': '1.66',
 'volumn': '174218',
 'volumn_hand': '300776'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-20' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '11.65',
 'change': '3.86',
 'change_rate': '7.14',
 'close': '57.95',
 'date': '2020-01-17',
 'max': '59.50',
 'min': '53.20',
 'name': '比亚迪',
 'open': '53.86',
 'turnover_rate': '2.93',
 'volumn': '302254',
 'volumn_hand': '530600'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-17' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.18',
 'change': '0.78',
 'change_rate': '1.46',
 'close': '54.09',
 'date': '2020-01-16',
 'max': '54.54',
 'min': '51.78',
 'name': '比亚迪',
 'open': '53.49',
 'turnover_rate': '1.85',
 'volumn': '177824',
 'volumn_hand': '335737'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-16' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.62',
 'change': '-0.13',
 'change_rate': '-0.24',
 'close': '53.31',
 'date': '2020-01-15',
 'max': '54.75',
 'min': '52.28',
 'name': '比亚迪',
 'open': '54.01',
 'turnover_rate': '1.65',
 'volumn': '159453',
 'volumn_hand': '298705'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-15' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '5.79',
 'change': '1.83',
 'change_rate': '3.55',
 'close': '53.44',
 'date': '2020-01-14',
 'max': '55.99',
 'min': '53.00',
 'name': '比亚迪',
 'open': '55.00',
 'turnover_rate': '3.39',
 'volumn': '335692',
 'volumn_hand': '614976'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-14' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.76',
 'change': '-1.75',
 'change_rate': '-2.98',
 'close': '56.98',
 'date': '2020-04-27',
 'max': '59.09',
 'min': '56.88',
 'name': '比亚迪',
 'open': '59.02',
 'turnover_rate': '0.76',
 'volumn': '79978',
 'volumn_hand': '138265'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-27' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.42',
 'change': '0.48',
 'change_rate': '0.82',
 'close': '58.73',
 'date': '2020-04-24',
 'max': '60.49',
 'min': '58.50',
 'name': '比亚迪',
 'open': '58.67',
 'turnover_rate': '0.75',
 'volumn': '80697',
 'volumn_hand': '135949'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-24' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.22',
 'change': '-1.18',
 'change_rate': '-1.99',
 'close': '58.25',
 'date': '2020-04-23',
 'max': '60.55',
 'min': '58.04',
 'name': '比亚迪',
 'open': '59.99',
 'turnover_rate': '0.64',
 'volumn': '68608',
 'volumn_hand': '116028'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-23' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.57',
 'change': '0.06',
 'change_rate': '0.10',
 'close': '59.43',
 'date': '2020-04-22',
 'max': '60.00',
 'min': '57.88',
 'name': '比亚迪',
 'open': '58.40',
 'turnover_rate': '0.67',
 'volumn': '71549',
 'volumn_hand': '121458'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-22' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.19',
 'change': '0.51',
 'change_rate': '0.87',
 'close': '59.37',
 'date': '2020-04-21',
 'max': '59.68',
 'min': '57.80',
 'name': '比亚迪',
 'open': '58.50',
 'turnover_rate': '0.81',
 'volumn': '86411',
 'volumn_hand': '147148'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-21' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.11',
 'change': '0.06',
 'change_rate': '0.10',
 'close': '58.86',
 'date': '2020-04-20',
 'max': '59.40',
 'min': '58.16',
 'name': '比亚迪',
 'open': '59.40',
 'turnover_rate': '0.59',
 'volumn': '63062',
 'volumn_hand': '107474'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-20' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.83',
 'change': '-1.21',
 'change_rate': '-2.02',
 'close': '58.80',
 'date': '2020-04-17',
 'max': '60.98',
 'min': '58.68',
 'name': '比亚迪',
 'open': '60.60',
 'turnover_rate': '0.86',
 'volumn': '93186',
 'volumn_hand': '156490'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-17' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.74',
 'change': '-0.13',
 'change_rate': '-0.22',
 'close': '60.01',
 'date': '2020-04-16',
 'max': '61.30',
 'min': '59.05',
 'name': '比亚迪',
 'open': '60.10',
 'turnover_rate': '0.91',
 'volumn': '99264',
 'volumn_hand': '165259'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-16' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.92',
 'change': '2.22',
 'change_rate': '3.83',
 'close': '60.14',
 'date': '2020-04-15',
 'max': '62.39',
 'min': '58.38',
 'name': '比亚迪',
 'open': '59.36',
 'turnover_rate': '1.69',
 'volumn': '184739',
 'volumn_hand': '306227'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-15' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.70',
 'change': '2.12',
 'change_rate': '3.80',
 'close': '57.92',
 'date': '2020-04-14',
 'max': '58.00',
 'min': '55.38',
 'name': '比亚迪',
 'open': '55.80',
 'turnover_rate': '1.29',
 'volumn': '133886',
 'volumn_hand': '233863'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-14' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.22',
 'change': '1.23',
 'change_rate': '2.25',
 'close': '55.80',
 'date': '2020-04-13',
 'max': '55.94',
 'min': '54.73',
 'name': '比亚迪',
 'open': '54.73',
 'turnover_rate': '0.57',
 'volumn': '56983',
 'volumn_hand': '102560'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-13' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.34',
 'change': '4.69',
 'change_rate': '10.00',
 'close': '51.61',
 'date': '2020-01-13',
 'max': '51.61',
 'min': '50.51',
 'name': '比亚迪',
 'open': '51.61',
 'turnover_rate': '2.86',
 'volumn': '266287',
 'volumn_hand': '518828'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-13' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.20',
 'change': '-0.73',
 'change_rate': '-1.53',
 'close': '46.92',
 'date': '2020-01-10',
 'max': '47.66',
 'min': '46.61',
 'name': '比亚迪',
 'open': '47.66',
 'turnover_rate': '0.60',
 'volumn': '51293',
 'volumn_hand': '109295'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-10' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.73',
 'change': '0.37',
 'change_rate': '0.78',
 'close': '47.65',
 'date': '2020-01-09',
 'max': '48.20',
 'min': '47.38',
 'name': '比亚迪',
 'open': '47.75',
 'turnover_rate': '0.49',
 'volumn': '42535',
 'volumn_hand': '89217'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-09' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.50',
 'change': '-0.77',
 'change_rate': '-1.60',
 'close': '47.28',
 'date': '2020-01-08',
 'max': '48.35',
 'min': '47.15',
 'name': '比亚迪',
 'open': '47.55',
 'turnover_rate': '0.61',
 'volumn': '52925',
 'volumn_hand': '110974'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-08' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.51',
 'change': '-0.23',
 'change_rate': '-0.48',
 'close': '48.05',
 'date': '2020-01-07',
 'max': '48.50',
 'min': '47.77',
 'name': '比亚迪',
 'open': '48.31',
 'turnover_rate': '0.52',
 'volumn': '44901',
 'volumn_hand': '93401'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-07' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '4.16',
 'change': '0.24',
 'change_rate': '0.50',
 'close': '48.28',
 'date': '2020-01-06',
 'max': '49.19',
 'min': '47.19',
 'name': '比亚迪',
 'open': '47.39',
 'turnover_rate': '0.94',
 'volumn': '82217',
 'volumn_hand': '169871'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-06' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.72',
 'change': '-0.13',
 'change_rate': '-0.27',
 'close': '48.04',
 'date': '2020-01-03',
 'max': '48.99',
 'min': '47.68',
 'name': '比亚迪',
 'open': '48.20',
 'turnover_rate': '0.72',
 'volumn': '62836',
 'volumn_hand': '129936'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-03' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.01',
 'change': '0.50',
 'change_rate': '1.05',
 'close': '48.17',
 'date': '2020-01-02',
 'max': '48.47',
 'min': '47.51',
 'name': '比亚迪',
 'open': '47.69',
 'turnover_rate': '0.88',
 'volumn': '76552',
 'volumn_hand': '159346'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-01-02' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.83',
 'change': '-1.08',
 'change_rate': '-1.94',
 'close': '54.57',
 'date': '2020-04-10',
 'max': '56.28',
 'min': '54.15',
 'name': '比亚迪',
 'open': '56.28',
 'turnover_rate': '0.73',
 'volumn': '72776',
 'volumn_hand': '131855'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-10' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.79',
 'change': '0.33',
 'change_rate': '0.60',
 'close': '55.65',
 'date': '2020-04-09',
 'max': '56.54',
 'min': '55.55',
 'name': '比亚迪',
 'open': '55.81',
 'turnover_rate': '0.74',
 'volumn': '74673',
 'volumn_hand': '133338'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-09' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '1.35',
 'change': '-0.99',
 'change_rate': '-1.76',
 'close': '55.32',
 'date': '2020-04-08',
 'max': '55.80',
 'min': '55.04',
 'name': '比亚迪',
 'open': '55.80',
 'turnover_rate': '0.71',
 'volumn': '71703',
 'volumn_hand': '129543'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-08' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.40',
 'change': '1.31',
 'change_rate': '2.38',
 'close': '56.31',
 'date': '2020-04-07',
 'max': '56.92',
 'min': '55.60',
 'name': '比亚迪',
 'open': '56.44',
 'turnover_rate': '1.04',
 'volumn': '106143',
 'volumn_hand': '189116'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-07' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '2.97',
 'change': '-1.59',
 'change_rate': '-2.81',
 'close': '55.00',
 'date': '2020-04-03',
 'max': '56.59',
 'min': '54.91',
 'name': '比亚迪',
 'open': '56.59',
 'turnover_rate': '0.93',
 'volumn': '94050',
 'volumn_hand': '169190'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-03' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '3.33',
 'change': '-0.53',
 'change_rate': '-0.93',
 'close': '56.59',
 'date': '2020-04-02',
 'max': '56.70',
 'min': '54.80',
 'name': '比亚迪',
 'open': '56.70',
 'turnover_rate': '1.29',
 'volumn': '130069',
 'volumn_hand': '233842'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-02' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.scraper] ERROR: Error processing {'amplitude': '6.07',
 'change': '-2.85',
 'change_rate': '-4.75',
 'close': '57.12',
 'date': '2020-04-01',
 'max': '60.66',
 'min': '57.02',
 'name': '比亚迪',
 'open': '59.90',
 'turnover_rate': '2.02',
 'volumn': '213909',
 'volumn_hand': '365565'}
Traceback (most recent call last):
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/glacier/scrapy/stocks163/stocks163/pipelines.py", line 17, in process_item
    item['amplitude'], item['turnover_rate'])
  File "/home/glacier/scrapy/stocks163/stocks163/dbutil.py", line 32, in insertData
    self.cur.execute(sql)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 170, in execute
    result = self._query(query)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/cursors.py", line 328, in _query
    conn.query(q)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 517, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 732, in _read_query_result
    result.read()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 1075, in read
    first_packet = self.connection._read_packet()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/connections.py", line 684, in _read_packet
    packet.check_error()
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/protocol.py", line 220, in check_error
    err.raise_mysql_exception(self._data)
  File "/home/glacier/.conda/envs/scrapy/lib/python3.6/site-packages/pymysql/err.py", line 109, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1062, "Duplicate entry '比亚迪-2020-04-01' for key 'uk_t_1'")
2020-08-02 22:59:11 [scrapy.core.engine] INFO: Closing spider (finished)
2020-08-02 22:59:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 34653,
 'downloader/request_count': 29,
 'downloader/request_method_count/GET': 2,
 'downloader/request_method_count/POST': 27,
 'downloader/response_bytes': 884184,
 'downloader/response_count': 29,
 'downloader/response_status_count/200': 28,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 24,
 'elapsed_time_seconds': 10.396846,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 8, 2, 14, 59, 11, 959428),
 'log_count/DEBUG': 30,
 'log_count/ERROR': 420,
 'log_count/INFO': 10,
 'memusage/max': 53440512,
 'memusage/startup': 53440512,
 'request_depth_max': 1,
 'response_received_count': 29,
 'robotstxt/request_count': 2,
 'robotstxt/response_count': 2,
 'robotstxt/response_status_count/200': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 54,
 'scheduler/dequeued/memory': 54,
 'scheduler/enqueued': 54,
 'scheduler/enqueued/memory': 54,
 'splash/execute/request_count': 27,
 'splash/execute/response_count/200': 27,
 'start_time': datetime.datetime(2020, 8, 2, 14, 59, 1, 562582)}
2020-08-02 22:59:11 [scrapy.core.engine] INFO: Spider closed (finished)
